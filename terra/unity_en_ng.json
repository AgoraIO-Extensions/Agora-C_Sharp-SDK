[
  {
    "id": "api_iagoraparameter_setparameters",
    "name": "SetParameters [2/2]",
    "description": "Configures technical preview or customized features provided by the SDK using JSON.\n\nPlease [contact technical support](https://ticket.shengwang.cn/) to obtain the JSON configuration method.",
    "parameters": [
      {
        "parameters": "Parameters in JSON string format."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_enumerateplaybackdevices",
    "name": "EnumeratePlaybackDevices",
    "description": "Gets the list of all playback devices in the system.\n\n(Windows and macOS only)",
    "parameters": [],
    "returns": "If the method call succeeds, returns a DeviceInfo array containing the device ID and device name of all audio playback devices.\n If the method call fails: null.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_enumeraterecordingdevices",
    "name": "EnumerateRecordingDevices",
    "description": "Gets the list of all audio recording devices in the system.\n\n(Windows and macOS only)",
    "parameters": [],
    "returns": "If the method call succeeds, returns a DeviceInfo array containing the device ID and device name of all audio recording devices.\n If the method call fails: null.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_followsystemloopbackdevice",
    "name": "FollowSystemLoopbackDevice",
    "description": "Sets whether the loopback capture device follows the system default playback device.\n\nThis method is only applicable to Windows and macOS.",
    "parameters": [
      {
        "enable": "Whether to follow the system default playback device: true : Follow. When the system default playback device changes, the SDK immediately switches the loopback capture device accordingly. false : Do not follow. The SDK switches to the system default playback device only when the current loopback capture device is removed."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_followsystemplaybackdevice",
    "name": "FollowSystemPlaybackDevice",
    "description": "Sets whether the audio playback device used by the SDK follows the system default audio playback device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "enable": "Whether to follow the system default audio playback device: true : Follow. When the system default audio playback device changes, the SDK immediately switches to it. false : Do not follow. The SDK switches to the system default audio playback device only when the current device used by the SDK is removed."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_followsystemrecordingdevice",
    "name": "FollowSystemRecordingDevice",
    "description": "Sets whether the audio recording device used by the SDK follows the system default audio recording device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "enable": "Whether to follow the system default audio recording device: true : Follow. When the system default audio recording device changes, the SDK immediately switches to it. false : Do not follow. The SDK switches to the system default audio recording device only when the current device used by the SDK is removed."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getloopbackdevice",
    "name": "GetLoopbackDevice",
    "description": "Gets the current loopback capture device.\n\nThis method is for Windows and macOS only.",
    "parameters": [
      {
        "deviceId": "Output parameter. The ID of the current loopback capture device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getplaybackdefaultdevice",
    "name": "GetPlaybackDefaultDevice [1/2]",
    "description": "Gets the system default audio playback device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The ID of the system default audio playback device."
      },
      {
        "deviceName": "Output parameter. The name of the system default audio playback device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getplaybackdefaultdevice2",
    "name": "GetPlaybackDefaultDevice [2/2]",
    "description": "Gets the system default audio playback device and its type.\n\n(macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The ID of the system default audio playback device."
      },
      {
        "deviceName": "Output parameter. The name of the system default audio playback device."
      },
      {
        "deviceTypeName": "Output parameter. The type of the audio device, such as: built-in, USB, HDMI, etc."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getplaybackdevice",
    "name": "GetPlaybackDevice",
    "description": "Gets the current audio playback device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The device ID of the current audio playback device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getplaybackdeviceinfo",
    "name": "GetPlaybackDeviceInfo [1/2]",
    "description": "Retrieves information about the audio playback device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The device ID of the playback device."
      },
      {
        "deviceName": "Output parameter. The device name of the playback device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getplaybackdeviceinfo2",
    "name": "GetPlaybackDeviceInfo [2/2]",
    "description": "Retrieves information about the audio playback device and its type.\n\n(macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The device ID of the playback device."
      },
      {
        "deviceName": "Output parameter. The device name of the playback device."
      },
      {
        "deviceTypeName": "Output parameter. The type of the audio playback device, such as built-in, USB, HDMI, etc."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getplaybackdevicevolume",
    "name": "GetPlaybackDeviceVolume",
    "description": "Retrieves the volume of the playback device.",
    "parameters": [],
    "returns": "Playback device volume. Value range: [0,255].",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getrecordingdefaultdevice",
    "name": "GetRecordingDefaultDevice [1/2]",
    "description": "Retrieves the system default audio recording device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The ID of the system default audio recording device."
      },
      {
        "deviceName": "Output parameter. The name of the system default audio recording device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getrecordingdefaultdevice2",
    "name": "GetRecordingDefaultDevice [2/2]",
    "description": "Retrieves the system default audio recording device and its type.\n\n(macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The ID of the system default audio recording device."
      },
      {
        "deviceName": "Output parameter. The name of the system default audio recording device."
      },
      {
        "deviceTypeName": "Output parameter. The type of the audio device, such as built-in, USB, HDMI, etc."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getrecordingdevice",
    "name": "GetRecordingDevice",
    "description": "Retrieves the current audio recording device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The device ID of the current recording device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getrecordingdeviceinfo",
    "name": "GetRecordingDeviceInfo [1/2]",
    "description": "Retrieves information about the audio recording device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The device ID of the playback device."
      },
      {
        "deviceName": "Output parameter. The device name of the playback device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getrecordingdeviceinfo2",
    "name": "GetRecordingDeviceInfo [2/2]",
    "description": "Retrieves information about the audio recording device and its type.\n\n(macOS only)",
    "parameters": [
      {
        "deviceId": "Output parameter. The device ID of the playback device."
      },
      {
        "deviceName": "Output parameter. The device name of the playback device."
      },
      {
        "deviceTypeName": "Output parameter. The type of the audio recording device, such as built-in, USB, HDMI, etc."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getrecordingdevicemute",
    "name": "GetRecordingDeviceMute",
    "description": "Gets the mute status of the current recording device.",
    "parameters": [],
    "returns": "true : The recording device is muted. false : The recording device is not muted.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_getrecordingdevicevolume",
    "name": "GetRecordingDeviceVolume",
    "description": "Gets the volume of the recording device.\n\nThis method applies to Windows only.",
    "parameters": [],
    "returns": "The volume of the recording device. Value range: [0,255].",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_setloopbackdevice",
    "name": "SetLoopbackDevice",
    "description": "Specifies the loopback device.\n\nBy default, the SDK uses the current playback device as the loopback device. To specify another audio device as the loopback device, call this method and set deviceId to the desired loopback device.\nThis method changes the current recording device used by the SDK but does not change the system default recording device. For example, if the system default recording device is Microphone 1, and you call this method before joining a channel to set the current audio route to Soundcard 1, the SDK performs device testing on Soundcard 1. After testing, when you join a channel, the SDK still uses the system default recording device, which is Microphone 1. This method applies to Windows and macOS only.\nApplicable scenario:\nApp A plays music through a Bluetooth headset; App B is used for video conferencing through a speaker.\n If the loopback device is set to the Bluetooth headset, the SDK publishes the music from App A to the remote end.\n If the loopback device is set to the speaker, the SDK does not publish the music from App A to the remote end.\n If you switch from Bluetooth headset to wired headset for App A after setting the loopback device to Bluetooth headset, you need to call this method again to set the loopback device to the wired headset. The SDK will then continue to publish the music from App A to the remote end.",
    "parameters": [
      {
        "deviceId": "Specifies the loopback device used by the SDK. Obtained via EnumeratePlaybackDevices. Plugging or unplugging devices does not affect deviceId."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_setplaybackdevice",
    "name": "SetPlaybackDevice",
    "description": "Specifies the playback device.\n\nThis method changes the current audio route but does not change the system default audio route. For example, if the system default audio route is Speaker 1, and you call this method before joining a channel to set the audio route to Speaker 2, the SDK performs device testing on Speaker 2. After testing, when you join a channel, the SDK still uses the system default audio route, which is Speaker 1. This method applies to Windows and macOS only.",
    "parameters": [
      {
        "deviceId": "Specifies the playback device. Obtained via EnumeratePlaybackDevices. Plugging or unplugging devices does not affect deviceId."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_setplaybackdevicemute",
    "name": "SetPlaybackDeviceMute",
    "description": "Sets the playback device to mute.",
    "parameters": [
      {
        "mute": "Whether to mute the playback device: true : Mute the playback device. false : Do not mute the playback device."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_setplaybackdevicevolume",
    "name": "SetPlaybackDeviceVolume",
    "description": "Sets the playback device volume.\n\nThis method applies to Windows only.",
    "parameters": [
      {
        "volume": "Playback device volume. Value range: [0,255]."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_setrecordingdevice",
    "name": "SetRecordingDevice",
    "description": "Specifies the recording device.\n\nThis method changes the current recording device used by the SDK but does not change the system default recording device. For example, if the system default recording device is Microphone 1, and you call this method before joining a channel to set the current audio route to Bluetooth Headset 1, the SDK performs device testing on Bluetooth Headset 1. After testing, when you join a channel, the SDK still uses the system default recording device, which is Microphone 1. This method applies to Windows and macOS only.",
    "parameters": [
      {
        "deviceId": "Device ID of the recording device. You can obtain it via EnumerateRecordingDevices. Plugging or unplugging devices does not affect deviceId."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_setrecordingdevicemute",
    "name": "SetRecordingDeviceMute",
    "description": "Sets the current recording device to mute.",
    "parameters": [
      {
        "mute": "Whether to mute the recording device: true : The recording device is muted. false : The recording device is not muted."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_setrecordingdevicevolume",
    "name": "SetRecordingDeviceVolume",
    "description": "Sets the volume of the audio recording device.\n\nThis method is only available on Windows and macOS.",
    "parameters": [
      {
        "volume": "The volume of the audio recording device. The range is [0,255]. 0 means mute, and 255 means the maximum volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_startaudiodeviceloopbacktest",
    "name": "StartAudioDeviceLoopbackTest",
    "description": "Starts an audio device loopback test.\n\nThis method tests whether the audio recording and playback devices are working properly. Once the test starts, the recording device captures local audio and plays it back through the playback device. The SDK triggers two OnAudioVolumeIndication callbacks at the specified time interval to report the volume levels of the recording device (uid = 0) and the playback device (uid = 1).\n This method is only available on Windows and macOS.\n You can call this method before or after joining a channel.\n Only the host role can call this method.\n This method only tests local audio devices and does not involve network connections.\n After the test is complete, you must call StopAudioDeviceLoopbackTest to stop the loopback test.",
    "parameters": [
      {
        "indicationInterval": "The time interval in milliseconds at which the SDK triggers the OnAudioVolumeIndication callback. It is recommended to set this to more than 200 ms. If set to less than 10 ms, the OnAudioVolumeIndication callback will not be received."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_startplaybackdevicetest",
    "name": "StartPlaybackDeviceTest",
    "description": "Starts a playback device test.\n\nThis method tests whether the local playback device is working properly. After starting the test, the SDK plays the specified audio file. If the tester hears sound, the playback device is functioning properly.\nAfter calling this method, the SDK triggers the OnAudioVolumeIndication callback every 100 milliseconds to report the volume information of uid = 1 and the playback device.\nThe difference between this method and StartEchoTest is that this method checks whether the local playback device is working, while the latter checks whether the audio/video devices and network are functioning properly. You must call this method before joining a channel. After the test is complete, if you want to join a channel, make sure to call StopPlaybackDeviceTest to stop the test first.",
    "parameters": [
      {
        "testAudioFilePath": "The absolute path of the audio file. The path string must be in UTF-8 encoding.\n Supported file formats: wav, mp3, m4a, aac.\n Supported sampling rates: 8000, 16000, 32000, 44100, 48000."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_startrecordingdevicetest",
    "name": "StartRecordingDeviceTest",
    "description": "Starts a recording device test.\n\nThis method tests whether the local recording device is working properly. After calling this method, the SDK triggers the OnAudioVolumeIndication callback at the specified time interval to report the volume information of uid = 0 and the recording device.\nThe difference between this method and StartEchoTest is that this method checks whether the local recording device is working, while the latter checks whether the audio/video devices and network are functioning properly. You must call this method before joining a channel. After the test is complete, if you want to join a channel, make sure to call StopRecordingDeviceTest to stop the test first.",
    "parameters": [
      {
        "indicationInterval": "The time interval in milliseconds at which the SDK triggers the OnAudioVolumeIndication callback. The minimum value is 10. Otherwise, the OnAudioVolumeIndication callback will not be received and the SDK will return error code -2. Agora recommends setting this value to 100."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.\n -2: Invalid parameter. Please reset the parameter.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_stopaudiodeviceloopbacktest",
    "name": "StopAudioDeviceLoopbackTest",
    "description": "Stops the audio device loopback test.\n\nThis method is only available on Windows and macOS.\n You can call this method before or after joining a channel.\n Only the host role can call this method.\n After calling StartAudioDeviceLoopbackTest, you must call this method to stop the loopback test.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_stopplaybackdevicetest",
    "name": "StopPlaybackDeviceTest",
    "description": "Stops the playback device test.\n\nThis method stops the playback device test. After calling StartPlaybackDeviceTest, you must call this method to stop the test. You must call this method before joining a channel.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_iaudiodevicemanager_stoprecordingdevicetest",
    "name": "StopRecordingDeviceTest",
    "description": "Stops the recording device test.\n\nThis method stops the recording device test. After calling StartRecordingDeviceTest, you must call this method to stop the test. You must call this method before joining a channel.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_muteallremoteaudiostreams",
    "name": "MuteAllRemoteAudioStreams",
    "description": "Unsubscribes from or resumes all remote users' audio streams.\n\nAfter successfully calling this method, the local user will unsubscribe from or resume all remote users' audio streams, including those who join the channel after this method is called.\n This method must be called after JoinChannel [2/2].\n When using spatial audio, if you need to control whether to subscribe to all remote users' audio streams, it is recommended to call this method instead of IRtcEngine 's MuteAllRemoteAudioStreams method.\n After calling this method, you need to call UpdateSelfPosition and UpdateRemotePosition to update the spatial positions of the local and remote users; otherwise, the settings in this method will not take effect.",
    "parameters": [
      {
        "mute": "Whether to unsubscribe from all remote users' audio streams: true : Unsubscribe from all remote users' audio streams. false : Subscribe to all remote users' audio streams."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_mutelocalaudiostream",
    "name": "MuteLocalAudioStream",
    "description": "Stops or resumes publishing the local audio stream.\n\nThis method does not affect the audio capturing state, as it does not disable the audio capture device.\n You must call this method after JoinChannel [1/2] or JoinChannel [2/2].\n When using spatial audio, to control whether to publish the local audio stream, it is recommended to call this method instead of IRtcEngine 's MuteLocalAudioStream method.\n After this method is successfully called, the remote user will receive the OnUserMuteAudio and OnRemoteAudioStateChanged callbacks.",
    "parameters": [
      {
        "mute": "Whether to stop publishing the local audio stream. true : Stop publishing the local audio stream. false : Publish the local audio stream."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_muteremoteaudiostream",
    "name": "MuteRemoteAudioStream",
    "description": "Stops or resumes subscribing to the audio stream of a specified remote user.",
    "parameters": [
      {
        "uid": "User ID. Must be the same as the ID used when the user joined the channel."
      },
      {
        "mute": "Whether to stop subscribing to the audio stream of the specified remote user. true : Stop subscribing to the specified user's audio stream. false : (Default) Subscribe to the specified user's audio stream. The SDK determines whether to subscribe based on the distance between the local and remote users."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_setaudiorecvrange",
    "name": "SetAudioRecvRange",
    "description": "Sets the audio reception range of the local user.\n\nAfter this method is successfully called, the user can only hear remote users within the specified range or in the same team. You can call this method at any time to update the audio reception range.",
    "parameters": [
      {
        "range": "The maximum range for receiving audio, in the distance unit of the game engine. The value must be greater than 0. The default value is 20."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_setdistanceunit",
    "name": "SetDistanceUnit",
    "description": "Sets the length (in meters) of one unit of distance in the game engine.\n\nThe unit of distance in the game engine is defined by the engine itself, while the unit of distance in the Agora spatial audio algorithm is meters. By default, the SDK converts one unit of game engine distance to one meter. You can call this method to convert the unit distance in the game engine to a specified number of meters.",
    "parameters": [
      {
        "unit": "The number of meters corresponding to one unit of distance in the game engine. This parameter must be greater than 0.00. The default value is 1.00. For example, setting unit to 2.00 means that one unit of game engine distance equals 2 meters.\nThe larger the value, the faster the sound attenuation when a remote user moves away from the local user."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_setmaxaudiorecvcount",
    "name": "SetMaxAudioRecvCount",
    "description": "Sets the maximum number of audio streams that can be received within the audio reception range.\n\nIf the number of audio streams that can be received within the audio reception range exceeds the set value, the local user will receive the maxCount audio streams that are closest in distance.",
    "parameters": [
      {
        "maxCount": "Maximum number of audio streams that can be received within the audio reception range. The value must be â‰¤ 16. Default is 10."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_setplayerattenuation",
    "name": "SetPlayerAttenuation",
    "description": "Sets the sound attenuation property of the media player.",
    "parameters": [
      {
        "playerId": "Media player ID."
      },
      {
        "attenuation": "Sound attenuation coefficient of the media player, value range [0,1].\n 0: Broadcast mode. Volume and tone do not attenuate with distance. The local user hears the same volume and tone regardless of distance.\n (0,0.5): Weak attenuation mode. Volume and tone attenuate slightly during transmission, allowing sound to travel farther than in a real environment.\n 0.5: (Default) Simulates volume attenuation in a real environment. Equivalent to not setting the attenuation parameter.\n (0.5,1]: Strong attenuation mode. Volume and tone attenuate rapidly during transmission."
      },
      {
        "forceSet": "Whether to forcefully apply the sound attenuation effect for the media player: true : Forcefully use attenuation to set the media player's sound attenuation effect. In this case, the audioAttenuation coefficient set in SpatialAudioZone does not apply to the media player. false : Do not forcefully use attenuation to set the media player's sound attenuation effect. There are two cases:\n If the sound source and listener are inside and outside the isolation zone respectively, the sound attenuation effect is determined by the audioAttenuation in SpatialAudioZone.\n If the sound source and listener are both inside the same isolation zone or both outside, the sound attenuation effect is determined by the attenuation in this method."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_setzones",
    "name": "SetZones",
    "description": "Sets sound insulation zones.\n\nIn a virtual interactive scenario, you can use this method to set sound insulation zones and sound attenuation coefficients. When the sound source (can be a user or media player) and the listener are inside and outside the insulation zone respectively, a sound attenuation effect similar to that in a real environment with building partitions is experienced.\n When the sound source and the listener are inside and outside the insulation zone respectively, the attenuation effect is determined by the attenuation coefficient in SpatialAudioZone.\n If the user or media player are in the same insulation zone, SpatialAudioZone has no effect. The attenuation effect is determined by the attenuation parameter in SetPlayerAttenuation or SetRemoteAudioAttenuation. If neither method is called, the SDK uses a default attenuation coefficient of 0.5, simulating real-world sound attenuation.\n If the sound source and the receiver belong to two different insulation zones, the receiver cannot hear the sound source. If this method is called multiple times, the most recent configuration of sound insulation zones takes effect.",
    "parameters": [
      {
        "zones": "Configuration of sound insulation zones. See SpatialAudioZone. Setting this parameter to NULL clears all sound insulation zones. On the Windows platform, make sure the number of members in the zones array matches the value of zoneCount, otherwise a crash may occur."
      },
      {
        "zoneCount": "Number of sound insulation zones."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_updateplayerpositioninfo",
    "name": "UpdatePlayerPositionInfo",
    "description": "Updates the spatial position of the media player.\n\nAfter a successful update, the local user can hear the change in the spatial position of the media player.",
    "parameters": [
      {
        "playerId": "Media player ID."
      },
      {
        "positionInfo": "Spatial position information of the media player. See RemoteVoicePositionInfo."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ibasespatialaudioengine_updateselfposition",
    "name": "UpdateSelfPosition",
    "description": "Updates the spatial position of the local user.\n\nUnder the ILocalSpatialAudioEngine class, this method must be used together with UpdateRemotePosition. The SDK calculates the relative position between the local and remote users based on the parameters set by this method and UpdateRemotePosition, and then calculates the spatial audio parameters.",
    "parameters": [
      {
        "position": "Coordinates in the world coordinate system. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions, respectively. Forward, right, and up correspond to the positive directions of Unity's Vector3 z, x, and y axes."
      },
      {
        "axisForward": "Unit vector of the forward axis in the world coordinate system. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions, respectively. Forward, right, and up correspond to the positive directions of Unity's Vector3 z, x, and y axes."
      },
      {
        "axisRight": "Unit vector of the right axis in the world coordinate system. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions."
      },
      {
        "axisUp": "Unit vector of the up axis in the world coordinate system. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_ilocalspatialaudioengine_clearremotepositions",
    "name": "ClearRemotePositions",
    "description": "Deletes the spatial position information of all remote users.\n\nAfter this method is successfully called, the local user will no longer hear any remote users.\nAfter leaving the channel, to avoid wasting computing resources, you can also call this method to delete the spatial position information of all remote users.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_ilocalspatialaudioengine_initialize",
    "name": "Initialize",
    "description": "Initializes ILocalSpatialAudioEngine.\n\nYou must call this method to initialize ILocalSpatialAudioEngine before calling any other method of the ILocalSpatialAudioEngine class.\n The SDK supports creating only one ILocalSpatialAudioEngine instance per app.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ilocalspatialaudioengine_release",
    "name": "Dispose",
    "description": "Destroys ILocalSpatialAudioEngine.\n\nThis method releases all resources under ILocalSpatialAudioEngine. When the user no longer needs spatial audio, you can call this method to release the resources for other operations.\nAfter calling this method, you can no longer use any API under ILocalSpatialAudioEngine. To use spatial audio again, you need to call Initialize to create a new ILocalSpatialAudioEngine after Dispose completes.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "api_ilocalspatialaudioengine_removeremoteposition",
    "name": "RemoveRemotePosition",
    "description": "Deletes the spatial position information of a specified remote user.\n\nAfter this method is successfully called, the local user will no longer hear the specified remote user.\nAfter leaving the channel, to avoid wasting computing resources, you need to call this method to delete the spatial position information of the specified remote user. Otherwise, the spatial position information of that user will be retained. When the number of remote users exceeds the maximum number of audio streams set by SetMaxAudioRecvCount, the SDK will automatically stop subscribing to the audio streams of the farthest users based on relative distance.",
    "parameters": [
      {
        "uid": "User ID. Must be the same as the ID used when the user joined the channel."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_ilocalspatialaudioengine_setremoteaudioattenuation",
    "name": "SetRemoteAudioAttenuation",
    "description": "Sets the sound attenuation effect for a specified user.",
    "parameters": [
      {
        "uid": "User ID. Must match the user ID used when joining the channel."
      },
      {
        "attenuation": "Sound attenuation coefficient for the specified user, value range [0,1]."
      },
      {
        "forceSet": "Whether to forcefully apply the sound attenuation effect for the user: true : Forcefully use attenuation to set the user's sound attenuation effect. In this case, the audioAttenuation coefficient set in SpatialAudioZone does not apply to the user. false : Do not forcefully use attenuation to set the user's sound attenuation effect. There are two cases:\n If the sound source and listener are inside and outside the isolation zone respectively, the sound attenuation effect is determined by the audioAttenuation in SpatialAudioZone.\n If the sound source and listener are both inside the same isolation zone or both outside, the sound attenuation effect is determined by the attenuation in this method."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ilocalspatialaudioengine_updateremoteposition",
    "name": "UpdateRemotePosition",
    "description": "Updates the spatial position information of a remote user.\n\nAfter this method is successfully called, the SDK calculates spatial audio parameters based on the relative position between the local and remote users. You must call this method after JoinChannel [2/2].",
    "parameters": [
      {
        "uid": "User ID. Must be the same as the ID used when the user joined the channel."
      },
      {
        "posInfo": "The spatial position information of the remote user. See RemoteVoicePositionInfo."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_createcustomaudiotrack",
    "name": "CreateCustomAudioTrack",
    "description": "Creates a custom audio capture track.\n\nTo publish custom captured audio in a channel, follow these steps:\n Call this method to create an audio track and obtain the audio track ID.\n When calling JoinChannel [2/2] to join a channel, set publishCustomAudioTrackId in ChannelMediaOptions to the audio track ID you want to publish, and set publishCustomAudioTrack to true.\n Call PushAudioFrame and set trackId to the audio track ID specified in step 2 to publish the corresponding custom audio source in the channel. This method must be called before joining a channel.",
    "parameters": [
      {
        "trackType": "The type of custom audio track. See AUDIO_TRACK_TYPE. If AUDIO_TRACK_DIRECT is specified, you must set publishMicrophoneTrack in ChannelMediaOptions to false when calling JoinChannel [2/2], otherwise joining the channel will fail and return error code -2."
      },
      {
        "config": "Configuration of the custom audio track. See AudioTrackConfig."
      }
    ],
    "returns": "If the method call succeeds, returns the audio track ID as the unique identifier of the audio track.\n If the method call fails, returns 0xffffffff. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_destroycustomaudiotrack",
    "name": "DestroyCustomAudioTrack",
    "description": "Destroys the specified audio track.",
    "parameters": [
      {
        "trackId": "The custom audio track ID returned by the CreateCustomAudioTrack method."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_pullaudioframe",
    "name": "PullAudioFrame",
    "description": "Pulls remote audio data.\n\nAfter calling this method, the app actively pulls the decoded and mixed remote audio data for playback. This method and the OnPlaybackAudioFrame callback can both be used to obtain the mixed remote audio playback data. After enabling external audio rendering using SetExternalAudioSink, the app will no longer receive data from the OnPlaybackAudioFrame callback. Therefore, choose between this method and the OnPlaybackAudioFrame callback based on your actual business needs. They differ in processing mechanisms as follows:\n After calling this method, the app actively pulls audio data. By setting audio data, the SDK can adjust the buffer to help the app handle latency and effectively avoid audio playback jitter.\n After registering the OnPlaybackAudioFrame callback, the SDK pushes audio data to the app through the callback. When the app processes audio frame latency, it may cause audio playback jitter. This method is only used to pull mixed remote audio playback data. To obtain raw captured audio data, or raw playback data of each stream before mixing, you can register the corresponding callback by calling RegisterAudioFrameObserver.",
    "parameters": [
      {
        "frame": "Pointer to AudioFrame."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_pushaudioframe",
    "name": "PushAudioFrame",
    "description": "Pushes external audio frames.\n\nCall this method to push external audio frames through an audio track.",
    "parameters": [
      {
        "frame": "External audio frame. See AudioFrame."
      },
      {
        "trackId": "Audio track ID. If you want to publish a custom external audio source, set this parameter to the ID of the custom audio track you want to publish."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_pushvideoframe",
    "name": "PushVideoFrame",
    "description": "Publishes external raw video frames to the channel through a custom video track.\n\nWhen you need to publish a custom captured video in the channel, refer to the following steps:\n Call the CreateCustomVideoTrack method to create a video track and get the video track ID.\n When calling JoinChannel [2/2] to join the channel, set customVideoTrackId in ChannelMediaOptions to the video track ID you want to publish, and set publishCustomVideoTrack to true.\n Call this method and specify videoTrackId as the video track ID set in step 2 to publish the corresponding custom video source in the channel. After calling this method, even if you stop pushing external video frames to the SDK, the custom captured video stream will still be counted in video usage duration and incur charges. Agora recommends taking appropriate measures based on your actual situation to avoid such video billing:\n If you no longer need to capture external video data, call DestroyCustomVideoTrack to destroy the custom captured video track.\n If you only want to use the captured external video data for local preview and not publish it in the channel, call MuteLocalVideoStream to stop sending the video stream, or call UpdateChannelMediaOptions and set publishCustomVideoTrack to false.",
    "parameters": [
      {
        "frame": "The video frame to be pushed. See ExternalVideoFrame."
      },
      {
        "videoTrackId": "The video track ID returned by the CreateCustomVideoTrack method. If you only need to push one external video stream, you can set videoTrackId to 0."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_registeraudioframeobserver",
    "name": "RegisterAudioFrameObserver",
    "description": "Registers an audio frame observer object.\n\nThis method registers an audio frame observer object, i.e., registers callbacks. You need to call this method to register the callbacks if you want the SDK to trigger the OnMixedAudioFrame, OnRecordAudioFrame, OnPlaybackAudioFrame, OnPlaybackAudioFrameBeforeMixing, and OnEarMonitoringAudioFrame callbacks.",
    "parameters": [
      {
        "audioFrameObserver": "Instance of the interface object. See IAudioFrameObserver. Passing NULL means unregistering. It is recommended to call this method after receiving OnLeaveChannel to release the audio frame observer object."
      },
      {
        "mode": "Audio data callback mode. See OBSERVER_MODE."
      },
      {
        "position": "Audio observation position.\n AUDIO_FRAME_POSITION_PLAYBACK (0x0001): Observes the playback audio after mixing from all remote users. Corresponds to the OnPlaybackAudioFrame callback.\n AUDIO_FRAME_POSITION_RECORD (0x0002): Observes the captured audio of the local user. Corresponds to the OnRecordAudioFrame callback.\n AUDIO_FRAME_POSITION_MIXED (0x0004): Observes the audio after mixing from the local and all remote users. Corresponds to the OnMixedAudioFrame callback.\n AUDIO_FRAME_POSITION_BEFORE_MIXING (0x0008): Observes the audio of a single remote user before mixing. Corresponds to the OnPlaybackAudioFrameBeforeMixing callback.\n AUDIO_FRAME_POSITION_EAR_MONITORING (0x0010): Observes the ear monitoring audio of a single local user. Corresponds to the OnEarMonitoringAudioFrame callback."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggested solutions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_registerfaceinfoobserver",
    "name": "RegisterFaceInfoObserver",
    "description": "Registers a face info observer.\n\nYou can call this method to register the OnFaceInfo callback to obtain the face information processed by the Agora voice driver extension. When registering the face info observer, you can register the callbacks in the IFaceInfoObserver class as needed. After successful registration, the SDK triggers the registered callback when it captures face information processed by the voice driver extension.\n You must call this method before joining a channel.\n Before calling this method, make sure you have called EnableExtension to enable the voice driver extension.",
    "parameters": [
      {
        "observer": "Face info observer. See IFaceInfoObserver."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_registervideoencodedframeobserver",
    "name": "RegisterVideoEncodedFrameObserver",
    "description": "Registers a video frame receiver observer for encoded video images.\n\nIf you only want to observe encoded video frames (such as H.264 format) and do not need to decode and render the video, Agora recommends that you register an IVideoEncodedFrameObserver class using this method. This method must be called before joining a channel.",
    "parameters": [
      {
        "videoEncodedImageReceiver": "Video frame receiver observer. See IVideoEncodedFrameObserver."
      },
      {
        "mode": "Video data callback mode. See OBSERVER_MODE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_registervideoframeobserver",
    "name": "RegisterVideoFrameObserver",
    "description": "Registers a raw video frame observer object.\n\nIf you want to observe raw video frames (such as YUV or RGBA format), Agora recommends registering an IVideoFrameObserver class using this method.\nWhen registering the video observer, you can choose to register the callbacks in the IVideoFrameObserver class as needed. After successful registration, the SDK triggers the registered callbacks whenever a video frame is captured. When handling callbacks, you need to consider changes in the width and height parameters of the video frame, as the observed video frames may vary due to the following reasons:\n When the network condition is poor, the resolution may drop in steps.\n When the user manually adjusts the resolution, the resolution reported in the callback will also change.",
    "parameters": [
      {
        "videoFrameObserver": "Instance of the interface object. See IVideoFrameObserver. Pass NULL to unregister."
      },
      {
        "mode": "Video data callback mode. See OBSERVER_MODE."
      },
      {
        "formatPreference": "Video data type. See VIDEO_OBSERVER_FRAME_TYPE."
      },
      {
        "position": "Bit mask of the video observation position. See VIDEO_MODULE_POSITION."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_setexternalaudiosink",
    "name": "SetExternalAudioSink",
    "description": "Sets external audio rendering.\n\nAfter calling this method to enable external audio rendering, you can call PullAudioFrame to pull remote audio data. The app can process the pulled raw audio data before rendering to achieve the desired audio effects. After calling this method to enable external audio rendering, the app will no longer receive data from the OnPlaybackAudioFrame callback.",
    "parameters": [
      {
        "enabled": "Whether to enable external audio rendering: true : Enable external audio rendering. false : (Default) Disable external audio rendering."
      },
      {
        "sampleRate": "Sample rate (Hz) for external audio rendering. Can be set to 16000, 32000, 44100, or 48000."
      },
      {
        "channels": "Number of channels for external audio rendering:\n 1: Mono\n 2: Stereo"
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_setexternalaudiosource2",
    "name": "SetExternalAudioSource",
    "description": "Sets the external audio capture parameters.\n\nDeprecated Deprecated: This method is deprecated. Use CreateCustomAudioTrack instead.",
    "parameters": [
      {
        "enabled": "Whether to enable the use of an external audio source: true : Enable external audio source. false : (Default) Disable external audio source."
      },
      {
        "sampleRate": "The sample rate (Hz) of the external audio source. Can be set to 8000, 16000, 32000, 44100, or 48000."
      },
      {
        "channels": "The number of channels of the external audio source. Can be set to 1 (mono) or 2 (stereo)."
      },
      {
        "localPlayback": "Whether to play the external audio source locally: true : Play locally. false : (Default) Do not play locally."
      },
      {
        "publish": "Whether to publish the audio to the remote end: true : (Default) Publish to the remote end. false : Do not publish to the remote end."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_setexternalvideosource",
    "name": "SetExternalVideoSource",
    "description": "Sets the external video source.\n\nAfter calling this method to enable the external video source, you can call PushVideoFrame to push external video data to the SDK. Switching video sources dynamically in the channel is not supported. If you have called this method to enable the external video source and joined a channel, to switch to an internal video source, you must first leave the channel, then call this method to disable the external video source, and rejoin the channel.",
    "parameters": [
      {
        "enabled": "Whether to enable the external video source: true : Enable the external video source. The SDK is ready to receive external video frames. false : (Default) Do not enable the external video source."
      },
      {
        "useTexture": "Whether to use Texture format for external video frames: true : Use Texture format for external video frames. false : Do not use Texture format for external video frames."
      },
      {
        "sourceType": "Whether the external video frames are encoded. See EXTERNAL_VIDEO_SOURCE_TYPE."
      },
      {
        "encodedVideoOption": "Video encoding options. If sourceType is ENCODED_VIDEO_FRAME, this parameter must be set. You can [contact technical support](https://ticket.shengwang.cn/) to learn how to set this parameter."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_unregisterfaceinfoobserver",
    "name": "UnregisterFaceInfoObserver",
    "description": "Unregisters the face info observer.",
    "parameters": [
      {
        "observer": "Face info observer. See IFaceInfoObserver."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_unregistervideoencodedframeobserver",
    "name": "UnregisterVideoEncodedFrameObserver",
    "description": "Unregisters the video frame receiver observer for encoded video images.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaengine_unregistervideoframeobserver",
    "name": "UnregisterVideoFrameObserver",
    "description": "Unregisters the video frame observer.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_adjustplayoutvolume",
    "name": "AdjustPlayoutVolume",
    "description": "Adjusts the local playback volume.",
    "parameters": [
      {
        "volume": "Local playback volume, ranging from 0 to 100:\n 0: Mute.\n 100: (Default) Original playback volume of the media file."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_adjustpublishsignalvolume",
    "name": "AdjustPublishSignalVolume",
    "description": "Adjusts the volume heard by remote users.\n\nAfter connecting to the Agora server, you can call this method to adjust the volume of the media file heard by remote users.",
    "parameters": [
      {
        "volume": "Signal volume, ranging from 0 to 400:\n 0: Mute.\n 100: (Default) Original volume of the media file.\n 400: Four times the original volume (with built-in overflow protection)."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_dispose",
    "name": "Dispose",
    "description": "Releases all resources used by the media player.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getaudiobufferdelay",
    "name": "GetAudioBufferDelay",
    "description": "Gets the audio buffer delay when playing a media file.",
    "parameters": [
      {
        "delayMs": "Output parameter that indicates the audio buffer delay in milliseconds when playing a media file."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getduration",
    "name": "GetDuration",
    "description": "Gets the total duration of the media file.",
    "parameters": [
      {
        "duration": "Output parameter. Total duration of the media file (in milliseconds)."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getmediaplayerid",
    "name": "GetId",
    "description": "Gets the player ID.",
    "parameters": [],
    "returns": "If the method call succeeds, returns the player ID.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getmute",
    "name": "GetMute",
    "description": "Checks whether the currently playing media file is muted.",
    "parameters": [
      {
        "muted": "Output parameter. Mute state: true : The media file is muted. false : The media file is not muted."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getplayoutvolume",
    "name": "GetPlayoutVolume",
    "description": "Gets the current local playback volume.",
    "parameters": [
      {
        "volume": "Output parameter. Local playback volume, ranging from 0 to 100:\n 0: Silent.\n 100: (Default) Original playback volume of the media file."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getplayposition",
    "name": "GetPlayPosition",
    "description": "Gets the current playback position.",
    "parameters": [
      {
        "pos": "Current playback position of the media resource file, in milliseconds."
      }
    ],
    "returns": "If the method call succeeds, returns the current playback position (in milliseconds).\n < 0: Failure. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getplaysrc",
    "name": "GetPlaySrc",
    "description": "Gets the path of the media resource being played.",
    "parameters": [],
    "returns": "The path of the media resource being played.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getpublishsignalvolume",
    "name": "GetPublishSignalVolume",
    "description": "Gets the volume heard by remote users.",
    "parameters": [
      {
        "volume": "Output parameter. Remote playback volume of the playing file."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getstate",
    "name": "GetState",
    "description": "Gets the current state of the player.",
    "parameters": [],
    "returns": "The current state of the player. See MEDIA_PLAYER_STATE.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getstreamcount",
    "name": "GetStreamCount",
    "description": "Gets the number of media streams in the current media file.\n\nCall this method after Open and after receiving the OnPlayerSourceStateChanged callback reporting the playback state as PLAYER_STATE_OPEN_COMPLETED.",
    "parameters": [
      {
        "count": "Output parameter. Number of media streams in the current media file."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_getstreaminfo",
    "name": "GetStreamInfo",
    "description": "Gets media stream information by index.",
    "parameters": [
      {
        "index": "Media stream index. This parameter must be less than the count parameter returned by GetStreamCount."
      },
      {
        "info": "Output parameter. All information of the media stream. See PlayerStreamInfo."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_initeventhandler",
    "name": "InitEventHandler",
    "description": "Adds callback events for the media player.",
    "parameters": [
      {
        "engineEventHandler": "The callback event to add. See IMediaPlayerSourceObserver."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_mute",
    "name": "Mute",
    "description": "Sets whether to mute.",
    "parameters": [
      {
        "muted": "Mute option. true : Mute. false : (Default) Do not mute."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_open",
    "name": "Open",
    "description": "Opens a media resource.\n\nThis method is asynchronous.",
    "parameters": [
      {
        "url": "The path to the media file. Supports both local and online files."
      },
      {
        "startPos": "The start position (in milliseconds) for playback. Default is 0."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_openwithmediasource",
    "name": "OpenWithMediaSource",
    "description": "Opens a media resource and configures playback settings.\n\nThis method allows you to open different types of media resources, including custom media files, and configure playback settings. This method is asynchronous. To play the media file, you need to call the Play method after receiving the OnPlayerSourceStateChanged callback reporting the PLAYER_STATE_OPEN_COMPLETED state.",
    "parameters": [
      {
        "source": "The media resource. See MediaSource."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_pause",
    "name": "Pause",
    "description": "Pauses playback.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_play",
    "name": "Play",
    "description": "Plays the media file.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_playpreloadedsrc",
    "name": "PlayPreloadedSrc",
    "description": "Plays a preloaded media resource.\n\nAfter calling the PreloadSrc method to preload the media resource into the playlist, you can call this method to play the preloaded media resource. If you receive the OnPlayerSourceStateChanged callback reporting the status as PLAYER_STATE_PLAYING, the playback has succeeded.\nIf you want to switch the preloaded media resource to play, you can call this method again and specify the new media resource path. If you want to replay the media resource, you need to call PreloadSrc again to preload the resource into the playlist before playing. To clear the playlist, call Stop. If you call this method while playback is paused, it will take effect only after playback resumes.",
    "parameters": [
      {
        "src": "The URL of the media resource in the playlist. It must match the src set by the PreloadSrc method, otherwise playback will fail."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_preloadsrc",
    "name": "PreloadSrc",
    "description": "Preloads a media resource.\n\nYou can call this method to preload a media resource into the playlist. To preload multiple media resources, call this method multiple times.\nAfter successful preloading, call PlayPreloadedSrc to play the media resource, or call Stop to clear the playlist.\n Before calling this method, make sure you have successfully opened the media resource using Open or OpenWithMediaSource.\n The SDK does not support preloading duplicate media resources into the playlist, but it does support preloading the currently playing media resource again into the playlist.",
    "parameters": [
      {
        "src": "The network path of the media resource."
      },
      {
        "startPos": "The start position (in milliseconds) for playback after preloading into the playlist. Set this parameter to 0 when preloading a live stream."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_registeraudioframeobserver1",
    "name": "RegisterAudioFrameObserver [1/2]",
    "description": "Registers a PCM audio frame observer.\n\nYou need to implement an IAudioPcmFrameSink class in this method and register its callback based on your scenario. After successfully registering the audio frame observer, the SDK triggers the registered callback whenever it captures an audio frame.",
    "parameters": [
      {
        "observer": "Audio frame observer that monitors the reception of each audio frame. See IAudioPcmFrameSink."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_registeraudioframeobserver2",
    "name": "RegisterAudioFrameObserver [2/2]",
    "description": "Registers an audio frame observer.",
    "parameters": [
      {
        "observer": "Audio frame observer that monitors the reception of each audio frame. See IAudioPcmFrameSink."
      },
      {
        "mode": "Usage mode of the audio frame. See RAW_AUDIO_FRAME_OP_MODE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_resume",
    "name": "Resume",
    "description": "Resumes playback after pause.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_seek",
    "name": "Seek",
    "description": "Seeks to the specified playback position in the media file.\n\nIf you call Seek after playback has completed (as indicated by the OnPlayerSourceStateChanged callback reporting the status as PLAYER_STATE_PLAYBACK_COMPLETED or PLAYER_STATE_PLAYBACK_ALL_LOOPS_COMPLETED), the SDK will automatically start playback from the specified position upon successful call. You will receive an OnPlayerSourceStateChanged callback reporting the status as PLAYER_STATE_PLAYING.\n If you call Seek while playback is paused, the SDK will seek to the specified position upon success. To play, call Resume or Play.",
    "parameters": [
      {
        "newPos": "The specified position (in milliseconds)."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_selectaudiotrack",
    "name": "SelectAudioTrack [2/2]",
    "description": "Specifies the audio track to play in the current audio file.\n\nAfter obtaining the audio track index of the audio file, you can call this method to specify any track for playback. If different tracks of a multi-track file contain songs in different languages, you can use this method to set the playback language. You need to call this method after calling GetStreamInfo to get the audio stream index.",
    "parameters": [
      {
        "index": "The index of the audio track."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_selectmultiaudiotrack",
    "name": "SelectMultiAudioTrack",
    "description": "Selects the audio tracks for local playback and remote sending.\n\nYou can call this method to separately set the audio tracks for local playback and for sending to the remote end.\nBefore calling this method, you need to open the media file using OpenWithMediaSource and set enableMultiAudioTrack to true via MediaSource.",
    "parameters": [
      {
        "playoutTrackIndex": "The index of the audio track used for local playback. You can get the index via GetStreamInfo."
      },
      {
        "publishTrackIndex": "The index of the audio track sent to the remote end. You can get the index via GetStreamInfo."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setaudiodualmonomode",
    "name": "SetAudioDualMonoMode",
    "description": "Sets the channel mode of the current audio file.\n\nIn stereo audio files, the left and right channels can store different audio data. Depending on your needs, you can set the channel mode to original, left, right, or mixed. For example, in a karaoke (KTV) scenario, the left channel of the audio file stores the accompaniment, while the right channel stores the original vocals. If you only want to hear the accompaniment, call this method to set the channel mode to left. If you want to hear both the accompaniment and the original vocals, set the channel mode to mixed.\n You need to call this method after calling Open.\n This method is only applicable to stereo audio files.",
    "parameters": [
      {
        "mode": "Channel mode. See AUDIO_DUAL_MONO_MODE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setaudiopitch",
    "name": "SetAudioPitch",
    "description": "Adjusts the pitch of the currently playing media resource.\n\nYou need to call this method after calling Open.",
    "parameters": [
      {
        "pitch": "Adjusts the pitch of the locally played music file in semitone steps. The default value is 0, meaning no pitch adjustment. The valid range is [-12,12], where the pitch difference between two adjacent values is one semitone. The greater the absolute value, the more the pitch increases or decreases."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setloopcount",
    "name": "SetLoopCount",
    "description": "Sets loop playback.\n\nIf you want to enable loop playback, call this method and set the number of loops.\nWhen loop playback ends, the SDK triggers the OnPlayerSourceStateChanged callback to report the playback state as PLAYER_STATE_PLAYBACK_ALL_LOOPS_COMPLETED.",
    "parameters": [
      {
        "loopCount": "Number of playback loops.\n â‰¥0: Number of loops. For example, 0 means no looping, play once; 1 means loop once, play twice in total.\n -1: Infinite loop playback."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setplaybackspeed",
    "name": "SetPlaybackSpeed",
    "description": "Sets the playback speed of the current audio file.\n\nYou need to call this method after Open.",
    "parameters": [
      {
        "speed": "Playback speed. Recommended range is [30,400], where:\n 30: 0.3x speed.\n 100: Original speed.\n 400: 4x speed."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setplayeroption",
    "name": "SetPlayerOption [1/2]",
    "description": "Sets media player options.\n\nThe media player supports setting options via key and value.\nThe difference between this method and setPlayerOption [2/2] is that the value in this method is of type Int, while in setPlayerOption [2/2] it is of type String. The two are not interchangeable.",
    "parameters": [
      {
        "key": "Key value."
      },
      {
        "value": "Value."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setplayeroption2",
    "name": "setPlayerOption [2/2]",
    "description": "Sets media player options.\n\nThe media player supports setting options via key and value.\nThe difference between this method and SetPlayerOption [1/2] is that the value in this method is of type String, while in SetPlayerOption [1/2] it is of type Int. The two are not interchangeable.",
    "parameters": [
      {
        "key": "Key value."
      },
      {
        "value": "Value."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setrendermode",
    "name": "SetRenderMode",
    "description": "Sets the rendering mode of the player view.",
    "parameters": [
      {
        "renderMode": "Rendering mode of the player view. See RENDER_MODE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setspatialaudioparams",
    "name": "SetSpatialAudioParams",
    "description": "Enables or disables spatial audio for the media player.\n\nAfter successfully setting the spatial audio parameters for the media player, the SDK enables spatial audio for the media player, allowing the local user to perceive spatial effects from the media source.\nTo disable spatial audio for the media player, you need to set the params parameter to null.",
    "parameters": [
      {
        "spatial_audio_params": "Spatial audio parameters for the media player. See SpatialAudioParams."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_setview",
    "name": "SetView",
    "description": "Sets the player rendering view.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_stop",
    "name": "Stop",
    "description": "Stops playback.\n\nAfter calling this method to stop playback, to play again you need to call Open or OpenWithMediaSource to reopen the media resource.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_switchsrc",
    "name": "SwitchSrc",
    "description": "Switches the media resource.\n\nYou can call this method to switch the bitrate of the currently playing media resource based on the network conditions. For example:\n When the network is poor, switch to a lower bitrate media resource.\n When the network is good, switch to a higher bitrate media resource. After calling this method, if you receive the OnPlayerEvent callback reporting the event PLAYER_EVENT_SWITCH_COMPLETE, the switch was successful. If the switch fails, the SDK retries 3 times. If it still fails, you receive the OnPlayerEvent callback reporting the PLAYER_EVENT_SWITCH_ERROR event, indicating an error occurred during the switch.\n Make sure to call this method after Open.\n To ensure normal playback, pay attention to the following when calling this method:\n Do not call this method while playback is paused.\n Do not call Seek during bitrate switching.\n Ensure the playback position before switching is not greater than the total duration of the media resource being switched to.",
    "parameters": [
      {
        "src": "The network path of the media resource."
      },
      {
        "syncPts": "Whether to synchronize the start playback position before and after switching: true : Synchronize. false : (Default) Do not synchronize."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_unloadsrc",
    "name": "UnloadSrc",
    "description": "Releases the preloaded media resource.",
    "parameters": [
      {
        "src": "The network path of the media resource."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayer_unregisteraudioframeobserver",
    "name": "UnregisterAudioFrameObserver",
    "description": "Unregisters the audio frame observer.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_enableautoremovecache",
    "name": "EnableAutoRemoveCache",
    "description": "Enables or disables automatic cache file removal.\n\nWhen automatic cache file removal is enabled, if the number of cached media files or the total cache size exceeds the limit you set, the SDK automatically deletes the least recently used cache file.",
    "parameters": [
      {
        "enable": "Whether to enable automatic cache file removal: true : Enable automatic cache file removal. false : (default) Disable automatic cache file removal."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_getcachedir",
    "name": "GetCacheDir",
    "description": "Gets the storage path of cached files.\n\nIf you have not called SetCacheDir to customize the cache file storage path before calling this method, it returns the default cache file storage path used by the SDK.",
    "parameters": [
      {
        "path": "Output parameter. Storage path of cached files."
      },
      {
        "length": "Input parameter. Maximum length of the cache file storage path string. Fill in based on the string obtained in path."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_getcachefilecount",
    "name": "GetCacheFileCount",
    "description": "Gets the total number of currently cached media files.",
    "parameters": [],
    "returns": "â‰¥ 0: Success. Returns the total number of currently cached media files.\n < 0: Failure. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_getmaxcachefilecount",
    "name": "GetMaxCacheFileCount",
    "description": "Gets the maximum number of cache files set.\n\nThe default maximum number of cache files in the SDK is 1000.",
    "parameters": [],
    "returns": "> 0: The method call succeeds and returns the maximum number of cache files.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_getmaxcachefilesize",
    "name": "GetMaxCacheFileSize",
    "description": "Gets the maximum total cache size of cached media files set.\n\nThe default maximum total cache size of cache files in the SDK is 1 GB. You can call the SetMaxCacheFileSize method to customize the maximum total cache size.",
    "parameters": [],
    "returns": "> 0: The method call succeeds and returns the maximum total cache size of cache files in bytes.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_getmediaplayercachemanager",
    "name": "GetMediaPlayerCacheManager",
    "description": "Gets the IMediaPlayerCacheManager instance.\n\nBefore calling other APIs under the IMediaPlayerCacheManager class, you need to call this method to get an instance of the media player cache manager. Since the media player cache manager object is a singleton, multiple calls to this method return the same instance.",
    "parameters": [],
    "returns": "IMediaPlayerCacheManager instance.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_removeallcaches",
    "name": "RemoveAllCaches",
    "description": "Deletes all cached media files in the media player.\n\nThis method does not delete cached media files that are currently playing.",
    "parameters": [],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_removecachebyuri",
    "name": "RemoveCacheByUri",
    "description": "Deletes the specified cached media file.\n\nThis method does not delete cached media files that are currently playing.",
    "parameters": [
      {
        "uri": "The URI (Uniform Resource Identifier) of the cache file to be deleted, which can be used to identify the media file."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_removeoldcache",
    "name": "RemoveOldCache",
    "description": "Deletes the least recently used cached media file in the media player.\n\nWhen cached media files occupy too much space, you can call this method to clean up cache files. After calling this method, the SDK deletes the least recently used cached media file. When you call this method to delete cached media files, the currently playing cached media file will not be deleted.",
    "parameters": [],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_setcachedir",
    "name": "SetCacheDir",
    "description": "Sets the storage path for media files to be cached.\n\nThis method must be called after initializing IRtcEngine.",
    "parameters": [
      {
        "path": "The absolute path where the cache files are stored. Make sure the specified directory exists and is writable."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_setmaxcachefilecount",
    "name": "SetMaxCacheFileCount",
    "description": "Sets the maximum number of cached media files.",
    "parameters": [
      {
        "count": "The maximum number of media files that can be cached. The default value is 1000."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_imediaplayercachemanager_setmaxcachefilesize",
    "name": "SetMaxCacheFileSize",
    "description": "Sets the maximum total cache size of cached media files.",
    "parameters": [
      {
        "cacheSize": "The maximum total cache size of cached media files in bytes. The default is 1 GB."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See MEDIA_PLAYER_REASON.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_addhandler",
    "name": "InitEventHandler",
    "description": "Adds the main callback event.\n\nThe interface class IRtcEngineEventHandler is used by the SDK to send callback event notifications to the App. The App receives SDK event notifications by inheriting methods of this interface class.\nAll methods of the interface class have default (empty) implementations. The App can choose to inherit only the events it cares about. In the callback methods, the App should not perform time-consuming operations or call APIs that may cause blocking (such as SendStreamMessage),\nas this may affect the operation of the SDK.",
    "parameters": [
      {
        "engineEventHandler": "The callback event to be added. See IRtcEngineEventHandler."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_addvideowatermark1",
    "name": "AddVideoWatermark [1/3]",
    "description": "Adds a local video watermark.\n\nDeprecated Deprecated: This method is deprecated. Use AddVideoWatermark [3/3] instead. This method adds a PNG image as a watermark to the local published live video stream. Users in the same live channel, CDN audience, and even capture devices can see or capture the watermark image. If you only want to add a watermark in CDN streaming, refer to the usage described in StartRtmpStreamWithTranscoding.\n The definition of URL differs between local live streaming and CDN streaming. In local live streaming, the URL refers to the absolute/relative local path of the image on the local video; in CDN streaming, the URL refers to the address of the image on the CDN stream.\n The source file format of the image to be added must be PNG. If the size of the PNG image differs from the size set in this method, the SDK will crop the PNG image to match the settings.\n Only one watermark is supported in the live video stream. Adding a new watermark will replace the previous one.",
    "parameters": [
      {
        "watermark": "The watermark image to be added to the local live stream: RtcImage."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_addvideowatermark2",
    "name": "AddVideoWatermark [2/3]",
    "description": "Adds a local video watermark.\n\nDeprecated Deprecated: This method is deprecated. Use addVideoWatermark [3/3] instead. This method adds a PNG image as a watermark to the local published live video stream. Users in the same live channel, CDN audience, and capture devices can see or capture the watermark image. Currently, only one watermark is supported in the live video stream. Adding a new watermark will replace the previous one.\nThe watermark coordinates depend on the settings in SetVideoEncoderConfiguration :\n If the video orientation (ORIENTATION_MODE) is fixed to landscape or adaptive landscape, landscape coordinates are used.\n If the video orientation is fixed to portrait or adaptive portrait, portrait coordinates are used.\n When setting watermark coordinates, the image area must not exceed the video dimensions set in SetVideoEncoderConfiguration, otherwise the excess will be cropped.\n You must call this method after calling EnableVideo.\n If you only want to add a watermark in CDN streaming, you can use this method or StartRtmpStreamWithTranscoding to set the watermark.\n The watermark image must be in PNG format. This method supports all PNG pixel formats: RGBA, RGB, Palette, Gray, and Alpha_gray.\n If the size of the PNG image differs from the size set in this method, the SDK will scale or crop the image to match the settings.\n If local video is set to mirror mode, the local watermark will also be mirrored. To avoid mirrored watermark for local users, it is recommended not to use both mirror and watermark features together. Implement watermark at the application layer instead.",
    "parameters": [
      {
        "watermarkUrl": "The local path of the watermark image to be added. This method supports adding watermark images from absolute/relative local paths."
      },
      {
        "options": "Settings for the watermark image. See WatermarkOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_addvideowatermark3",
    "name": "AddVideoWatermark [3/3]",
    "description": "Adds a watermark image to the local video stream.\n\nSince Available since v4.6.2. You can use this method to overlay a watermark image onto the local video stream, and configure its position, size, and visibility in the preview using WatermarkConfig.",
    "parameters": [
      {
        "configs": "Watermark configuration. See WatermarkConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustaudiomixingplayoutvolume",
    "name": "AdjustAudioMixingPlayoutVolume",
    "description": "Adjusts the local playback volume of the music file.",
    "parameters": [
      {
        "volume": "The volume of the music file. The range is [0,100], where 100 (default) is the original volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustaudiomixingpublishvolume",
    "name": "AdjustAudioMixingPublishVolume",
    "description": "Adjusts the remote playback volume of the music file.\n\nThis method adjusts the playback volume of the mixed music file on the remote end.",
    "parameters": [
      {
        "volume": "The volume of the music file. The range is [0,100], where 100 (default) is the original volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustaudiomixingvolume",
    "name": "AdjustAudioMixingVolume",
    "description": "Adjusts the playback volume of the music file.\n\nThis method adjusts the playback volume of the mixed music file on both the local and remote ends. Calling this method does not affect the playback volume of sound effects set by the PlayEffect method.",
    "parameters": [
      {
        "volume": "The volume of the music file. The range is [0,100]. 100 (default) represents the original volume of the file."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustcustomaudioplayoutvolume",
    "name": "AdjustCustomAudioPlayoutVolume",
    "description": "Adjusts the playback volume of a custom audio capture track locally.\n\nAfter calling this method to set the local playback volume of the audio, if you want to readjust the volume, you can call this method again. Before calling this method, make sure you have already called CreateCustomAudioTrack to create a custom audio capture track.",
    "parameters": [
      {
        "trackId": "Audio track ID. Set this parameter to the custom audio track ID returned by the CreateCustomAudioTrack method."
      },
      {
        "volume": "Playback volume of the custom captured audio, ranging from [0,100]. 0 means mute, 100 means original volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustcustomaudiopublishvolume",
    "name": "AdjustCustomAudioPublishVolume",
    "description": "Adjusts the playback volume of the custom audio capture track on the remote end.\n\nAfter calling this method to set the playback volume of the audio on the remote end, you can call it again to readjust the volume. Before calling this method, make sure you have already called the CreateCustomAudioTrack method to create a custom audio capture track.",
    "parameters": [
      {
        "trackId": "The audio track ID. Set this parameter to the custom audio track ID returned by the CreateCustomAudioTrack method."
      },
      {
        "volume": "The playback volume of the custom captured audio, ranging from [0,100]. 0 means mute, and 100 means the original volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustloopbacksignalvolume",
    "name": "AdjustLoopbackSignalVolume",
    "description": "Adjusts the volume of the signal captured by the sound card.\n\nAfter calling EnableLoopbackRecording to enable sound card capture, you can call this method to adjust the volume of the captured signal.",
    "parameters": [
      {
        "volume": "Volume range of the music file is 0~100. 100 (default) represents the original file volume."
      }
    ],
    "returns": "0: The method call succeeds\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustplaybacksignalvolume",
    "name": "AdjustPlaybackSignalVolume",
    "description": "Adjusts the playback volume of all remote users locally.\n\nThis method adjusts the signal volume of all remote users after mixing, as played locally. If you want to adjust the volume of a specific remote user locally, you are advised to call AdjustUserPlaybackSignalVolume.",
    "parameters": [
      {
        "volume": "Volume, range is [0,400].\n 0: Mute.\n 100: (Default) Original volume.\n 400: 4 times the original volume, with built-in overflow protection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustrecordingsignalvolume",
    "name": "AdjustRecordingSignalVolume",
    "description": "Adjusts the volume of the recorded audio signal.\n\nIf you only need to mute the audio signal, it is recommended to use MuteRecordingSignal.",
    "parameters": [
      {
        "volume": "Volume, range is [0,400].\n 0: Mute.\n 100: (Default) Original volume.\n 400: Four times the original volume, with built-in overflow protection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_adjustuserplaybacksignalvolume",
    "name": "AdjustUserPlaybackSignalVolume",
    "description": "Adjusts the playback volume of a specified remote user locally.\n\nYou can call this method during a call to adjust the playback volume of a specified remote user locally. To adjust the volume for multiple users, call this method multiple times.",
    "parameters": [
      {
        "uid": "Remote user ID."
      },
      {
        "volume": "Volume, ranging from [0,400].\n 0: Mute.\n 100: (Default) Original volume.\n 400: Four times the original volume, with built-in overflow protection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_clearvideowatermarks",
    "name": "ClearVideoWatermarks",
    "description": "Removes added video watermarks.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_complain",
    "name": "Complain",
    "description": "Report call quality issues.\n\nThis method allows users to report issues with call quality. It must be called after leaving the channel.",
    "parameters": [
      {
        "callId": "Call ID. You can obtain this parameter by calling GetCallId."
      },
      {
        "description": "(Optional) Description of the call. The length should be less than 800 bytes."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -1: General error (not specifically classified).\n -2: Invalid parameter.\n -7: IRtcEngine is not initialized before calling the method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_configrhythmplayer",
    "name": "ConfigRhythmPlayer",
    "description": "Configures the virtual metronome.\n\nDeprecated Deprecated since v4.6.2.\n After calling StartRhythmPlayer, you can call this method to reconfigure the virtual metronome.\n Once the virtual metronome is enabled, the SDK starts playing the specified audio files from the beginning and controls the duration of each file based on the beatsPerMinute setting in AgoraRhythmPlayerConfig. For example, if beatsPerMinute is set to 60, the SDK plays 1 beat per second. If the file duration exceeds the beat duration, the SDK only plays the portion of the audio corresponding to the beat duration.\n By default, the virtual metronome sound is not published to the remote. If you want remote users to hear the metronome, set publishRhythmPlayerTrack in ChannelMediaOptions to true after calling this method.",
    "parameters": [
      {
        "config": "Metronome configuration. See AgoraRhythmPlayerConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_createagorartcengine",
    "name": "CreateAgoraRtcEngine",
    "description": "Creates an IRtcEngine object.\n\nCurrently, RTC SDK v4.x supports creating only one IRtcEngine object per App.",
    "parameters": [],
    "returns": "IRtcEngine object.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_createcustomvideotrack",
    "name": "CreateCustomVideoTrack",
    "description": "Creates a custom video track.\n\nWhen you need to publish a custom captured video in the channel, refer to the following steps:\n Call this method to create a video track and get the video track ID.\n When calling JoinChannel [2/2] to join the channel, set customVideoTrackId in ChannelMediaOptions to the video track ID you want to publish, and set publishCustomVideoTrack to true.\n Call PushVideoFrame and specify videoTrackId as the video track ID set in step 2 to publish the corresponding custom video source in the channel.",
    "parameters": [],
    "returns": "The video track ID, if the method call succeeds.\n 0xffffffff, if the method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_createdatastream1",
    "name": "CreateDataStream [1/2]",
    "description": "Creates a data stream.\n\nYou can call this method to create a data stream and improve the reliability and ordering of data transmission. If you need a more comprehensive low-latency, high-concurrency, and scalable real-time messaging and state synchronization solution, we recommend using [Real-time Messaging](https://doc.shengwang.cn/doc/rtm2/unity/landing-page).\nDuring the lifecycle of IRtcEngine, each user can create up to 5 data streams. Data streams are destroyed when leaving the channel and must be recreated if needed.",
    "parameters": [
      {
        "streamId": "An output parameter. ID of the created data stream."
      },
      {
        "reliable": "Make sure to set both reliable and ordered to true or both to false. Whether to ensure data reliability, i.e., whether the receiver must receive the data within 5 seconds after it is sent: true : The receiver will receive the data within 5 seconds, otherwise the OnStreamMessageError callback is triggered with the corresponding error information. false : The receiver is not guaranteed to receive the data, and no error is reported even if the data is lost."
      },
      {
        "ordered": "Whether to ensure data ordering, i.e., whether the receiver must receive data in the order sent: true : The receiver receives data packets in the order sent by the sender. false : The receiver is not guaranteed to receive data packets in the order sent by the sender."
      }
    ],
    "returns": "0: Data stream created successfully.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_createdatastream2",
    "name": "CreateDataStream [2/2]",
    "description": "Creates a data stream.\n\nCompared with CreateDataStream [1/2], this method does not guarantee the reliability of data transmission. The receiver discards packets that are received more than 5 seconds after being sent. If you need a more comprehensive low-latency, high-concurrency, and scalable real-time messaging and state synchronization solution, we recommend using [Real-time Messaging](https://doc.shengwang.cn/doc/rtm2/unity/landing-page).\nDuring the lifecycle of IRtcEngine, each user can create up to 5 data streams. The data streams are destroyed when leaving the channel. To use them again, you need to recreate the data streams.",
    "parameters": [
      {
        "streamId": "Output parameter. The ID of the created data stream."
      },
      {
        "config": "Data stream configuration. See DataStreamConfig."
      }
    ],
    "returns": "0: Data stream created successfully.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_createmediaplayer",
    "name": "CreateMediaPlayer",
    "description": "Creates a media player object.\n\nBefore calling other APIs under the IMediaPlayer class, you must first call this method to create a media player instance. If you need multiple instances, you can call this method multiple times.",
    "parameters": [
      {
        "delegate": "Event handler for IRtcEngine. See IRtcEngineEventHandler."
      }
    ],
    "returns": "The IMediaPlayer object, if the method call succeeds.\n An empty pointer, if the method call fails.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_createvideoeffectobject",
    "name": "CreateVideoEffectObject",
    "description": "Creates an IVideoEffectObject video effect object.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "bundlePath": "The path to the video effect resource bundle."
      },
      {
        "type": "The media source type. See MEDIA_SOURCE_TYPE."
      }
    ],
    "returns": "If the method call succeeds, returns a pointer to the IVideoEffectObject. See IVideoEffectObject.\n If the method call fails, returns NULL.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_destroycustomvideotrack",
    "name": "DestroyCustomVideoTrack",
    "description": "Destroys the specified video track.",
    "parameters": [
      {
        "video_track_id": "The video track ID returned by the CreateCustomVideoTrack method."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_destroymediaplayer",
    "name": "DestroyMediaPlayer",
    "description": "Destroys the media player.",
    "parameters": [
      {
        "mediaPlayer": "IMediaPlayer object."
      }
    ],
    "returns": "â‰¥ 0: Success, returns the media player ID\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_destroyvideoeffectobject",
    "name": "DestroyVideoEffectObject",
    "description": "Destroys a video effect object.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "videoEffectObject": "The video effect object to destroy. See IVideoEffectObject."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_disableaudio",
    "name": "DisableAudio",
    "description": "Disables the audio module.\n\nThe audio module is enabled by default. You can call this method to disable it. This method resets the entire engine and has a slower response time. Therefore, Agora recommends using the following methods to control the audio module: EnableLocalAudio : Whether to enable microphone capture and create a local audio stream. EnableLoopbackRecording : Whether to enable sound card capture. MuteLocalAudioStream : Whether to publish the local audio stream. MuteRemoteAudioStream : Whether to receive and play the remote audio stream. MuteAllRemoteAudioStreams : Whether to receive and play all remote audio streams.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_disableaudiospectrummonitor",
    "name": "DisableAudioSpectrumMonitor",
    "description": "Disables audio spectrum monitoring.\n\nAfter calling EnableAudioSpectrumMonitor, if you want to disable audio spectrum monitoring, call this method. This method can be called either before or after joining a channel.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_disablevideo",
    "name": "DisableVideo",
    "description": "Disables the video module.\n\nThis method disables the video module.\n This method sets the internal engine to a disabled state and remains effective after leaving the channel.\n Calling this method resets the entire engine, which may result in a slower response. You can use the following methods to independently control specific video module features as needed: EnableLocalVideo : Whether to start camera capture and create a local video stream. MuteLocalVideoStream : Whether to publish the local video stream. MuteRemoteVideoStream : Whether to receive and play the remote video stream. MuteAllRemoteVideoStreams : Whether to receive and play all remote video streams.",
    "parameters": [],
    "returns": "0: Method call succeeded.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableaudio",
    "name": "EnableAudio",
    "description": "Enables the audio module.\n\nThe audio module is enabled by default. If you have disabled it using DisableAudio, you can call this method to re-enable it.\n Calling this method resets the entire engine and has a slower response time. You can use the following methods to control specific audio module features as needed: EnableLocalAudio : Whether to enable microphone capture and create a local audio stream. MuteLocalAudioStream : Whether to publish the local audio stream. MuteRemoteAudioStream : Whether to receive and play the remote audio stream. MuteAllRemoteAudioStreams : Whether to receive and play all remote audio streams.\n When called within a channel, this method resets the settings of EnableLocalAudio, MuteRemoteAudioStream, and MuteAllRemoteAudioStreams. Use with caution.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableaudiospectrummonitor",
    "name": "EnableAudioSpectrumMonitor",
    "description": "Enables audio spectrum monitoring.\n\nIf you want to obtain audio spectrum data of local or remote users, register an audio spectrum observer and enable audio spectrum monitoring. This method can be called either before or after joining a channel.",
    "parameters": [
      {
        "intervalInMS": "The interval (in milliseconds) at which the SDK triggers the OnLocalAudioSpectrum and OnRemoteAudioSpectrum callbacks. Default is 100 ms. The value must not be less than 10 ms, otherwise the method call will fail."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter settings.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableaudiovolumeindication",
    "name": "EnableAudioVolumeIndication",
    "description": "Enables audio volume indication.\n\nThis method allows the SDK to periodically report volume information of the local user and up to three remote users with the highest instantaneous volume to the app.",
    "parameters": [
      {
        "interval": "Sets the time interval of the volume indication:\n â‰¤ 0: Disables the volume indication.\n > 0: The interval (ms) at which the volume indication is returned. We recommend setting it to greater than 100 ms. The minimum value is 10 ms. If the value is less than 10 ms, you may not receive the OnAudioVolumeIndication callback."
      },
      {
        "smooth": "The smoothing factor that sets the sensitivity of the volume indication. The value range is [0,10], and the recommended value is 3. The greater the value, the more sensitive the indication; the smaller the value, the smoother the indication."
      },
      {
        "reportVad": "true : Enables the local voice activity detection (VAD). After it is enabled, the vad parameter in the OnAudioVolumeIndication callback reports whether voice is detected locally. false : (Default) Disables the local VAD. Except for scenarios where the engine automatically performs local VAD, the vad parameter in the OnAudioVolumeIndication callback does not report whether voice is detected locally."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablecameracenterstage",
    "name": "EnableCameraCenterStage",
    "description": "Enables or disables the Center Stage feature.\n\nThe Center Stage feature is disabled by default. You need to call this method to enable it. To disable the feature, call this method again and set enabled to false. This method is only applicable to iOS and macOS.\nDue to high performance requirements, use this feature on the following or higher performance devices:\n iPad:\n 12.9-inch iPad Pro (5th generation)\n 11-inch iPad Pro (3rd generation)\n iPad (9th generation)\n iPad mini (6th generation)\n iPad Air (5th generation)\n 2020 M1 MacBook Pro 13-inch + iPhone 11 (use iPhone as external camera for MacBook) Agora recommends calling IsCameraCenterStageSupported before enabling this feature to check if the current device supports Center Stage.",
    "parameters": [
      {
        "enabled": "Whether to enable the Center Stage feature: true : Enable Center Stage. false : Disable Center Stage."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablecontentinspect",
    "name": "EnableContentInspect",
    "description": "Enables/disables local snapshot upload.\n\nAfter enabling local snapshot upload, the SDK captures and uploads snapshots of the local user's video based on the module type and frequency you set in ContentInspectConfig. Once the snapshots are captured, Agora's server sends a callback notification to your server via an HTTPS request and uploads all snapshots to your designated third-party cloud storage.\n Before calling this method, ensure that the local snapshot upload service has been enabled in the Agora Console.\n When using Agora's proprietary plugin for content inspection (CONTENT_INSPECT_SUPERVISION), you must integrate the local snapshot upload dynamic library libagora_content_inspect_extension.dll. Deleting this library will cause the local snapshot upload feature to fail.",
    "parameters": [
      {
        "enabled": "Sets whether to enable local snapshot upload: true : Enable local snapshot upload. false : Disable local snapshot upload."
      },
      {
        "config": "Local snapshot upload configuration. See ContentInspectConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablecustomaudiolocalplayback",
    "name": "EnableCustomAudioLocalPlayback",
    "description": "Sets whether to play the external audio source locally.\n\nAfter calling this method to enable local playback of the externally captured audio source, you can call it again and set enabled to false to stop local playback.\nYou can call AdjustCustomAudioPlayoutVolume to adjust the playback volume of the custom audio capture track locally. Before calling this method, make sure you have already called the CreateCustomAudioTrack method to create a custom audio capture track.",
    "parameters": [
      {
        "trackId": "The audio track ID. Set this parameter to the custom audio track ID returned by the CreateCustomAudioTrack method."
      },
      {
        "enabled": "Whether to play the external audio source locally: true : Play locally. false : (Default) Do not play locally."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enabledualstreammode",
    "name": "EnableDualStreamMode [1/2]",
    "description": "Enables or disables dual-stream mode on the sending side.\n\nDeprecated Deprecated: Deprecated since v4.2.0. Use SetDualStreamMode [1/2] instead. Dual-stream refers to high-quality (high resolution, high frame rate) and low-quality (low resolution, low frame rate) video streams:\n High-quality stream: High resolution and high frame rate video stream.\n Low-quality stream: Low resolution and low frame rate video stream. After enabling dual-stream mode, you can call SetRemoteVideoStreamType on the receiving side to choose whether to receive the high-quality or low-quality video stream.\n This method applies to all types of streams sent by the sender, including but not limited to camera-captured video, screen sharing, and custom captured video streams.\n To enable dual-stream in multi-channel scenarios, call EnableDualStreamModeEx.\n This method can be called before or after joining a channel.",
    "parameters": [
      {
        "enabled": "Whether to enable dual-stream mode. true : Enable dual-stream mode. false : (Default) Disable dual-stream mode."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enabledualstreammode3",
    "name": "EnableDualStreamMode [2/2]",
    "description": "Enables or disables dual-stream mode on the sender and sets the low-quality video stream.\n\nDeprecated Deprecated: Deprecated since v4.2.0. Use SetDualStreamMode [2/2] instead. You can call this method on the sender to enable or disable dual-stream mode. Dual-stream refers to high-quality and low-quality video streams:\n High-quality stream: High resolution and high frame rate video stream.\n Low-quality stream: Low resolution and low frame rate video stream. After enabling dual-stream mode, you can call SetRemoteVideoStreamType on the receiver to choose to receive the high-quality or low-quality video stream.\n This method applies to all types of streams sent by the sender, including but not limited to camera-captured video streams, screen sharing streams, and custom captured video streams.\n To enable video dual-stream in multi-channel scenarios, call the EnableDualStreamModeEx method.\n This method can be called before or after joining a channel.",
    "parameters": [
      {
        "enabled": "Whether to enable dual-stream mode: true : Enable dual-stream mode. false : (Default) Disable dual-stream mode."
      },
      {
        "streamConfig": "Configuration of the low-quality video stream. See SimulcastStreamConfig. When mode is set to DISABLE_SIMULCAST_STREAM, setting streamConfig has no effect."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableencryption",
    "name": "EnableEncryption",
    "description": "Enables or disables built-in encryption.\n\nAfter a user leaves the channel, the SDK automatically disables encryption. To re-enable encryption, you need to call this method before the user rejoins the channel.\n All users in the same channel must use the same encryption mode and key when calling this method.\n When built-in encryption is enabled, the RTMP streaming feature cannot be used.",
    "parameters": [
      {
        "enabled": "Whether to enable built-in encryption: true : Enable built-in encryption. false : (default) Disable built-in encryption."
      },
      {
        "config": "Configure the built-in encryption mode and key. See EncryptionConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure\n -2: Invalid parameter. You need to specify the parameter again.\n -4: Incorrect encryption mode or failed to load external encryption library. Check the enum value or reload the external encryption library.\n -7: SDK is not initialized. You need to create the IRtcEngine object and complete initialization before calling the API.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableextension",
    "name": "EnableExtension",
    "description": "Enables/disables an extension.\n\nTo enable multiple extensions, call this method multiple times.\n After this method is successfully called, no other extensions can be loaded.",
    "parameters": [
      {
        "provider": "The name of the extension provider."
      },
      {
        "extension": "The name of the extension."
      },
      {
        "enable": "Whether to enable the extension: true : Enable the extension. false : Disable the extension."
      },
      {
        "type": "The media source type of the extension. See MEDIA_SOURCE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -3: The extension dynamic library was not loaded. Agora recommends checking whether the library is placed in the expected location or whether the library name is correct.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablefacedetection",
    "name": "EnableFaceDetection",
    "description": "Enables/disables local face detection.",
    "parameters": [
      {
        "enabled": "Whether to enable face detection: true : Enable face detection. false : (Default) Disable face detection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableinearmonitoring2",
    "name": "EnableInEarMonitoring",
    "description": "Enables in-ear monitoring.\n\nThis method enables or disables in-ear monitoring. Users must use headphones (wired or Bluetooth) to hear the in-ear monitoring effect.",
    "parameters": [
      {
        "enabled": "Enable/disable in-ear monitoring: true : Enable in-ear monitoring. false : (Default) Disable in-ear monitoring."
      },
      {
        "includeAudioFilters": "The type of audio filter for in-ear monitoring. See EAR_MONITORING_FILTER_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -8: Please ensure the current audio route is Bluetooth or headset.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableinstantmediarendering",
    "name": "EnableInstantMediaRendering",
    "description": "Enables accelerated audio and video frame rendering.\n\nAfter successfully calling this method, the SDK enables accelerated rendering for both video and audio, which speeds up the first frame rendering and audio output after a user joins the channel. Both broadcaster and audience need to call this method to enable accelerated audio and video frame rendering to experience the feature.\nOnce this method is successfully called, the only way to disable accelerated rendering is to destroy the IRtcEngine object by calling Dispose.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -7: IRtcEngine is not initialized when calling the method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablelocalaudio",
    "name": "EnableLocalAudio",
    "description": "Enables or disables local audio capture.\n\nWhen a user joins a channel, audio is enabled by default. This method can disable or re-enable local audio, i.e., stop or restart local audio capture.\nThe difference between this method and MuteLocalAudioStream is: EnableLocalAudio : Enables or disables local audio capture and processing. When you disable or enable local capture using EnableLocalAudio, local playback of remote audio will briefly interrupt. MuteLocalAudioStream : Stops or resumes sending the local audio stream without affecting the capture status.",
    "parameters": [
      {
        "enabled": "true : Re-enable local audio, i.e., start local audio capture (default); false : Disable local audio, i.e., stop local audio capture."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablelocalvideo",
    "name": "EnableLocalVideo",
    "description": "Enables or disables local video capture.\n\nThis method disables or re-enables local video capture without affecting the reception of remote video.\nAfter calling EnableVideo, local video capture is enabled by default.\nIf you call EnableLocalVideo(false) in the channel to disable local video capture, it also stops publishing the video stream in the channel. To re-enable it, call EnableLocalVideo(true), then call UpdateChannelMediaOptions and set the options parameter to publish the locally captured video stream to the channel.\nAfter successfully enabling or disabling local video capture, the remote side triggers the OnRemoteVideoStateChanged callback.\n This method can be called before or after joining a channel, but settings made before joining only take effect after joining.\n This method sets the internal engine to an enabled state and remains effective after leaving the channel.",
    "parameters": [
      {
        "enabled": "Whether to enable local video capture. true : (default) Enable local video capture. false : Disable local video capture. After disabling, the remote user will not receive the local user's video stream; however, the local user can still receive the remote user's video stream. When set to false, this method does not require the local device to have a camera."
      }
    ],
    "returns": "0: Method call succeeded.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enableloopbackrecording",
    "name": "EnableLoopbackRecording",
    "description": "Enables loopback recording.\n\nAfter enabling loopback recording, the sound played by the sound card will be mixed into the local audio stream and can be sent to the remote end.\n This method is only applicable to macOS and Windows platforms.\n It can be called before or after joining a channel.\n If you call DisableAudio to disable the audio module, loopback recording will also be disabled. To re-enable loopback recording, you must call EnableAudio to enable the audio module, then call EnableLoopbackRecording again.",
    "parameters": [
      {
        "enabled": "Whether to enable loopback recording: true : Enable loopback recording; the system sound > output interface displays the virtual sound card name. false : (Default) Disable loopback recording; the system sound > output interface does not display the virtual sound card name."
      },
      {
        "deviceName": "macOS: The device name of the virtual sound card. Default is empty, which means using the AgoraALD virtual sound card for recording.\n Windows: The device name of the sound card. Default is empty, which means using the built-in sound card of the device for recording."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablemulticamera",
    "name": "EnableMultiCamera",
    "description": "Enables or disables multi-camera capture.\n\nIn scenarios where one camera is already capturing video, Agora recommends the following steps to enable multi-camera capture and publish video:\n Call this method to enable multi-camera capture.\n Call StartPreview [2/2] to start local video preview.\n Call StartCameraCapture and set sourceType to specify the second camera for capture.\n Call JoinChannelEx and set publishSecondaryCameraTrack to true to publish the second cameraâ€™s video stream in the channel. To disable multi-camera capture:\n Call StopCameraCapture.\n Call this method and set enabled to false. This method is for iOS only. When using multi-camera video capture, ensure the system version is 13.0 or later. The minimum supported iOS devices for multi-camera capture are:\n iPhone XR\n iPhone XS\n iPhone XS Max\n iPad Pro (3rd generation and above) You can call this method before or after StartPreview [2/2] to enable multi-camera capture:\n If called before StartPreview [2/2], the local video preview shows feeds from both cameras simultaneously.\n If called after StartPreview [2/2], the SDK stops the current camera capture, then starts both the original and second camera. The preview may briefly go black before recovering automatically.",
    "parameters": [
      {
        "enabled": "Whether to enable multi-camera video capture mode: true : Enable multi-camera mode. The SDK uses multiple cameras to capture video. false : Disable multi-camera mode. The SDK uses only one camera to capture video."
      },
      {
        "config": "Capture configuration for the second camera. See CameraCapturerConfiguration."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablesoundpositionindication",
    "name": "EnableSoundPositionIndication",
    "description": "Enables/disables stereo sound for remote users.\n\nTo use SetRemoteVoicePosition to implement spatial audio positioning, make sure to call this method before joining the channel to enable stereo sound for remote users.",
    "parameters": [
      {
        "enabled": "Whether to enable stereo sound for remote users: true : Enable stereo sound. false : Disable stereo sound."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablespatialaudio",
    "name": "EnableSpatialAudio",
    "description": "Enables or disables spatial audio.\n\nAfter enabling spatial audio, you can call SetRemoteUserSpatialAudioParams to set spatial audio parameters for remote users.\n This method can be called before or after joining a channel.\n This method depends on the spatial audio dynamic library libagora_spatial_audio_extension.dll. Removing this library will prevent the feature from working properly.",
    "parameters": [
      {
        "enabled": "Whether to enable spatial audio: true : Enable spatial audio. false : Disable spatial audio."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablevideo",
    "name": "EnableVideo",
    "description": "Enables the video module.\n\nThe video module is disabled by default and must be enabled by calling this method. To disable the video module later, call the DisableVideo method.\n This method sets the internal engine to an enabled state and remains effective after leaving the channel.\n Calling this method resets the entire engine, which may result in a slower response. You can use the following methods to independently control specific video module features as needed: EnableLocalVideo : Whether to start camera capture and create a local video stream. MuteLocalVideoStream : Whether to publish the local video stream. MuteRemoteVideoStream : Whether to receive and play the remote video stream. MuteAllRemoteVideoStreams : Whether to receive and play all remote video streams.\n When this method is called in a channel, it resets the settings of EnableLocalVideo, MuteRemoteVideoStream, and MuteAllRemoteVideoStreams, so use with caution.",
    "parameters": [],
    "returns": "0: Method call succeeded.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablevideoimagesource",
    "name": "EnableVideoImageSource",
    "description": "Enables or disables placeholder image streaming.\n\nWhen publishing a video stream, you can call this method to use a custom image to replace the current video stream for streaming.\nAfter enabling this feature, you can customize the placeholder image using the ImageTrackOptions parameter. When you disable the placeholder feature, remote users will continue to see your current video stream.",
    "parameters": [
      {
        "enable": "Whether to enable placeholder image streaming: true : Enable placeholder streaming. false : (default) Disable placeholder streaming."
      },
      {
        "options": "Placeholder image settings. See ImageTrackOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablevirtualbackground",
    "name": "EnableVirtualBackground",
    "description": "Enables/disables virtual background.\n\nThe virtual background feature allows replacing the original background of the local user with a static image, dynamic video, blurred background, or segmenting the portrait from the background to achieve picture-in-picture. Once enabled successfully, all users in the channel can see the customized background.\nCall this method after EnableVideo or StartPreview [2/2].\n Using video as a virtual background may lead to continuous memory increase and could cause app crashes. Therefore, reduce the resolution and frame rate of the video whenever possible.\n This feature requires high device performance. When you call this method, the SDK automatically checks the device capability. It is recommended to use devices with the following chipsets:\n Snapdragon 700 series 750G or above\n Snapdragon 800 series 835 or above\n MediaTek Dimensity 700 series 720 or above\n Kirin 800 series 810 or above\n Kirin 900 series 980 or above\n Devices with i5 CPU or better\n Devices with A9 chip or later, including:\n iPhone 6S or later\n iPad Air 3rd generation or later\n iPad 5th generation or later\n iPad Pro 1st generation or later\n iPad mini 5th generation or later\n It is recommended to use this feature under the following conditions:\n Use a high-definition camera and ensure uniform lighting.\n The scene contains few objects, the portrait is half-body and mostly unobstructed, the background color is simple and differs from the userâ€™s clothing.\n This method depends on the virtual background dynamic library libagora_segmentation_extension.dll. If this library is deleted, the feature cannot be enabled properly.",
    "parameters": [
      {
        "enabled": "Whether to enable virtual background: true : Enable virtual background. false : Disable virtual background."
      },
      {
        "backgroundSource": "Customized background. See VirtualBackgroundSource. To adapt the resolution of the custom background image to the SDK's video capture resolution, the SDK scales and crops the image while maintaining its aspect ratio."
      },
      {
        "segproperty": "Processing properties for the background image. See SegmentationProperty."
      },
      {
        "type": "Media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When using the camera to capture local video, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -4: The device does not meet the performance requirements for virtual background. Consider using a higher-performance device.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablevoiceaituner",
    "name": "EnableVoiceAITuner",
    "description": "Enables or disables the AI tuner feature.\n\nThe AI tuner feature enhances voice quality and adjusts voice tone style.",
    "parameters": [
      {
        "enabled": "Whether to enable the AI tuner feature: true : Enable the AI tuner feature. false : (Default) Disable the AI tuner feature."
      },
      {
        "type": "AI tuner effect type. See VOICE_AI_TUNER_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_enablewebsdkinteroperability",
    "name": "EnableWebSdkInteroperability",
    "description": "Enables interoperability with the Web SDK (only applicable in live broadcast scenarios).\n\nDeprecated Deprecated: This method is deprecated. The SDK automatically enables interoperability with the Web SDK, so you do not need to call this method. This method enables or disables interoperability with the Web SDK. If a user joins the channel using the Web SDK, make sure to call this method; otherwise, the Web user will see a black screen for the Native user's video.\nThis method is only applicable in live broadcast scenarios. In communication scenarios, interoperability is enabled by default.",
    "parameters": [
      {
        "enabled": "Whether to enable interoperability with the Web SDK: true : Enable interoperability. false : (Default) Disable interoperability."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getaudiodeviceinfo",
    "name": "GetAudioDeviceInfo",
    "description": "Gets audio device information.\n\nAfter calling this method, you can check whether the audio device supports ultra-low latency capture and playback.\n This method is for Android only.\n This method can be called both before and after joining a channel.",
    "parameters": [
      {
        "deviceInfo": "Audio device information. See DeviceInfoMobile."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getaudiodevicemanager",
    "name": "GetAudioDeviceManager",
    "description": "Gets the IAudioDeviceManager object to manage audio devices.",
    "parameters": [],
    "returns": "An IAudioDeviceManager object.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getaudiomixingcurrentposition",
    "name": "GetAudioMixingCurrentPosition",
    "description": "Gets the playback progress of the music file.\n\nThis method gets the current playback progress of the music file, in milliseconds.\n You need to call this method after calling StartAudioMixing [2/2] and receiving the OnAudioMixingStateChanged(AUDIO_MIXING_STATE_PLAYING) callback.\n If you need to call GetAudioMixingCurrentPosition multiple times, make sure the interval between calls is greater than 500 ms.",
    "parameters": [],
    "returns": "â‰¥ 0: Success. Returns the current playback progress of the music file (ms). 0 indicates the music file has not started playing.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getaudiomixingduration",
    "name": "GetAudioMixingDuration",
    "description": "Gets the total duration of the music file.\n\nThis method gets the total duration of the music file, in milliseconds.",
    "parameters": [],
    "returns": "â‰¥ 0: Success. Returns the duration of the music file.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getaudiomixingplayoutvolume",
    "name": "GetAudioMixingPlayoutVolume",
    "description": "Gets the local playback volume of the music file.\n\nYou can call this method to get the local playback volume of the mixed music file, which helps troubleshoot volume-related issues.",
    "parameters": [],
    "returns": "â‰¥ 0: Success. Returns the volume value, range is [0,100].\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getaudiomixingpublishvolume",
    "name": "GetAudioMixingPublishVolume",
    "description": "Gets the remote playback volume of the music file.\n\nThis API helps developers troubleshoot volume-related issues. You need to call this method after calling StartAudioMixing [2/2] and receiving the OnAudioMixingStateChanged(AUDIO_MIXING_STATE_PLAYING) callback.",
    "parameters": [],
    "returns": "â‰¥ 0: Success. Returns the volume value, range is [0,100].\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getaudiotrackcount",
    "name": "GetAudioTrackCount",
    "description": "Gets the audio track index of the current music file.\n\nYou need to call this method after calling StartAudioMixing [2/2] and receiving the OnAudioMixingStateChanged(AUDIO_MIXING_STATE_PLAYING) callback.",
    "parameters": [],
    "returns": "On success, returns the audio track index of the current music file.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getcallid",
    "name": "GetCallId",
    "description": "Gets the call ID.\n\nEach time the client joins a channel, it generates a corresponding callId to identify the current call. You can call this method to get the callId parameter, and then pass it in when calling methods such as Rate and Complain.",
    "parameters": [
      {
        "callId": "An output parameter. The current call ID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getcameramaxzoomfactor",
    "name": "GetCameraMaxZoomFactor",
    "description": "Gets the maximum zoom factor supported by the camera.\n\nThis method is for Android and iOS only.\n You must call this method after the SDK triggers the OnLocalVideoStateChanged callback and the local video state is LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).",
    "parameters": [],
    "returns": "The maximum zoom factor supported by the device camera.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getconnectionstate",
    "name": "GetConnectionState",
    "description": "Gets the current network connection state.",
    "parameters": [],
    "returns": "The current network connection state. See CONNECTION_STATE_TYPE.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getcurrentmonotonictimeinms",
    "name": "GetCurrentMonotonicTimeInMs",
    "description": "Gets the current Monotonic Time of the SDK.\n\nMonotonic Time refers to a monotonically increasing time sequence whose value increases over time. The unit is milliseconds.\nIn scenarios such as custom video or audio capture, to ensure audio-video synchronization, Agora recommends that you call this method to get the current Monotonic Time of the SDK, and then pass this value into the timestamp parameter of the captured VideoFrame or AudioFrame.",
    "parameters": [],
    "returns": "â‰¥ 0: Success. Returns the current Monotonic Time (in milliseconds) of the SDK.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_geteffectcurrentposition",
    "name": "GetEffectCurrentPosition",
    "description": "Gets the playback progress of the specified sound effect file.\n\nYou must call this method after PlayEffect.",
    "parameters": [
      {
        "soundId": "The ID of the sound effect. Each sound effect has a unique ID."
      }
    ],
    "returns": "If the method call succeeds, returns the playback progress (in milliseconds) of the specified sound effect file.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_geteffectduration",
    "name": "GetEffectDuration",
    "description": "Gets the total duration of the specified sound effect file.\n\nYou must call this method after joining a channel.",
    "parameters": [
      {
        "filePath": "File path:\n Android: File path, including the file name and extension. Supports URL of online files, URI of local files, absolute path, or path starting with /assets/. Accessing local files via absolute path may cause permission issues. It is recommended to use URI to access local files. For example: content://com.android.providers.media.documents/document/audio%3A14441.\n Windows: Absolute path or URL of the audio file, including the file name and extension. For example: C:\\music\\audio.mp4.\n iOS or macOS: Absolute path or URL of the audio file, including the file name and extension. For example: /var/mobile/Containers/Data/audio.mp4."
      }
    ],
    "returns": "If the method call succeeds, returns the duration (in milliseconds) of the specified sound effect file.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_geteffectsvolume",
    "name": "GetEffectsVolume",
    "description": "Gets the playback volume of audio effects.\n\nThe volume range is 0~100. 100 (default) represents the original file volume. You need to call this method after PlayEffect.",
    "parameters": [],
    "returns": "The volume of the audio effect.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_geterrordescription",
    "name": "GetErrorDescription",
    "description": "Gets the warning or error description.",
    "parameters": [
      {
        "code": "The error code reported by the SDK."
      }
    ],
    "returns": "The specific error description.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getextensionproperty2",
    "name": "GetExtensionProperty",
    "description": "Gets detailed information of the extension.",
    "parameters": [
      {
        "provider": "Output parameter. The name of the extension provider."
      },
      {
        "extension": "Output parameter. The name of the extension."
      },
      {
        "key": "Output parameter. The key of the extension property."
      },
      {
        "value": "Output parameter. The value corresponding to the extension property key."
      },
      {
        "type": "The media source type of the extension. See MEDIA_SOURCE_TYPE."
      },
      {
        "buf_len": "The maximum length of the extension property JSON string. Maximum value: 512 bytes."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getfaceshapeareaoptions",
    "name": "GetFaceShapeAreaOptions",
    "description": "Gets the face shaping area options.\n\nCall this method to get the current parameter settings for the face shaping area.",
    "parameters": [
      {
        "shapeArea": "Face shaping area. See FACE_SHAPE_AREA."
      },
      {
        "options": "Face shaping area options. See FaceShapeAreaOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When using the camera to capture local video, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getfaceshapebeautyoptions",
    "name": "GetFaceShapeBeautyOptions",
    "description": "Gets the face shaping effect options.\n\nCall this method to get the current parameter settings for face shaping effects.",
    "parameters": [
      {
        "options": "Face shaping style options. See FaceShapeBeautyOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When using the camera to capture local video, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getlocalspatialaudioengine",
    "name": "GetLocalSpatialAudioEngine",
    "description": "Gets the ILocalSpatialAudioEngine object.\n\nThis method must be called after initializing the IRtcEngine object.",
    "parameters": [],
    "returns": "An ILocalSpatialAudioEngine object.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getnativehandle",
    "name": "GetNativeHandler",
    "description": "Gets the C++ handle of the Native SDK.\n\nThis method gets the C++ handle of the Native SDK engine, used in special scenarios including registering audio and video callbacks.",
    "parameters": [
      {
        "nativeHandler": "An output parameter. The native handle of the SDK engine."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getnetworktype",
    "name": "GetNetworkType",
    "description": "Gets the local network connection type.\n\nYou can call this method at any time to get the current network type in use. This method can be called before or after joining a channel.",
    "parameters": [],
    "returns": "â‰¥ 0: Success. Returns the local network connection type.\n 0: Network disconnected.\n 1: Network type is LAN.\n 2: Network type is Wi-Fi (including hotspot).\n 3: Network type is 2G mobile network.\n 4: Network type is 3G mobile network.\n 5: Network type is 4G mobile network.\n 6: Network type is 5G mobile network.\n < 0: Failure. Returns an error code.\n -1: Unknown network connection type.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getntpwalltimeinms",
    "name": "GetNtpWallTimeInMs",
    "description": "Gets the current NTP (Network Time Protocol) time.\n\nIn real-time chorus scenarios, especially when the downlink is inconsistent across receiving ends due to network issues, you can call this method to get the current NTP time as the reference time to align lyrics and music across multiple receivers, enabling chorus synchronization.",
    "parameters": [],
    "returns": "The Unix timestamp (in milliseconds) of the current NTP time.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getscreencapturesources",
    "name": "GetScreenCaptureSources",
    "description": "Gets the list of shareable screen and window objects.\n\nBefore screen or window sharing, you can call this method to get a list of shareable screen and window objects. This allows users to select a display or window to share based on the thumbnails in the list. The list includes important information such as window ID and screen ID. After obtaining the ID, you can call StartScreenCaptureByWindowId or StartScreenCaptureByDisplayId to start sharing. This method is for macOS and Windows only.",
    "parameters": [
      {
        "thumbSize": "Target size (in pixels) of the screen or window thumbnail. The SDK scales the original image to match the longest side of the target size while maintaining the aspect ratio. For example, if the original image is 400 Ã— 300 and thumbSize is 100 Ã— 100, the thumbnail size will be 100 Ã— 75. If the target size is larger than the original image, the SDK returns the original image without scaling."
      },
      {
        "iconSize": "Target size (in pixels) of the application icon. The SDK scales the original image to match the longest side of the target size while maintaining the aspect ratio. For example, if the original image is 400 Ã— 300 and iconSize is 100 Ã— 100, the icon size will be 100 Ã— 75. If the target size is larger than the original image, the SDK returns the original image without scaling."
      },
      {
        "includeScreen": "Whether the SDK returns screen information in addition to window information: true : Returns both screen and window information. false : Returns only window information."
      }
    ],
    "returns": "ScreenCaptureSourceInfo array.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getuserinfobyuid",
    "name": "GetUserInfoByUid",
    "description": "Gets user information by UID.\n\nAfter a remote user joins the channel, the SDK retrieves the UID and User Account of the remote user, then caches a mapping table of UID and User Account, and triggers the OnUserInfoUpdated callback locally. After receiving the callback, call this method with the UID to get the UserInfo object containing the specified user's User Account.",
    "parameters": [
      {
        "uid": "User ID."
      },
      {
        "userInfo": "Input and output parameter. The UserInfo object identifying the user:\n Input: A UserInfo object.\n Output: A UserInfo object containing the user's User Account and UID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getuserinfobyuseraccount",
    "name": "GetUserInfoByUserAccount",
    "description": "Gets user information by User Account.\n\nAfter a remote user joins the channel, the SDK retrieves the UID and User Account of the remote user, then caches a mapping table of UID and User Account, and triggers the OnUserInfoUpdated callback locally. After receiving the callback, call this method with the User Account to get the UserInfo object containing the specified user's UID.",
    "parameters": [
      {
        "userAccount": "User Account."
      },
      {
        "userInfo": "Input and output parameter. The UserInfo object identifying the user:\n Input: A UserInfo object.\n Output: A UserInfo object containing the user's User Account and UID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getversion",
    "name": "GetVersion",
    "description": "Gets the SDK version.",
    "parameters": [
      {
        "build": "Build number."
      }
    ],
    "returns": "The current SDK version number in string format.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getvideodevicemanager",
    "name": "GetVideoDeviceManager",
    "description": "Gets the IVideoDeviceManager object for managing video devices.",
    "parameters": [],
    "returns": "An IVideoDeviceManager object.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_getvolumeofeffect",
    "name": "GetVolumeOfEffect",
    "description": "Gets the playback volume of the specified audio effect.",
    "parameters": [
      {
        "soundId": "The ID of the audio effect."
      }
    ],
    "returns": "â‰¥ 0: Method call succeeds and returns the playback volume. The volume range is [0,100]. 100 represents the original volume.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_initialize",
    "name": "Initialize",
    "description": "Initializes IRtcEngine.\n\nAll interface functions of the IRtcEngine class are asynchronous by default unless otherwise specified. It is recommended to call the interfaces on the same thread.\nThe SDK only supports creating one IRtcEngine instance per App.",
    "parameters": [
      {
        "context": "Configuration for the IRtcEngine instance. See RtcEngineContext."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.\n -1: General error (not specifically classified).\n -2: Invalid parameter.\n -7: SDK initialization failed.\n -22: Resource allocation failed. This error occurs when the App consumes too many resources or system resources are exhausted, causing the SDK to fail in allocating resources.\n -101: Invalid App ID.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscameraautoexposurefacemodesupported",
    "name": "IsCameraAutoExposureFaceModeSupported",
    "description": "Checks whether the device supports auto exposure.",
    "parameters": [],
    "returns": "true : The device supports auto exposure. false : The device does not support auto exposure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscameraautofocusfacemodesupported",
    "name": "IsCameraAutoFocusFaceModeSupported",
    "description": "Checks whether the device supports face auto focus.\n\nThis method is only applicable to Android and iOS.\n You must call this method after the SDK triggers the OnLocalVideoStateChanged callback and the local video state returns LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).",
    "parameters": [],
    "returns": "true : The device supports face auto focus. false : The device does not support face auto focus.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscameracenterstagesupported",
    "name": "IsCameraCenterStageSupported",
    "description": "Checks whether the camera supports Center Stage.\n\nBefore calling EnableCameraCenterStage to enable Center Stage, it is recommended to call this method to check whether the current device supports this feature. This method is only applicable to iOS and macOS.",
    "parameters": [],
    "returns": "true : The current camera supports Center Stage. false : The current camera does not support Center Stage.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscameraexposurepositionsupported",
    "name": "IsCameraExposurePositionSupported",
    "description": "Checks whether the device supports manual exposure.\n\nThis method is only applicable to Android and iOS.\n You must call this method after the SDK triggers the OnLocalVideoStateChanged callback and the local video state returns LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).",
    "parameters": [],
    "returns": "true : The device supports manual exposure. false : The device does not support manual exposure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscameraexposuresupported",
    "name": "IsCameraExposureSupported",
    "description": "Checks whether the current camera supports exposure adjustment.\n\nThis method is only applicable to Android and iOS.\n You must call this method after the SDK triggers the OnLocalVideoStateChanged callback and the local video state returns LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).\n It is recommended to call this method before using SetCameraExposureFactor to adjust the exposure factor.\n This method checks whether the currently used camera supports exposure adjustment, which is the camera specified when calling SetCameraCapturerConfiguration.",
    "parameters": [],
    "returns": "true : The method call succeeds. false : The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscamerafacedetectsupported",
    "name": "IsCameraFaceDetectSupported",
    "description": "Checks whether the device camera supports face detection.\n\nThis method is only applicable to Android and iOS.\n You must call this method after the SDK triggers the OnLocalVideoStateChanged callback and the local video state returns LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).",
    "parameters": [],
    "returns": "true : The device camera supports face detection. false : The device camera does not support face detection.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscamerafocussupported",
    "name": "IsCameraFocusSupported",
    "description": "Checks whether the device supports manual focus.\n\nThis method is only applicable to Android and iOS.\n You must call this method after the SDK triggers the OnLocalVideoStateChanged callback and the local video state returns LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).",
    "parameters": [],
    "returns": "true : The device supports manual focus. false : The device does not support manual focus.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscameratorchsupported",
    "name": "IsCameraTorchSupported",
    "description": "Checks whether the device supports torch mode.\n\nThis method is only applicable to Android and iOS.\n You must call this method after the SDK triggers the OnLocalVideoStateChanged callback and the local video state returns LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).\n Generally, the app uses the front camera by default. If the front camera does not support torch mode, calling this method will return false. To check whether the rear camera supports torch mode, switch the camera using SwitchCamera before calling this method.\n On iPads with system version 15, even if IsCameraTorchSupported returns true, due to system issues, you may still fail to enable the torch using SetCameraTorchOn.",
    "parameters": [],
    "returns": "true : The device supports torch mode. false : The device does not support torch mode.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_iscamerazoomsupported",
    "name": "IsCameraZoomSupported",
    "description": "Checks whether the device supports camera zoom.\n\nThis method is only applicable to Android and iOS.",
    "parameters": [],
    "returns": "true : The device supports camera zoom. false : The device does not support camera zoom.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_isfeatureavailableondevice",
    "name": "IsFeatureAvailableOnDevice",
    "description": "Checks whether the device supports the specified advanced feature.\n\nChecks whether the current device meets the requirements for advanced features such as virtual background and beauty effects.",
    "parameters": [
      {
        "type": "The type of advanced feature. See FeatureType."
      }
    ],
    "returns": "true : The device supports the specified advanced feature. false : The device does not support the specified advanced feature.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_isspeakerphoneenabled",
    "name": "IsSpeakerphoneEnabled",
    "description": "Checks whether the speakerphone is enabled.\n\nThis method is for Android and iOS only.",
    "parameters": [],
    "returns": "true : The speakerphone is enabled, and audio is routed to the speaker. false : The speakerphone is not enabled, and audio is routed to a non-speaker device (earpiece, headset, etc.).",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_joinchannel1",
    "name": "JoinChannel [1/2]",
    "description": "Joins a channel.\n\nAfter joining a channel, by default users subscribe to all other users' audio and video streams in the channel, which generates usage and affects billing. To unsubscribe, use the corresponding mute methods.\n This method only supports joining one channel at a time.\n Apps using different App IDs cannot communicate with each other.\n Before joining a channel, ensure that the App ID used to generate the Token and the one used in Initialize are the same. Otherwise, joining the channel using the Token will fail.",
    "parameters": [
      {
        "token": "A dynamic key generated on the server for authentication. See [Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\n (Recommended) If your project enables security mode (i.e., uses APP ID + Token for authentication), this parameter is required.\n If your project only enables debug mode (i.e., uses APP ID for authentication), you can join the channel without providing a Token. You will be automatically disconnected after 24 hours.\n If you need to join multiple channels or frequently switch between channels, Agora recommends using a wildcard Token to avoid requesting a new Token from the server for each new channel. See [Wildcard Token](https://doc.shengwang.cn/doc/rtc/unity/best-practice/wildcard-token)."
      },
      {
        "channelId": "Channel name. This parameter identifies the channel for real-time audio and video interaction. Users with the same App ID and channel name will join the same channel. The parameter must be a string of up to 64 bytes. Supported character set (89 characters total):\n 26 lowercase letters a~z\n 26 uppercase letters A~Z\n 10 digits 0~9\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      },
      {
        "info": "(Optional) Reserved parameter."
      },
      {
        "uid": "User ID. This parameter identifies the user in the real-time audio and video interaction channel. You must set and manage the user ID yourself and ensure that each user ID is unique within the same channel. The parameter is a 32-bit unsigned integer. Recommended range: 1 to 2^32-1. If not specified (i.e., set to 0), the SDK automatically assigns one and returns it in the OnJoinChannelSuccess callback. The application layer must store and maintain this value as the SDK does not."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter. For example, using an illegal Token, uid not set as an integer, or invalid ChannelMediaOptions values. Provide valid parameters and rejoin the channel.\n -3: IRtcEngine initialization failed. Reinitialize the IRtcEngine object.\n -7: IRtcEngine not initialized. Initialize IRtcEngine before calling this method.\n -8: Internal state error of IRtcEngine. Possible cause: calling this method after StartEchoTest without calling StopEchoTest. Call StopEchoTest before this method.\n -17: Join channel rejected. Possible cause: user already in the channel. Use OnConnectionStateChanged to check if the user is in the channel. Unless receiving CONNECTION_STATE_DISCONNECTED (1), do not call this method again.\n -102: Invalid channel name. Provide a valid channelId and rejoin the channel.\n -121: Invalid user ID. Provide a valid uid and rejoin the channel.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_joinchannel2",
    "name": "JoinChannel [2/2]",
    "description": "Sets media options and joins a channel.\n\nCompared to JoinChannel [1/2], this method adds the options parameter to set media options, such as whether to publish audio and video streams in the channel. Whether a user automatically subscribes to all remote audio and video streams in the channel upon joining. By default, the user subscribes to all other users' audio and video streams in the channel, which incurs usage and affects billing. If you want to unsubscribe, you can do so by setting the options parameter or using the corresponding mute methods.\n This method only supports joining one channel at a time.\n Apps with different App IDs cannot communicate with each other.\n Before joining a channel, make sure the App ID used to generate the Token is the same as the one used to initialize the engine with the Initialize method; otherwise, joining the channel with the Token will fail.",
    "parameters": [
      {
        "token": "A dynamic key generated on your server for authentication. See [Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\n (Recommended) If your project has enabled secure mode (i.e., using APP ID + Token for authentication), this parameter is required.\n If your project is in debug mode only (i.e., using APP ID for authentication), you can join the channel without providing a Token. The user will automatically leave the channel after 24 hours.\n If you need to join multiple channels simultaneously or switch channels frequently, Agora recommends using a wildcard Token to avoid requesting a new Token from your server each time you join a new channel. See [Using Wildcard Token](https://doc.shengwang.cn/doc/rtc/unity/best-practice/wildcard-token)."
      },
      {
        "channelId": "Channel name. This parameter identifies the channel for real-time audio and video interaction. Users with the same App ID and channel name will join the same channel. The parameter must be a string of up to 64 bytes. Supported character set (89 characters total):\n 26 lowercase English letters a~z\n 26 uppercase English letters A~Z\n 10 digits 0~9\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      },
      {
        "uid": "User ID. This parameter identifies the user in the real-time audio and video interaction channel. You must set and manage the user ID yourself and ensure that each user ID is unique within the same channel. This parameter is a 32-bit unsigned integer. Recommended range: 1 to 2^32-1. If not specified (i.e., set to 0), the SDK automatically assigns one and returns it in the OnJoinChannelSuccess callback. The application layer must remember and manage this return value; the SDK does not maintain it."
      },
      {
        "options": "Channel media configuration options. See ChannelMediaOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting advice.\n -2: Invalid parameters. For example, using an invalid Token, uid not set as an integer, or invalid values in ChannelMediaOptions. You need to provide valid parameters and rejoin the channel.\n -3: IRtcEngine initialization failed. You need to reinitialize the IRtcEngine object.\n -7: IRtcEngine is not initialized. You must successfully initialize IRtcEngine before calling this method.\n -8: Internal state error in IRtcEngine. Possible cause: calling this method to join a channel after StartEchoTest without calling StopEchoTest. You need to call StopEchoTest before this method.\n -17: This method call was rejected. Possible cause: the user is already in the channel. Use the OnConnectionStateChanged callback to check the connection state. Do not call this method again unless you receive CONNECTION_STATE_DISCONNECTED (1).\n -102: Invalid channel name. You need to provide a valid channelId and rejoin the channel.\n -121: Invalid user ID. You need to provide a valid uid and rejoin the channel.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_joinchannelwithuseraccount1",
    "name": "JoinChannelWithUserAccount [1/2]",
    "description": "Joins a channel using a User Account and Token.\n\nBefore calling this method, if you have not called RegisterLocalUserAccount to register a User Account, the SDK will automatically create one for you when you call this method to join a channel. Calling RegisterLocalUserAccount before joining can reduce the time required to enter the channel.\nAfter successfully joining a channel, the user subscribes to all other users' audio and video streams by default, which incurs usage and affects billing. If you want to unsubscribe, you can do so by calling the corresponding mute methods. To ensure communication quality, use the same type of identifier (UID or User Account) for all users in a channel. If users join via the Web SDK, make sure they use the same identifier type.\n This method only supports joining one channel at a time.\n Apps with different App IDs cannot communicate with each other.\n Before joining a channel, make sure the App ID used to generate the Token is the same as the one used to initialize the engine with the Initialize method; otherwise, joining the channel with the Token will fail.",
    "parameters": [
      {
        "token": "A dynamic key generated on your server for authentication. See [Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\n (Recommended) If your project has enabled secure mode (i.e., using APP ID + Token for authentication), this parameter is required.\n If your project is in debug mode only (i.e., using APP ID for authentication), you can join the channel without providing a Token. The user will automatically leave the channel after 24 hours.\n If you need to join multiple channels simultaneously or switch channels frequently, Agora recommends using a wildcard Token to avoid requesting a new Token from your server each time you join a new channel. See [Using Wildcard Token](https://doc.shengwang.cn/doc/rtc/unity/best-practice/wildcard-token)."
      },
      {
        "userAccount": "User Account. This parameter identifies the user in the real-time audio and video interaction channel. You must set and manage the User Account yourself and ensure that each User Account is unique within the same channel. This parameter is required, must not exceed 255 bytes, and cannot be null. Supported character set (89 characters total):\n 26 lowercase English letters a-z\n 26 uppercase English letters A-Z\n 10 digits 0-9\n Space\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting advice.\n -2: Invalid parameters. For example, using an invalid Token, uid not set as an integer, or invalid values in ChannelMediaOptions. You need to provide valid parameters and rejoin the channel.\n -3: IRtcEngine initialization failed. You need to reinitialize the IRtcEngine object.\n -7: IRtcEngine is not initialized. You must successfully initialize IRtcEngine before calling this method.\n -8: Internal state error in IRtcEngine. Possible cause: calling this method to join a channel after StartEchoTest without calling StopEchoTest. You need to call StopEchoTest before this method.\n -17: This method call was rejected. Possible cause: the user is already in the channel. Use the OnConnectionStateChanged callback to check the connection state. Do not call this method again unless you receive CONNECTION_STATE_DISCONNECTED (1).\n -102: Invalid channel name. You need to provide a valid channelId and rejoin the channel.\n -121: Invalid user ID. You need to provide a valid uid and rejoin the channel.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_joinchannelwithuseraccount2",
    "name": "JoinChannelWithUserAccount [2/2]",
    "description": "Joins a channel using a User Account and Token, and sets channel media options.\n\nBefore calling this method, if you have not called RegisterLocalUserAccount to register a User Account, the SDK automatically creates one for you when joining the channel. Calling RegisterLocalUserAccount before this method can shorten the time to join the channel.\nCompared with JoinChannelWithUserAccount [1/2], this method adds the options parameter, which allows you to set media options when joining the channel, such as whether to publish audio and video streams. By default, a user subscribes to all other users' audio and video streams in the channel, which incurs usage and affects billing. If you want to unsubscribe, you can do so via the options parameter or corresponding mute methods. To ensure communication quality, make sure to use the same type of user identity in the channel. That is, use either UID or User Account consistently within the same channel. If users join via the Web SDK, ensure they use the same identity type.\n This method only supports joining one channel at a time.\n Apps with different App IDs cannot communicate with each other.\n Before joining a channel, ensure the App ID used to generate the Token is the same as the one used in the Initialize method. Otherwise, joining the channel with the Token will fail.",
    "parameters": [
      {
        "token": "A dynamic key generated on your server for authentication. See [Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\n (Recommended) If your project enables security mode (i.e., uses APP ID + Token for authentication), this parameter is required.\n If your project is in debug mode only (i.e., uses APP ID for authentication), you can join the channel without a Token. You will automatically leave the channel after 24 hours.\n If you need to join multiple channels or switch between them frequently, Agora recommends using a wildcard Token to avoid requesting a new Token from your server each time. See [Using Wildcard Token](https://doc.shengwang.cn/doc/rtc/unity/best-practice/wildcard-token)."
      },
      {
        "userAccount": "The User Account of the user. This parameter identifies the user in the real-time audio and video interaction channel. You need to set and manage the User Account yourself and ensure each user in the same channel has a unique User Account. This parameter is required. Maximum length is 255 bytes and cannot be null. Supported character set (89 characters total):\n 26 lowercase English letters a-z\n 26 uppercase English letters A-Z\n 10 digits 0-9\n Space\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      },
      {
        "options": "Channel media configuration options. See ChannelMediaOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggestions.\n -2: Invalid parameter. For example, an invalid Token, uid is not an integer, or ChannelMediaOptions contains invalid values. Provide valid parameters and rejoin the channel.\n -3: IRtcEngine initialization failed. Reinitialize the IRtcEngine object.\n -7: IRtcEngine not initialized. Initialize it before calling this method.\n -8: Internal state error of IRtcEngine. Possible cause: calling this method after StartEchoTest without calling StopEchoTest. Call StopEchoTest before this method.\n -17: Join channel request rejected. Possible cause: user already in channel. Use OnConnectionStateChanged to check. Do not call this method again unless receiving CONNECTION_STATE_DISCONNECTED (1).\n -102: Invalid channel name. Provide a valid channel name in channelId and rejoin.\n -121: Invalid user ID. Provide a valid UID and rejoin.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_leavechannel",
    "name": "LeaveChannel [1/2]",
    "description": "Leaves the channel.\n\nAfter calling this method, the SDK stops audio and video interactions, leaves the current channel, and releases all session-related resources.\nYou must call this method after successfully joining a channel to end the call, otherwise you cannot start a new one.\n This method is asynchronous. The return does not mean you have actually left the channel.\n If you have joined multiple channels using JoinChannelEx, calling this method leaves all joined channels. If you call Dispose immediately after this method, the SDK will not trigger the OnLeaveChannel callback.",
    "parameters": [
      {
        "leaveChannelBlock": "Callback after successfully leaving the channel, providing call statistics. See RtcStats."
      }
    ],
    "returns": "0(ERR_OK): Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggestions.\n -1: General error (not specifically classified).\n -2: Invalid parameter.\n -7: SDK not initialized.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_leavechannel2",
    "name": "LeaveChannel [2/2]",
    "description": "Sets channel options and leaves the channel.\n\nAfter calling this method, the SDK stops audio and video interactions, leaves the current channel, and releases all session-related resources.\nYou must call this method or LeaveChannel [1/2] after successfully joining a channel to end the call, otherwise you cannot start a new one. If you have joined multiple channels using JoinChannelEx, calling this method leaves all joined channels. This method is asynchronous. The return does not mean you have actually left the channel.\nIf you call Dispose immediately after this method, the SDK will not trigger the OnLeaveChannel callback.",
    "parameters": [
      {
        "options": "Options for leaving the channel. See LeaveChannelOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_loadextensionprovider",
    "name": "LoadExtensionProvider",
    "description": "Loads an extension.\n\nThis method adds external SDK extensions (such as Marketplace extensions and SDK extension plugins) to the SDK. To load multiple extensions, call this method multiple times.\nThis method applies to Windows and Android only.",
    "parameters": [
      {
        "path": "The path and name of the extension dynamic library. For example: /library/libagora_segmentation_extension.dll."
      },
      {
        "unload_after_use": "Whether to automatically unload the extension after use: true : Automatically unloads the extension when IRtcEngine is destroyed. false : Does not automatically unload the extension until the process exits (recommended)."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_muteallremoteaudiostreams",
    "name": "MuteAllRemoteAudioStreams",
    "description": "Stops or resumes subscribing to all remote users' audio streams.\n\nAfter successfully calling this method, the local user stops or resumes subscribing to all remote users' audio streams, including those who join the channel after this method is called. By default, the SDK subscribes to all remote users' audio streams when joining a channel. To change this behavior, you can set autoSubscribeAudio to false when calling JoinChannel [2/2] to join the channel, which disables audio stream subscription at join time.\nIf you call EnableAudio or DisableAudio after this method, the latter call takes effect.",
    "parameters": [
      {
        "mute": "Whether to stop subscribing to all remote users' audio streams: true : Stop subscribing to all remote users' audio streams. false : (Default) Subscribe to all remote users' audio streams."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_muteallremotevideostreams",
    "name": "MuteAllRemoteVideoStreams",
    "description": "Stops or resumes subscribing to all remote users' video streams.\n\nAfter successfully calling this method, the local user stops or resumes subscribing to all remote users' video streams, including those who join the channel after this method is called. By default, the SDK subscribes to all remote users' video streams when joining a channel. To change this behavior, you can set autoSubscribeVideo to false when calling JoinChannel [2/2] to join the channel, which disables video stream subscription at join time.\nIf you call EnableVideo or DisableVideo after this method, the latter call takes effect.",
    "parameters": [
      {
        "mute": "Whether to stop subscribing to all remote users' video streams. true : Stop subscribing to all users' video streams. false : (Default) Subscribe to all users' video streams."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_mutelocalaudiostream",
    "name": "MuteLocalAudioStream",
    "description": "Stops or resumes publishing the local audio stream.\n\nThis method controls whether to publish the locally captured audio stream. Not publishing the local audio stream does not disable the audio capture device, so it does not affect the audio capture status.",
    "parameters": [
      {
        "mute": "Whether to stop publishing the local audio stream. true : Stop publishing. false : (Default) Publish."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_mutelocalvideostream",
    "name": "MuteLocalVideoStream",
    "description": "Stops or resumes publishing the local video stream.\n\nThis method controls whether to publish the locally captured video stream. Not publishing the local video stream does not disable the video capture device, so it does not affect the video capture status.\nCompared to calling EnableLocalVideo(false) to stop local video capture and thus stop publishing, this method responds faster.",
    "parameters": [
      {
        "mute": "Whether to stop sending the local video stream. true : Stop sending the local video stream. false : (Default) Send the local video stream."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_muterecordingsignal",
    "name": "MuteRecordingSignal",
    "description": "Mutes or unmutes the recording signal.\n\nIf you have already called AdjustRecordingSignalVolume to adjust the recording signal volume, calling this method with true will cause the SDK to:\n Record the adjusted volume.\n Mute the recording signal. When you call this method again with false, the recording signal will be restored to the volume recorded by the SDK before muting.",
    "parameters": [
      {
        "mute": "true : Mute. false : (Default) Original volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_muteremoteaudiostream",
    "name": "MuteRemoteAudioStream",
    "description": "Stops or resumes subscribing to the specified remote user's audio stream.",
    "parameters": [
      {
        "uid": "The user ID of the specified user."
      },
      {
        "mute": "Whether to stop subscribing to the specified remote user's audio stream. true : Stop subscribing to the specified user's audio stream. false : (Default) Subscribe to the specified user's audio stream."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_muteremotevideostream",
    "name": "MuteRemoteVideoStream",
    "description": "Stops or resumes subscribing to the video stream of a specified remote user.",
    "parameters": [
      {
        "uid": "The user ID of the specified user."
      },
      {
        "mute": "Whether to stop subscribing to the video stream of the specified remote user. true : Stop subscribing to the video stream of the specified user. false : (Default) Subscribe to the video stream of the specified user."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_pauseallchannelmediarelay",
    "name": "PauseAllChannelMediaRelay",
    "description": "Pauses media stream forwarding to all destination channels.\n\nAfter starting to forward media streams across channels, if you need to pause forwarding to all channels, you can call this method. To resume forwarding, call the ResumeAllChannelMediaRelay method. You must call this method after calling StartOrUpdateChannelMediaRelay to start cross-channel media stream forwarding.",
    "parameters": [],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -5: This method call was rejected. No cross-channel media stream forwarding is currently in progress.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_pausealleffects",
    "name": "PauseAllEffects",
    "description": "Pauses playback of all audio effects.",
    "parameters": [],
    "returns": "0: Method call succeeds.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_pauseaudiomixing",
    "name": "PauseAudioMixing",
    "description": "Pauses the playback of the music file.\n\nAfter calling the StartAudioMixing [2/2] method to play a music file, if you want to pause playback, call this method. If you want to stop playback, call StopAudioMixing.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_pauseeffect",
    "name": "PauseEffect",
    "description": "Pauses playback of the audio effect.",
    "parameters": [
      {
        "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_playalleffects",
    "name": "PlayAllEffects",
    "description": "Plays all audio effects.\n\nAfter calling PreloadEffect multiple times to preload several audio effects, you can call this method to play all preloaded audio effects.",
    "parameters": [
      {
        "loopCount": "The number of times the audio effect loops:\n -1: Loops indefinitely until StopEffect or StopAllEffects is called.\n 0: Plays the audio effect once.\n 1: Plays the audio effect twice."
      },
      {
        "pitch": "The pitch of the audio effect. The range is [0.5,2.0]. Default is 1.0, which represents the original pitch. The smaller the value, the lower the pitch."
      },
      {
        "pan": "The spatial position of the audio effect. The range is [-1.0,1.0]:\n -1.0: Audio appears on the left.\n 0: Audio appears in the center.\n 1.0: Audio appears on the right."
      },
      {
        "gain": "The volume of the audio effect. The range is [0,100]. 100 is the default and represents the original volume. The smaller the value, the lower the volume."
      },
      {
        "publish": "Whether to publish the audio effect to remote users: true : Publishes the audio effect to remote users. Both local and remote users can hear it. false : (Default) Does not publish the audio effect to remote users. Only the local user can hear it."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_playeffect3",
    "name": "PlayEffect",
    "description": "Plays the specified local or online audio effect.\n\nYou can call this method multiple times with different soundID and filePath values to play multiple audio effects simultaneously. For optimal user experience, it is recommended not to play more than 3 audio effects at the same time. If you need to play an online audio effect, Agora recommends caching the online file to the local device, preloading it into memory using PreloadEffect, and then calling this method to play it. Otherwise, playback may fail or be silent due to loading timeouts or failures.",
    "parameters": [
      {
        "soundId": "The ID of the audio effect. Each audio effect has a unique ID. If you have loaded the audio effect into memory using PreloadEffect, ensure this parameter matches the soundId set in PreloadEffect."
      },
      {
        "filePath": "The file path to play. Supports online URLs and absolute paths to local files, including the file name and extension. Supported audio formats include MP3, AAC, M4A, MP4, WAV, 3GP, etc. If you have loaded the audio effect into memory using PreloadEffect, ensure this parameter matches the filePath set in PreloadEffect."
      },
      {
        "loopCount": "The number of times the audio effect loops.\n â‰¥ 0: Number of loops. For example, 1 means loop once, i.e., play twice in total.\n -1: Loop indefinitely."
      },
      {
        "pitch": "The pitch of the audio effect. The range is [0.5,2.0]. Default is 1.0, which represents the original pitch. The smaller the value, the lower the pitch."
      },
      {
        "pan": "The spatial position of the audio effect. The range is [-1.0,1.0], for example:\n -1.0: Audio appears on the left\n 0.0: Audio appears in the center\n 1.0: Audio appears on the right"
      },
      {
        "gain": "The volume of the audio effect. The range is [0.0,100.0]. Default is 100.0, which represents the original volume. The smaller the value, the lower the volume."
      },
      {
        "publish": "Whether to publish the audio effect to remote users: true : Publishes the audio effect to remote users. Both local and remote users can hear it. false : Does not publish the audio effect to remote users. Only the local user can hear it."
      },
      {
        "startPos": "The playback position of the audio effect in milliseconds."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_preloadchannel",
    "name": "PreloadChannel",
    "description": "Preloads a channel using token, channelId, and uid.\n\nCalling this method can reduce the time it takes for a viewer to join a channel when frequently switching channels, thereby shortening the time to hear the first frame of audio or see the first frame of video from the host and improving the viewer's video experience.\nIf the channel has already been successfully preloaded, and the viewer leaves and rejoins the same channel, as long as the Token used during preloading is still valid, preloading does not need to be performed again. If preloading fails, it does not affect the subsequent normal channel join process, nor does it increase the time to join the channel.\n When calling this method, make sure the user role is set to audience and the audio scenario is not set to chorus (AUDIO_SCENARIO_CHORUS), otherwise preloading will not take effect.\n Ensure that the channel name, user ID, and Token passed in during preloading are the same as those used when joining the channel later, otherwise preloading will not take effect.\n Currently, one IRtcEngine instance supports preloading up to 20 channels. If this limit is exceeded, only the most recently preloaded 20 channels take effect.",
    "parameters": [
      {
        "token": "A dynamic key generated on your server for authentication. See [Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\nWhen the Token expires, depending on the number of preloaded channels, you can provide a new Token in different ways:\n Preloading a single channel: call this method with the new Token.\n Preloading multiple channels:\n If you use a wildcard Token, call UpdatePreloadChannelToken to update the Token for all preloaded channels. When generating a wildcard Token, the user ID must not be 0. See [Using Wildcard Tokens](https://doc.shengwang.cn/doc/rtc/unity/best-practice/wildcard-token).\n If you use different Tokens: call this method with your user ID, corresponding channel name, and the updated Token."
      },
      {
        "channelId": "The name of the channel to preload. This parameter identifies the channel for real-time audio and video interaction. Users with the same App ID and channel name will enter the same channel for interaction.\nThis parameter is a string up to 64 bytes in length. The supported character set (89 characters total) includes:\n 26 lowercase letters aâ€“z\n 26 uppercase letters Aâ€“Z\n 10 digits 0â€“9\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      },
      {
        "uid": "User ID. This parameter identifies the user in the real-time audio and video interaction channel. You need to set and manage the user ID yourself and ensure that each user ID in the same channel is unique. This parameter is a 32-bit unsigned integer. Recommended range: 1 to 2^32 - 1. If not specified (i.e., set to 0), the SDK will automatically assign one and return it in the OnJoinChannelSuccess callback. The application must store and maintain this return value, as the SDK does not manage it."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -7: The IRtcEngine object is not initialized. You need to initialize the IRtcEngine object successfully before calling this method.\n -102: Invalid channel name. You need to provide a valid channel name and rejoin the channel.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_preloadchannelwithuseraccount",
    "name": "PreloadChannelWithUserAccount",
    "description": "Preloads a channel using token, channelId, and userAccount.\n\nCalling this method can reduce the time it takes for a viewer to join a channel when frequently switching channels, thereby shortening the time to hear the first frame of audio or see the first frame of video from the host and improving the viewer's video experience.\nIf the channel has already been successfully preloaded, and the viewer leaves and rejoins the same channel, as long as the Token used during preloading is still valid, preloading does not need to be performed again. If preloading fails, it does not affect the subsequent normal channel join process, nor does it increase the time to join the channel.\n When calling this method, make sure the user role is set to audience and the audio scenario is not set to chorus (AUDIO_SCENARIO_CHORUS), otherwise preloading will not take effect.\n Ensure that the channel name, user userAccount, and Token passed in during preloading are the same as those used when joining the channel later, otherwise preloading will not take effect.\n Currently, one IRtcEngine instance supports preloading up to 20 channels. If this limit is exceeded, only the most recently preloaded 20 channels take effect.",
    "parameters": [
      {
        "token": "A dynamic key generated on your server for authentication. See [Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\nWhen the Token expires, depending on the number of preloaded channels, you can provide a new Token in different ways:\n Preloading a single channel: call this method with the new Token.\n Preloading multiple channels:\n If you use a wildcard Token, call UpdatePreloadChannelToken to update the Token for all preloaded channels. When generating a wildcard Token, the user ID must not be 0. See [Using Wildcard Tokens](https://doc.shengwang.cn/doc/rtc/unity/best-practice/wildcard-token).\n If you use different Tokens: call this method with your user ID, corresponding channel name, and the updated Token."
      },
      {
        "channelId": "The name of the channel to preload. This parameter identifies the channel for real-time audio and video interaction. Users with the same App ID and channel name will enter the same channel for interaction.\nThis parameter is a string up to 64 bytes in length. The supported character set (89 characters total) includes:\n 26 lowercase letters aâ€“z\n 26 uppercase letters Aâ€“Z\n 10 digits 0â€“9\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      },
      {
        "userAccount": "User userAccount. This parameter identifies the user in the real-time audio and video interaction channel. You need to set and manage the userAccount yourself and ensure that each userAccount in the same channel is unique. This parameter is required, must not exceed 255 bytes, and cannot be NULL. The supported character set (89 characters total) includes:\n 26 lowercase letters aâ€“z\n 26 uppercase letters Aâ€“Z\n 10 digits 0â€“9\n space\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter. For example, userAccount is empty. You need to provide a valid parameter and rejoin the channel.\n -7: The IRtcEngine object is not initialized. You need to initialize the IRtcEngine object successfully before calling this method.\n -102: Invalid channel name. You need to provide a valid channel name and rejoin the channel.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_preloadeffect",
    "name": "PreloadEffect",
    "description": "Loads the audio effect into memory.\n\nTo ensure smooth communication, pay attention to the size of the preloaded audio effect file.\nSupported audio formats for preloading can be found in [What audio formats does the RTC SDK support for playback](https://doc.shengwang.cn/faq/general-product-inquiry/audio-format).",
    "parameters": [
      {
        "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
      },
      {
        "filePath": "File path:\n Android: File path including file name and extension. Supports online URLs, local file URI, absolute paths, or paths starting with /assets/. Accessing local files via absolute paths may cause permission issues. It is recommended to use URI, e.g., content://com.android.providers.media.documents/document/audio%3A14441.\n Windows: Absolute path or URL of the audio file, including file name and extension. For example, C:\\music\\audio.mp4.\n iOS or macOS: Absolute path or URL of the audio file, including file name and extension. For example, /var/mobile/Containers/Data/audio.mp4."
      },
      {
        "startPos": "The start position for loading the audio effect, in milliseconds."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_querycamerafocallengthcapability",
    "name": "QueryCameraFocalLengthCapability",
    "description": "Queries the focal length capabilities supported by the camera.\n\nTo enable wide-angle or ultra-wide-angle camera modes, it is recommended to call this method first to check whether the device supports the corresponding focal length capabilities. Then, based on the result, call SetCameraCapturerConfiguration to adjust the focal length configuration for optimal camera capture performance. This method is only applicable to Android and iOS.",
    "parameters": [
      {
        "focalLengthInfos": "Output parameter. After execution, returns an array of FocalLengthInfo objects containing the camera focal length information."
      },
      {
        "size": "Output parameter. After execution, returns the number of focal length entries found."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_querycodeccapability",
    "name": "QueryCodecCapability",
    "description": "Queries the video codec capabilities supported by the SDK.",
    "parameters": [
      {
        "codecInfo": "Input and output parameter, representing the array of video codec capabilities supported by the SDK. See CodecCapInfo.\n Input: The CodecCapInfo defined by the user when calling this method, indicating the video codec capabilities to query.\n Output: The CodecCapInfo returned after the method execution, indicating the actual video codec capabilities supported by the SDK."
      },
      {
        "size": "Input and output parameter, indicating the size of the CodecCapInfo array.\n Input: The size of CodecCapInfo defined by the user when calling this method.\n Output: The size of CodecCapInfo returned after the method execution."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_querydevicescore",
    "name": "QueryDeviceScore",
    "description": "Queries the device score level.",
    "parameters": [],
    "returns": "> 0: The method call succeeds. The value indicates the current device score level, ranging from [0,100]. A higher value indicates better device capability. Most devices score between 60 and 100.\n < 0: The method call fails.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_queryscreencapturecapability",
    "name": "QueryScreenCaptureCapability",
    "description": "Queries the maximum supported frame rate for screen sharing on the device.",
    "parameters": [],
    "returns": "On success, returns the maximum supported frame rate. See SCREEN_CAPTURE_FRAMERATE_CAPABILITY.\n <0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_rate",
    "name": "Rate",
    "description": "Rates the call.\n\nYou must call this method after the user leaves the channel.",
    "parameters": [
      {
        "callId": "Call ID. You can get this parameter by calling GetCallId."
      },
      {
        "rating": "Rating for the call, ranging from 1 (lowest) to 5 (highest)."
      },
      {
        "description": "(Optional) Description of the call. The length should be less than 800 bytes."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -1: General error (not specifically categorized).\n -2: Invalid parameter.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_registeraudioencodedframeobserver",
    "name": "RegisterAudioEncodedFrameObserver",
    "description": "Registers an audio encoded frame observer.\n\nCall this method after joining a channel.\n Since this method and StartAudioRecording [3/3] both configure audio content and quality, it is not recommended to use them together. Otherwise, only the one called later takes effect.",
    "parameters": [
      {
        "config": "Observer configuration for encoded audio. See AudioEncodedFrameObserverConfig."
      },
      {
        "observer": "Observer for encoded audio. See IAudioEncodedFrameObserver."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_registeraudiospectrumobserver",
    "name": "RegisterAudioSpectrumObserver",
    "description": "Registers an audio spectrum observer.\n\nAfter successfully registering the audio spectrum observer and calling EnableAudioSpectrumMonitor to enable audio spectrum monitoring, the SDK reports callbacks you implement in the IAudioSpectrumObserver class at the interval you set. This method can be called either before or after joining a channel.",
    "parameters": [
      {
        "observer": "Audio spectrum observer. See IAudioSpectrumObserver."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_registerextension",
    "name": "RegisterExtension",
    "description": "Registers an extension.\n\nFor external SDK extensions (such as Marketplace extensions and SDK extension plugins), after loading the extension, you need to call this method to register it. Internal SDK extensions (included in the SDK package) are automatically loaded and registered after IRtcEngine is initialized, and do not require this method.\n To register multiple extensions, call this method multiple times.\n The order in which different extensions process data in the SDK is determined by the registration order. That is, extensions registered earlier process data first.",
    "parameters": [
      {
        "provider": "The name of the extension provider."
      },
      {
        "extension": "The name of the extension."
      },
      {
        "type": "The media source type of the extension. See MEDIA_SOURCE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -3: The extension dynamic library was not loaded. Agora recommends checking whether the library is placed in the expected location or whether the library name is correct.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_registerlocaluseraccount",
    "name": "RegisterLocalUserAccount",
    "description": "Registers a local user userAccount.\n\nThis method registers a userAccount for the local user. Once registered successfully, the userAccount can be used to identify the local user and join a channel.\nThis method is optional. If you want users to join a channel using a userAccount, you can choose either of the following approaches:\n First call RegisterLocalUserAccount to register the account, then call JoinChannelWithUserAccount [1/2] or JoinChannelWithUserAccount [2/2] to join the channel, which can reduce the time to enter the channel.\n Directly call JoinChannelWithUserAccount [1/2] or JoinChannelWithUserAccount [2/2] to join the channel.\n Ensure the userAccount set in this method is unique within the channel.\n To ensure communication quality, make sure all users in the same channel use the same type of identifier (either UID or userAccount). If users join via Web SDK, ensure they use the same type as well.",
    "parameters": [
      {
        "appId": "The App ID of your project registered in the console."
      },
      {
        "userAccount": "User userAccount. This parameter identifies the user in the real-time audio and video interaction channel. You need to set and manage the userAccount yourself and ensure that each userAccount in the same channel is unique. This parameter is required, must not exceed 255 bytes, and cannot be NULL. The supported character set (89 characters total) includes:\n 26 lowercase letters aâ€“z\n 26 uppercase letters Aâ€“Z\n 10 digits 0â€“9\n space\n \"!\", \"#\", \"$\", \"%\", \"&\", \"(\", \")\", \"+\", \"-\", \":\", \";\", \"<\", \"=\", \".\", \">\", \"?\", \"@\", \"[\", \"]\", \"^\", \"_\", \"{\", \"}\", \"|\", \"~\", \",\""
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_registermediametadataobserver",
    "name": "RegisterMediaMetadataObserver",
    "description": "Registers a media metadata observer to receive or send metadata.\n\nYou need to implement the IMetadataObserver class and specify the metadata type in this method. This method allows you to add synchronized metadata to the video stream for interactive live streaming scenarios, such as sending shopping links, e-coupons, or online quizzes. Call this method before JoinChannel [2/2].",
    "parameters": [
      {
        "observer": "The metadata observer. See IMetadataObserver."
      },
      {
        "type": "The metadata type. Currently only VIDEO_METADATA is supported. See METADATA_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_release",
    "name": "Dispose",
    "description": "Destroys the IRtcEngine object.\n\nThis method releases all resources used by the SDK. Some Apps only use real-time audio and video communication when needed and release resources when not needed. This method is suitable for such scenarios.\nAfter calling this method, you can no longer use other SDK methods or callbacks. To use real-time audio and video communication again, you must call CreateAgoraRtcEngine and Initialize in sequence to create a new IRtcEngine object.\n This method is a synchronous call. You must wait for the IRtcEngine resources to be released before performing other operations (e.g., creating a new IRtcEngine object). Therefore, it is recommended to call this method in a sub-thread to avoid blocking the main thread.\n It is not recommended to call Dispose inside SDK callbacks. Otherwise, since the SDK waits for the callback to return before reclaiming related object resources, it may cause a deadlock.",
    "parameters": [
      {
        "sync": "Whether this method is called synchronously: true : The method is synchronous. false : The method is asynchronous. Currently, only synchronous calls are supported. Do not set this parameter to this value."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_removevideowatermark",
    "name": "RemoveVideoWatermark",
    "description": "Removes a watermark image from the local video.\n\nSince Available since v4.6.2. This method removes the previously added watermark image from the local video stream based on the specified unique ID.",
    "parameters": [
      {
        "id": "The ID of the watermark to be removed. This value must be the same as the ID used when the watermark was added."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_renewtoken",
    "name": "RenewToken",
    "description": "Renews the Token.\n\nThis method is used to renew the Token. The Token will expire after a certain period, at which point the SDK will be unable to connect to the server.",
    "parameters": [
      {
        "token": "The newly generated Token."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter. For example, the Token is empty.\n -7: The IRtcEngine object is not initialized. You need to initialize the IRtcEngine object successfully before calling this method.\n -110: Invalid Token. Please ensure:\n The user ID specified when generating the Token matches the one used to join the channel,\n The generated Token matches the one used to join the channel.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_resumeallchannelmediarelay",
    "name": "ResumeAllChannelMediaRelay",
    "description": "Resumes media stream forwarding to all destination channels.\n\nAfter calling the PauseAllChannelMediaRelay method, if you need to resume forwarding to all destination channels, you can call this method. You must call this method after PauseAllChannelMediaRelay.",
    "parameters": [],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -5: This method call was rejected. No cross-channel media stream forwarding is currently paused.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_resumealleffects",
    "name": "ResumeAllEffects",
    "description": "Resumes playback of all audio effect files.\n\nAfter you call PauseAllEffects to pause all audio effect files, you can call this method to resume playback.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_resumeaudiomixing",
    "name": "ResumeAudioMixing",
    "description": "Resumes the playback of the music file.\n\nAfter calling PauseAudioMixing to pause the playback of a music file, call this method to resume playback.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_resumeeffect",
    "name": "ResumeEffect",
    "description": "Resumes playback of the specified audio effect file.",
    "parameters": [
      {
        "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_selectaudiotrack",
    "name": "SelectAudioTrack [1/2]",
    "description": "Specifies the audio track to play in the current music file.\n\nAfter retrieving the number of audio tracks in the music file, you can call this method to specify any track for playback. For example, if different tracks in a multi-track file contain songs in different languages, you can call this method to set the playback language of the music file.\n For supported audio file formats, see [What audio formats does the RTC SDK support for playback?](https://doc.shengwang.cn/faq/general-product-inquiry/audio-format).\n You need to call this method after calling StartAudioMixing [2/2] and receiving the OnAudioMixingStateChanged(AUDIO_MIXING_STATE_PLAYING) callback.",
    "parameters": [
      {
        "index": "The specified audio track to play. The value must be greater than or equal to 0 and less than the return value of GetAudioTrackCount."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_sendcustomreportmessage",
    "name": "SendCustomReportMessage",
    "description": "Sends a custom report message.\n\nAgora provides custom data reporting and analytics services. This service is currently in a free beta period. During the beta, you can report up to 10 data entries within 6 seconds. Each custom data entry must not exceed 256 bytes, and each string must not exceed 100 bytes. To try this service, please [contact sales](https://www.shengwang.cn/contact-sales/) to enable it and agree on the custom data format.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_sendmetadata",
    "name": "SendMetadata",
    "description": "Sends media metadata.\n\nIf the media metadata is successfully sent, the receiver receives the OnMetadataReceived callback.",
    "parameters": [
      {
        "metadata": "Media metadata. See Metadata."
      },
      {
        "source_type": "Type of the video source. See VIDEO_SOURCE_TYPE."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_sendstreammessage",
    "name": "SendStreamMessage",
    "description": "Sends a data stream.\n\nAfter calling CreateDataStream [2/2], you can call this method to send data stream messages to all users in the channel.\nThe SDK imposes the following restrictions on this method:\n Each client in the channel can have up to 5 data channels simultaneously, and the total sending bitrate shared by all data channels is limited to 30 KB/s.\n Each data channel can send up to 60 packets per second, with each packet up to 1 KB in size. After the method is successfully called, the remote end triggers the OnStreamMessage callback, where remote users can retrieve the received stream message; if the call fails, the remote end triggers the OnStreamMessageError callback. If you need a more comprehensive low-latency, high-concurrency, and scalable real-time messaging and state synchronization solution, we recommend using [Real-time Messaging](https://doc.shengwang.cn/doc/rtm2/unity/landing-page).\n This method must be called after joining a channel and after calling CreateDataStream [2/2] to create the data channel.\n This method applies to broadcaster users only.",
    "parameters": [
      {
        "streamId": "Data stream ID. You can obtain it through CreateDataStream [2/2]."
      },
      {
        "data": "The data to be sent."
      },
      {
        "length": "Length of the data."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setadvancedaudiooptions",
    "name": "SetAdvancedAudioOptions",
    "description": "Sets advanced audio options.\n\nIf you have advanced audio processing needs, such as capturing and sending stereo audio, you can call this method to set advanced audio options. You need to call this method before JoinChannel [2/2], EnableAudio, and EnableLocalAudio.",
    "parameters": [
      {
        "options": "Advanced audio options. See AdvancedAudioOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setainsmode",
    "name": "SetAINSMode",
    "description": "Enables or disables the AI noise reduction feature and sets the noise reduction mode.\n\nYou can call this method to enable the AI noise reduction feature. This feature intelligently detects and reduces various steady-state and non-steady-state noises in the surrounding environment while ensuring voice quality, making the voice clearer.\nSteady-state noise refers to noise with the same frequency at any point in time. Common steady-state noises include:\n TV noise\n Air conditioner noise\n Factory machine noise Non-steady-state noise refers to noise that changes rapidly over time. Common non-steady-state noises include:\n Thunder\n Explosion sounds\n Cracking sounds\n This method depends on the AI noise reduction dynamic library. If the library is removed, the feature cannot be enabled properly. See [Plugin List](https://doc.shengwang.cn/doc/rtc/unity/best-practice/reduce-app-size#%E6%8F%92%E4%BB%B6%E5%88%97%E8%A1%A8) for the library name.\n It is currently not recommended to enable this feature on devices running Android 6.0 or lower.",
    "parameters": [
      {
        "enabled": "Whether to enable the AI noise reduction feature: true : Enable the AI noise reduction feature. false : (Default) Disable the AI noise reduction feature."
      },
      {
        "mode": "Noise reduction mode. See AUDIO_AINS_MODE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudioeffectparameters",
    "name": "SetAudioEffectParameters",
    "description": "Sets parameters for SDK preset voice effects.\n\nCall this method to configure the following for local sending users:\n 3D voice effect: Set the surround cycle for the 3D voice effect.\n Pitch correction effect: Set the base scale and main pitch. To allow users to adjust pitch correction easily, it is recommended to bind the base scale and main pitch options to your app's UI elements. After setting, all users in the channel can hear the effect. To achieve better voice effects, it is recommended to do the following before calling this method:\n Call SetAudioScenario to set the audio scenario to high-quality, i.e., AUDIO_SCENARIO_GAME_STREAMING (3).\n Call SetAudioProfile [2/2] and set profile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY (4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5).\n This method can be called before or after joining a channel.\n Do not set the profile parameter of SetAudioProfile [2/2] to AUDIO_PROFILE_SPEECH_STANDARD (1) or AUDIO_PROFILE_IOT (6), otherwise this method will not take effect.\n This method is best suited for processing voice and is not recommended for processing audio that contains music.\n After calling SetAudioEffectParameters, do not call the following methods, or the effect set by SetAudioEffectParameters will be overridden: SetAudioEffectPreset SetVoiceBeautifierPreset SetLocalVoicePitch SetLocalVoiceEqualization SetLocalVoiceReverb SetVoiceBeautifierParameters SetVoiceConversionPreset\n This method depends on the voice beautifier dynamic library libagora_audio_beauty_extension.dll. If the library is removed, the feature cannot be enabled properly.",
    "parameters": [
      {
        "preset": "SDK preset effects. Supported values: ROOM_ACOUSTICS_3D_VOICE : 3D voice effect.\n Before using this enum, you must set the profile parameter of SetAudioProfile [2/2] to AUDIO_PROFILE_MUSIC_STANDARD_STEREO (3) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5), otherwise the setting is invalid.\n To hear the expected effect, users must use audio playback devices that support stereo. PITCH_CORRECTION : Pitch correction effect."
      },
      {
        "param1": "If preset is set to ROOM_ACOUSTICS_3D_VOICE, then param1 specifies the surround cycle in seconds. Value range: [1,60]. Default is 10, meaning the voice surrounds 360 degrees in 10 seconds.\n If preset is set to PITCH_CORRECTION, then param1 specifies the base scale: 1 : (Default) Major scale. 2 : Minor scale. 3 : Japanese scale."
      },
      {
        "param2": "If preset is set to ROOM_ACOUSTICS_3D_VOICE, set param2 to 0.\n If preset is set to PITCH_CORRECTION, then param2 specifies the main pitch: 1 : A 2 : A# 3 : B 4 : (Default) C 5 : C# 6 : D 7 : D# 8 : E 9 : F 10 : F# 11 : G 12 : G#"
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudioeffectpreset",
    "name": "SetAudioEffectPreset",
    "description": "Sets SDK preset voice effects.\n\nCall this method to set SDK preset voice effects for local sending users without altering the gender characteristics of the original voice. Once set, all users in the channel can hear the effect.\n Do not set the profile parameter of SetAudioProfile [2/2] to AUDIO_PROFILE_SPEECH_STANDARD (1) or AUDIO_PROFILE_IOT (6), otherwise this method will not take effect.\n If you call SetAudioEffectPreset with an enum other than ROOM_ACOUSTICS_3D_VOICE or PITCH_CORRECTION, do not call SetAudioEffectParameters, or the effect set by SetAudioEffectPreset will be overridden.\n After calling SetAudioEffectPreset, do not call the following methods, or the effect set by SetAudioEffectPreset will be overridden: SetVoiceBeautifierPreset SetLocalVoicePitch SetLocalVoiceEqualization SetLocalVoiceReverb SetVoiceBeautifierParameters SetVoiceConversionPreset\n This method depends on the voice beautifier dynamic library libagora_audio_beauty_extension.dll. If the library is removed, the feature cannot be enabled properly.",
    "parameters": [
      {
        "preset": "Preset effect options. See AUDIO_EFFECT_PRESET."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudiomixingdualmonomode",
    "name": "SetAudioMixingDualMonoMode",
    "description": "Sets the channel mode of the current audio file.\n\nIn stereo audio files, the left and right channels can store different audio data. Depending on your needs, you can set the channel mode to original, left channel, right channel, or mixed mode. This method applies to stereo audio files only.",
    "parameters": [
      {
        "mode": "The channel mode. See AUDIO_MIXING_DUAL_MONO_MODE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudiomixingpitch",
    "name": "SetAudioMixingPitch",
    "description": "Adjusts the pitch of the music file played locally.\n\nWhen mixing local vocals with a music file, you can call this method to adjust only the pitch of the music file.",
    "parameters": [
      {
        "pitch": "Adjusts the pitch of the music file played locally in semitone steps. The default value is 0, meaning no adjustment. The range is [-12,12]. Each adjacent value differs by one semitone. The greater the absolute value, the more the pitch is raised or lowered."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudiomixingplaybackspeed",
    "name": "SetAudioMixingPlaybackSpeed",
    "description": "Sets the playback speed of the current music file.\n\nYou need to call this method after calling StartAudioMixing [2/2] and receiving the OnAudioMixingStateChanged callback reporting AUDIO_MIXING_STATE_PLAYING.",
    "parameters": [
      {
        "speed": "The playback speed of the music file. Recommended range is [50,400], where:\n 50: 0.5x speed.\n 100: original speed.\n 400: 4x speed."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudiomixingposition",
    "name": "SetAudioMixingPosition",
    "description": "Sets the playback position of the music file.\n\nThis method sets the playback position of the audio file so that you can play it from a specific point instead of from the beginning.",
    "parameters": [
      {
        "pos": "Integer. The position on the progress bar in milliseconds."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudioprofile",
    "name": "SetAudioProfile [1/2]",
    "description": "Sets the audio encoding profile and scenario.\n\nDeprecated Deprecated: This method is deprecated. To set the audio encoding profile, use SetAudioProfile [2/2]; to set the audio scenario, use SetAudioScenario. Due to iOS system limitations, some audio routes cannot be recognized in the call volume mode. Therefore, if you want to use an external sound card, it is recommended to set the audio scenario to the high-quality scenario AUDIO_SCENARIO_GAME_STREAMING (3). In this scenario, the SDK switches to media volume to avoid the issue.",
    "parameters": [
      {
        "profile": "The audio encoding profile, including sample rate, bitrate, encoding mode, and number of channels. See AUDIO_PROFILE_TYPE."
      },
      {
        "scenario": "The audio scenario. The volume type of the device varies by scenario.\nSee AUDIO_SCENARIO_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudioprofile2",
    "name": "SetAudioProfile [2/2]",
    "description": "Sets the audio encoding profile.\n\nIf you want to set the audio scenario, you can call the SetAudioScenario method directly, or call Initialize and set the audioScenario field in the RtcEngineContext structure.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudioscenario",
    "name": "SetAudioScenario",
    "description": "Sets the audio scenario.\n\nDue to iOS system limitations, some audio routes cannot be recognized in the call volume mode. Therefore, if you want to use an external sound card, it is recommended to set the audio scenario to the high-quality scenario AUDIO_SCENARIO_GAME_STREAMING (3). In this scenario, the SDK switches to media volume to avoid the issue.",
    "parameters": [
      {
        "scenario": "The audio scenario. The volume type of the device varies by scenario.\nSee AUDIO_SCENARIO_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setaudiosessionoperationrestriction",
    "name": "SetAudioSessionOperationRestriction",
    "description": "Sets the SDK's operation permissions for the Audio Session.\n\nBy default, both the SDK and the app have permissions to operate the Audio Session. If you only want the app to operate the Audio Session, you can call this method to restrict the SDK's permissions.\nYou can call this method before or after joining a channel. Once called, the restriction takes effect when the SDK needs to change the Audio Session.\n This method is only applicable on iOS.\n This method does not restrict the app's permission to operate the Audio Session.",
    "parameters": [
      {
        "restriction": "The SDK's operation permissions for the Audio Session. See AUDIO_SESSION_OPERATION_RESTRICTION. This parameter is a bit mask, with each bit representing a permission."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setbeautyeffectoptions",
    "name": "SetBeautyEffectOptions",
    "description": "Sets beauty effect options.\n\nEnables the local beauty effect and sets the beauty effect options.\n This method depends on the video enhancement dynamic library libagora_clear_vision_extension.dll. Removing this library will cause this feature to fail.\n This feature has high performance requirements for the device. When calling this method, the SDK automatically checks the current device capabilities.",
    "parameters": [
      {
        "enabled": "Whether to enable the beauty effect: true : Enable the beauty effect. false : (default) Disable the beauty effect."
      },
      {
        "options": "Beauty options. See BeautyOptions for details."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When using the camera to capture local video, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -4: The current device does not support this feature. Possible reasons include:\n The current device does not meet the performance requirements for using beauty effects. Consider using a higher-performance device.\n The current device version is lower than Android 5.0 and does not support this operation. Consider changing the device or upgrading the OS.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcameraautoexposurefacemodeenabled",
    "name": "SetCameraAutoExposureFaceModeEnabled",
    "description": "Enables or disables the auto exposure feature.",
    "parameters": [
      {
        "enabled": "Whether to enable auto exposure: true : Enable auto exposure. false : Disable auto exposure."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcameraautofocusfacemodeenabled",
    "name": "SetCameraAutoFocusFaceModeEnabled",
    "description": "Enables or disables face auto focus.\n\nBy default, the SDK disables face auto focus on Android and enables it on iOS. To manually configure face auto focus, call this method. This method is for Android and iOS only.",
    "parameters": [
      {
        "enabled": "Whether to enable face auto focus: true : Enable face auto focus. false : Disable face auto focus."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcameracapturerconfiguration",
    "name": "SetCameraCapturerConfiguration",
    "description": "Sets the camera capture configuration.\n\nBefore adjusting the camera focal length configuration, it is recommended to call QueryCameraFocalLengthCapability to query the supported focal length capabilities of the device, and then configure accordingly.\nDue to limitations on some Android devices, even if the focal length type is set according to the result of QueryCameraFocalLengthCapability, the setting may not take effect.",
    "parameters": [
      {
        "config": "Camera capture configuration. See CameraCapturerConfiguration. You do not need to set the deviceId parameter in this method."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcameradeviceorientation",
    "name": "SetCameraDeviceOrientation",
    "description": "Sets the rotation angle of the captured video.\n\n(Windows only)\n This method must be called after EnableVideo. The setting takes effect after the camera is successfully turned on, i.e., when the SDK triggers the OnLocalVideoStateChanged callback and returns the local video state as LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).\n If the video capture device does not have a gravity sensor, you can call this method to manually adjust the rotation angle of the captured video.",
    "parameters": [
      {
        "type": "Video source type. See VIDEO_SOURCE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcameraexposurefactor",
    "name": "SetCameraExposureFactor",
    "description": "Sets the exposure factor of the current camera.\n\nPoor or overly bright lighting conditions affect the quality of video capture. To achieve better video results, you can use this method to adjust the camera's exposure factor.\n This method is for Android and iOS only.\n You must call this method after EnableVideo. The setting takes effect after the camera is successfully enabled, i.e., after the SDK triggers the OnLocalVideoStateChanged callback and returns the local video state as LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).\n It is recommended to call IsCameraExposureSupported first to check whether the current camera supports adjusting the exposure factor.\n When you call this method, it sets the exposure factor for the currently used camera, i.e., the one specified in SetCameraCapturerConfiguration.",
    "parameters": [
      {
        "factor": "Exposure factor of the camera. The default value is 0, which means using the camera's default exposure. The larger the value, the greater the exposure. If the video is overexposed, you can reduce the exposure factor; if the video is underexposed and lacks detail in dark areas, you can increase the exposure factor. If the specified value exceeds the device's supported range, the SDK automatically adjusts it to a supported value.\nOn Android, the range is [-20.0, 20.0]; on iOS, the range is [-8.0, 8.0]."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcameraexposureposition",
    "name": "SetCameraExposurePosition",
    "description": "Sets the manual exposure position.\n\nThis method is for Android and iOS only.\n You must call this method after EnableVideo. The setting takes effect after the camera is successfully enabled, i.e., after the SDK triggers the OnLocalVideoStateChanged callback and returns the local video state as LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).\n After successfully calling this method, the local client triggers the OnCameraExposureAreaChanged callback.",
    "parameters": [
      {
        "positionXinView": "The X coordinate of the touch point relative to the view."
      },
      {
        "positionYinView": "The Y coordinate of the touch point relative to the view."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcamerafocuspositioninpreview",
    "name": "SetCameraFocusPositionInPreview",
    "description": "Sets the manual focus position and triggers focus.\n\nThis method is for Android and iOS only.\n You must call this method after EnableVideo. The setting takes effect after the camera is successfully enabled, i.e., after the SDK triggers the OnLocalVideoStateChanged callback and returns the local video state as LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).\n After successfully calling this method, the local client triggers the OnCameraFocusAreaChanged callback.",
    "parameters": [
      {
        "positionX": "The X coordinate of the touch point relative to the view."
      },
      {
        "positionY": "The Y coordinate of the touch point relative to the view."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcamerastabilizationmode",
    "name": "SetCameraStabilizationMode",
    "description": "Sets the camera stabilization mode.\n\nCamera stabilization is disabled by default. You need to call this method to enable it and set the appropriate stabilization mode. This method is only applicable to iOS.\n Camera stabilization only works when the video resolution is higher than 1280 Ã— 720.\n The higher the stabilization level, the narrower the camera's field of view and the greater the camera delay. To ensure user experience, it is recommended to set the mode parameter to CAMERA_STABILIZATION_MODE_LEVEL_1.",
    "parameters": [
      {
        "mode": "Camera stabilization mode. See CAMERA_STABILIZATION_MODE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcameratorchon",
    "name": "SetCameraTorchOn",
    "description": "Sets whether to turn on the flashlight.\n\nThis method is applicable to Android and iOS only.\n You must call this method after EnableVideo. The setting takes effect after the camera is successfully started, that is, after the SDK triggers the OnLocalVideoStateChanged callback and returns the local video state as LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).",
    "parameters": [
      {
        "isOn": "Whether to turn on the flashlight: true : Turn on the flashlight. false : (default) Turn off the flashlight."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcamerazoomfactor",
    "name": "SetCameraZoomFactor",
    "description": "Sets the camera zoom factor.\n\nSome iOS devices have composite rear cameras consisting of multiple lenses, such as dual-camera (wide and ultra-wide) or triple-camera (wide, ultra-wide, and telephoto). For such composite lenses with ultra-wide capability, you can call SetCameraCapturerConfiguration to set cameraFocalLengthType to CAMERA_FOCAL_LENGTH_DEFAULT (0) (standard lens), and then call this method to set the zoom factor to a value less than 1.0 to achieve an ultra-wide-angle effect.\n This method is applicable to Android and iOS only.\n You must call this method after EnableVideo. The setting takes effect after the camera is successfully started, that is, after the SDK triggers the OnLocalVideoStateChanged callback and returns the local video state as LOCAL_VIDEO_STREAM_STATE_CAPTURING (1).",
    "parameters": [
      {
        "factor": "Camera zoom factor. For devices that do not support ultra-wide-angle, the range is from 1.0 to the maximum zoom factor. For devices that support ultra-wide-angle, the range is from 0.5 to the maximum zoom factor. You can call GetCameraMaxZoomFactor to get the maximum supported zoom factor."
      }
    ],
    "returns": "On success: Returns the set factor value.\n On failure: Return value < 0.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setchannelprofile",
    "name": "SetChannelProfile",
    "description": "Sets the channel profile.\n\nYou can call this method to set the channel profile. The SDK applies different optimization strategies for different scenarios. For example, in live streaming, the SDK prioritizes video quality. The default channel profile after SDK initialization is live streaming. To ensure real-time audio and video quality, users in the same channel must use the same channel profile.",
    "parameters": [
      {
        "profile": "The channel profile. See CHANNEL_PROFILE_TYPE."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter.\n -7: The SDK is not initialized.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setclientrole1",
    "name": "SetClientRole [1/2]",
    "description": "Sets the user role.\n\nBy default, the SDK sets the user role to audience. You can call this method to set the user role to broadcaster. The user role (role) determines the permissions at the SDK level, including whether the user can publish streams. When calling this method outside the channel and setting the user role to BROADCASTER, the local OnClientRoleChanged callback is not triggered.",
    "parameters": [
      {
        "role": "The user role. See CLIENT_ROLE_TYPE. Users with the audience role cannot publish audio or video streams in the channel. To publish streams in a live streaming scenario, ensure the user role is switched to broadcaster."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -1: General error (not specifically categorized).\n -2: Invalid parameter.\n -7: The SDK is not initialized.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setclientrole2",
    "name": "SetClientRole [2/2]",
    "description": "Sets the user role and audience latency level in live streaming.\n\nBy default, the SDK sets the user role to audience. You can call this method to set the user role to broadcaster. The user role (role) determines the user's permissions at the SDK level, such as whether the user can publish streams.\nCompared to SetClientRole [1/2], this method also supports setting the audience latency level (audienceLatencyLevel). audienceLatencyLevel must be used together with role to determine the level of service a user can enjoy within their permission scope. For example, for audience users, whether to receive low-latency or ultra-low-latency video streams.\nDifferent latency levels affect billing. See [Billing Strategy](https://doc.shengwang.cn/doc/rtc/android/billing/billing-strategy#%E6%9E%81%E9%80%9F%E7%9B%B4%E6%92%AD%E8%A7%82%E4%BC%97%E8%B4%B9%E7%94%A8). When the user role is set to broadcaster, the audience latency level only supports AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY.\nWhen calling this method before joining the channel and setting role to BROADCASTER, the local OnClientRoleChanged callback is not triggered.",
    "parameters": [
      {
        "role": "The user role. See CLIENT_ROLE_TYPE. Users with the audience role cannot publish audio or video streams in the channel. To publish streams in a live streaming scenario, ensure the user role is switched to broadcaster."
      },
      {
        "options": "User-specific settings, including user level. See ClientRoleOptions."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -1: General error (not specifically categorized).\n -2: Invalid parameter.\n -5: The call was rejected.\n -7: The SDK is not initialized.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcloudproxy",
    "name": "SetCloudProxy",
    "description": "Sets the cloud proxy service.\n\nWhen the user's network access is restricted by a firewall, you need to add the IP and port numbers provided by Agora to the firewall whitelist, then call this method to enable the cloud proxy and set the proxy type via the proxyType parameter.\nAfter successfully connecting to the cloud proxy, the SDK triggers the OnConnectionStateChanged (CONNECTION_STATE_CONNECTING, CONNECTION_CHANGED_SETTING_PROXY_SERVER) callback.\nIf you want to disable the currently set Force UDP or Force TCP cloud proxy, call SetCloudProxy(NONE_PROXY).\nIf you want to change the currently set cloud proxy type, call SetCloudProxy(NONE_PROXY) first, then call SetCloudProxy again and pass in your desired proxyType value.\n It is recommended to call this method outside the channel.\n If the user is in a network environment with an internal firewall, the features of CDN live streaming and media stream relay across channels are not available when using the Force UDP cloud proxy.\n When using the Force UDP cloud proxy, the StartAudioMixing [2/2] method cannot play online audio files over HTTP. The features of CDN live streaming and media stream relay across channels use the TCP cloud proxy.",
    "parameters": [
      {
        "proxyType": "Cloud proxy type. See CLOUD_PROXY_TYPE.\nThis parameter is required. If you do not assign a value, the SDK will report an error."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter.\n -7: SDK not initialized.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setcolorenhanceoptions",
    "name": "SetColorEnhanceOptions",
    "description": "Sets the color enhancement feature.\n\nVideo captured by the camera may suffer from color distortion. The color enhancement feature can improve the richness and fidelity of video colors by intelligently adjusting video attributes such as saturation and contrast, making the video more vivid.\nYou can call this method to enable the color enhancement feature and set the color enhancement effect.\n Call this method after EnableVideo.\n Color enhancement has certain performance requirements. If the device experiences issues such as overheating after enabling this feature, it is recommended to reduce the enhancement level to a less performance-intensive setting or disable the feature.\n This method depends on the video enhancement dynamic library libagora_clear_vision_extension.dll. Removing this library will cause this feature to fail.",
    "parameters": [
      {
        "enabled": "Whether to enable the color enhancement feature: true : Enable color enhancement. false : (default) Disable color enhancement."
      },
      {
        "options": "Color enhancement options used to configure the effect. See ColorEnhanceOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When using the camera to capture local video, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setdefaultaudioroutetospeakerphone",
    "name": "SetDefaultAudioRouteToSpeakerphone",
    "description": "Sets the default audio route.\n\nMobile devices typically have two audio routes: the earpiece at the top with lower volume, and the speaker at the bottom with higher volume. Setting the default audio route determines whether the system uses the earpiece or speaker to play audio when no external device is connected.\nThe system's default audio route varies by scenario:\n Voice call: Earpiece\n Voice live streaming: Speaker\n Video call: Speaker\n Video live streaming: Speaker Calling this API allows you to change the default audio route. This method is for Android and iOS only.\nAfter setting the default audio route using this method, the actual audio route may change depending on whether an external audio device (wired or Bluetooth headset) is connected. See [Audio Route](https://doc.shengwang.cn/doc/rtc/android/advanced-features/audio-route) for details.",
    "parameters": [
      {
        "defaultToSpeaker": "Whether to use the speaker as the default audio route: true : Set the default audio route to speaker. false : Set the default audio route to earpiece."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setdirectcdnstreamingaudioconfiguration",
    "name": "SetDirectCdnStreamingAudioConfiguration",
    "description": "Sets the audio encoding configuration for pushing streams directly to the CDN from the host.\n\nDeprecated Deprecated since v4.6.2.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setdirectcdnstreamingvideoconfiguration",
    "name": "SetDirectCdnStreamingVideoConfiguration",
    "description": "Sets the video encoding properties when the host pushes the stream directly to the CDN.\n\nDeprecated Deprecated since v4.6.2. This method is only effective for video captured by the camera, screen sharing, or custom video sources. That is, it applies to video captured when publishCameraTrack or publishCustomVideoTrack is set to true in DirectCdnStreamingMediaOptions.\nIf the resolution you set exceeds the range supported by your camera device, the SDK adapts based on your settings and captures, encodes, and pushes the stream using the closest resolution with the same aspect ratio as your setting. You can get the actual resolution of the pushed video stream via the OnDirectCdnStreamingStats callback.",
    "parameters": [
      {
        "config": "Video encoding configuration. See VideoEncoderConfiguration. When pushing the stream directly to the CDN, the SDK currently only supports setting ORIENTATION_MODE to landscape (ORIENTATION_MODE_FIXED_LANDSCAPE) or portrait (ORIENTATION_MODE_FIXED_PORTRAIT) mode."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setdualstreammode",
    "name": "SetDualStreamMode [1/2]",
    "description": "Sets the dual-stream mode on the sender.\n\nBy default, the SDK enables adaptive low-quality stream mode (AUTO_SIMULCAST_STREAM) on the sender, meaning the sender does not actively send low-quality streams. Receivers with host identity can call SetRemoteVideoStreamType to request a low-quality stream, and the sender starts sending it upon receiving the request.\n If you want to change this behavior, call this method and set mode to DISABLE_SIMULCAST_STREAM (never send low-quality stream) or ENABLE_SIMULCAST_STREAM (always send low-quality stream).\n If you want to revert to the default behavior after changing it, call this method again and set mode to AUTO_SIMULCAST_STREAM. The differences and relationships between this method and EnableDualStreamMode [1/2] are as follows:\n Calling this method and setting mode to DISABLE_SIMULCAST_STREAM has the same effect as setting EnableDualStreamMode [1/2] to false.\n Calling this method and setting mode to ENABLE_SIMULCAST_STREAM has the same effect as setting EnableDualStreamMode [1/2] to true.\n Both methods can be called before or after joining a channel. If both are used, the settings from the later call take effect.",
    "parameters": [
      {
        "mode": "The mode for sending video streams. See SIMULCAST_STREAM_MODE."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setdualstreammode2",
    "name": "SetDualStreamMode [2/2]",
    "description": "Sets the dual-stream mode on the sender and configures the low-quality video stream.\n\nBy default, the SDK enables adaptive low-quality stream mode (AUTO_SIMULCAST_STREAM) on the sender, meaning the sender does not actively send low-quality streams. Receivers with host identity can call SetRemoteVideoStreamType to request a low-quality stream, and the sender starts sending it upon receiving the request.\n If you want to change this behavior, call this method and set mode to DISABLE_SIMULCAST_STREAM (never send low-quality stream) or ENABLE_SIMULCAST_STREAM (always send low-quality stream).\n If you want to revert to the default behavior after changing it, call this method again and set mode to AUTO_SIMULCAST_STREAM. Compared to SetDualStreamMode [1/2], this method also allows you to configure the low-quality video stream. The SDK sends the low-quality stream based on the configuration in streamConfig. The differences and relationships between this method and EnableDualStreamMode [2/2] are as follows:\n Calling this method and setting mode to DISABLE_SIMULCAST_STREAM has the same effect as calling EnableDualStreamMode [2/2] with enabled set to false.\n Calling this method and setting mode to ENABLE_SIMULCAST_STREAM has the same effect as calling EnableDualStreamMode [2/2] with enabled set to true.\n Both methods can be called before or after joining a channel. If both are used, the settings from the later call take effect.",
    "parameters": [
      {
        "mode": "The mode for sending video streams. See SIMULCAST_STREAM_MODE."
      },
      {
        "streamConfig": "Configuration of the low-quality video stream. See SimulcastStreamConfig. When mode is set to DISABLE_SIMULCAST_STREAM, setting streamConfig has no effect."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setearmonitoringaudioframeparameters",
    "name": "SetEarMonitoringAudioFrameParameters",
    "description": "Sets the data format for the OnEarMonitoringAudioFrame callback.\n\nThis method sets the data format for the OnEarMonitoringAudioFrame callback.\n Before calling this method, you need to call EnableInEarMonitoring and set includeAudioFilters to EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS or EAR_MONITORING_FILTER_NOISE_SUPPRESSION.\n The SDK calculates the sampling interval using the samplesPerCall, sampleRate, and channel parameters in this method. The formula is: sampling interval = samplesPerCall / (sampleRate Ã— channel). Make sure the sampling interval is no less than 0.01 seconds. The SDK triggers the OnEarMonitoringAudioFrame callback based on this sampling interval.",
    "parameters": [
      {
        "sampleRate": "The sampling rate (Hz) of the audio reported in OnEarMonitoringAudioFrame. Can be set to 8000, 16000, 32000, 44100, or 48000."
      },
      {
        "channel": "The number of channels of the audio reported in OnEarMonitoringAudioFrame. Can be set to 1 or 2:\n 1: Mono.\n 2: Stereo."
      },
      {
        "mode": "The operation mode of the audio frame. See RAW_AUDIO_FRAME_OP_MODE_TYPE."
      },
      {
        "samplesPerCall": "The number of audio samples reported in OnEarMonitoringAudioFrame, typically 1024 in RTMP streaming scenarios."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggested solutions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_seteffectposition",
    "name": "SetEffectPosition",
    "description": "Sets the playback position of the specified audio effect file.\n\nAfter successful setting, the local audio effect file will start playing from the specified position. This method must be called after playEffect.",
    "parameters": [
      {
        "soundId": "The ID of the audio effect. Each audio effect has a unique ID."
      },
      {
        "pos": "The playback position of the audio effect file, in milliseconds."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_seteffectsvolume",
    "name": "SetEffectsVolume",
    "description": "Sets the playback volume of audio effect files.",
    "parameters": [
      {
        "volume": "Playback volume. The range is [0,100]. The default value is 100, which means the original volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setenablespeakerphone",
    "name": "SetEnableSpeakerphone",
    "description": "Enables or disables speakerphone playback.\n\nFor the SDK's default audio routes in different scenarios, see [Audio Route](https://doc.shengwang.cn/doc/rtc/android/advanced-features/audio-route). This method is for Android and iOS only.\n This method only sets the audio route used by the user in the current channel. It does not affect the SDK's default audio route. When the user leaves the current channel and joins a new one, the SDK's default audio route is used again.\n If the user uses external audio playback devices such as Bluetooth or wired headsets, this method has no effect. Audio will only be played through the external device. If multiple external devices are connected, audio is played through the most recently connected one.",
    "parameters": [
      {
        "speakerOn": "Whether to enable speakerphone playback: true : Enable. Audio route is speaker. false : Disable. Audio route is earpiece."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setextensionproperty",
    "name": "SetExtensionProperty",
    "description": "Sets the extension property.\n\nAfter enabling an extension, you can call this method to set its properties. To set properties for multiple extensions, call this method multiple times.",
    "parameters": [
      {
        "provider": "The name of the extension provider."
      },
      {
        "extension": "The name of the extension."
      },
      {
        "key": "The key of the extension property."
      },
      {
        "value": "The value corresponding to the extension property key."
      },
      {
        "type": "The media source type of the extension. See MEDIA_SOURCE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setextensionproviderproperty",
    "name": "SetExtensionProviderProperty",
    "description": "Sets the properties of the extension provider.\n\nYou can call this method to set the properties of the extension provider and initialize related parameters based on the provider type. To set properties for multiple extension providers, call this method multiple times.",
    "parameters": [
      {
        "provider": "The name of the extension provider."
      },
      {
        "key": "The key of the extension property."
      },
      {
        "value": "The value corresponding to the extension property key."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setexternalmediaprojection",
    "name": "SetExternalMediaProjection",
    "description": "Sets an external MediaProjection to capture screen video stream.\n\nAfter successfully calling this method, the external MediaProjection you set will replace the one requested by the SDK to capture the screen video stream.\nWhen screen sharing stops or IRtcEngine is destroyed, the SDK automatically releases the MediaProjection. This method is for Android only.\nYou must request MediaProjection permission before calling this method.",
    "parameters": [
      {
        "mediaProjection": "A [MediaProjection](https://developer.android.com/reference/android/media/projection/MediaProjection) object used to capture the screen video stream."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setexternalremoteeglcontext",
    "name": "SetExternalRemoteEglContext",
    "description": "Sets the EGL context for rendering remote video streams.\n\nBy calling this method, developers can replace the SDK's default internal remote EGL context, making it easier to manage a unified EGL context.\nWhen the engine is destroyed, the SDK automatically releases the EGL context. This method is only applicable to Android.",
    "parameters": [
      {
        "eglContext": "The EGL context object used for rendering remote video streams."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setfaceshapeareaoptions",
    "name": "SetFaceShapeAreaOptions",
    "description": "Sets face shaping area options and specifies the media source.\n\nIf the preset face shaping effect implemented in the SetFaceShapeBeautyOptions method does not meet expectations, you can use this method to set the face shaping area options and fine-tune each part of the face individually for more refined effects. Face shaping is a value-added service. For billing details, see [Billing Strategy](https://doc.shengwang.cn/doc/rtc/android/billing/billing-strategy).\n On Android, this method applies to Android 4.4 and later only.\n This method depends on the video enhancement dynamic library libagora_clear_vision_extension.dll. Removing this library will cause this feature to fail.\n This feature has high performance requirements for the device. When calling this method, the SDK automatically checks the current device capabilities.",
    "parameters": [
      {
        "options": "Face shaping area options. See FaceShapeAreaOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When using the camera to capture local video, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -4: The current device does not support this feature. Possible reasons include:\n The current device does not meet the performance requirements for using beauty effects. Consider using a higher-performance device.\n The current device version is lower than Android 4.4 and does not support this operation. Consider changing the device or upgrading the OS.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setfaceshapebeautyoptions",
    "name": "SetFaceShapeBeautyOptions",
    "description": "Sets face shaping effect options and specifies the media source.\n\nCall this method to enhance facial features using preset parameters to achieve effects such as face slimming, eye enlarging, and nose slimming in one go. You can also fine-tune the intensity of the overall enhancement. Face shaping is a value-added service. For billing details, see [Billing Strategy](https://doc.shengwang.cn/doc/rtc/android/billing/billing-strategy).\n On Android, this method applies to Android 4.4 and later versions only.\n This method depends on the video enhancement dynamic library libagora_clear_vision_extension.dll. Deleting this library will cause the feature to fail.\n This feature requires high device performance. When you call this method, the SDK automatically checks the device capabilities.",
    "parameters": [
      {
        "enabled": "Whether to enable the face shaping effect: true : Enable face shaping. false : (Default) Disable face shaping."
      },
      {
        "options": "Face shaping style options. See FaceShapeBeautyOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When capturing local video using the camera, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -4: The current device does not support this feature. Possible reasons include:\n The device does not meet the performance requirements for beauty effects. Consider using a higher-performance device.\n The device runs a version lower than Android 4.4, which does not support this operation. Consider upgrading the OS or using a different device.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setfiltereffectoptions",
    "name": "SetFilterEffectOptions",
    "description": "Sets filter effect options and specifies the media source.\n\nThis method depends on the video enhancement dynamic library libagora_clear_vision_extension.dll. Deleting this library will cause the feature to fail.\n This feature requires high device performance. When you call this method, the SDK automatically checks the device capabilities.",
    "parameters": [
      {
        "enabled": "Whether to enable the filter effect: true : Enable filter effect. false : (Default) Disable filter effect."
      },
      {
        "options": "Filter options. See FilterEffectOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When capturing local video using the camera, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setheadphoneeqparameters",
    "name": "SetHeadphoneEQParameters",
    "description": "Sets the low and high frequency parameters of the headphone equalizer.\n\nIn spatial audio scenarios, if the preset headphone equalizer effect set by calling SetHeadphoneEQPreset does not meet expectations, you can further adjust the headphone equalizer effect by calling this method.",
    "parameters": [
      {
        "lowGain": "Low frequency parameter of the headphone equalizer. Value range: [-10,10]. The higher the value, the deeper the sound."
      },
      {
        "highGain": "High frequency parameter of the headphone equalizer. Value range: [-10,10]. The higher the value, the sharper the sound."
      }
    ],
    "returns": "0: Success.\n < 0: Failure\n -1: General error (not specifically categorized).",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setheadphoneeqpreset",
    "name": "SetHeadphoneEQPreset",
    "description": "Sets a preset headphone equalizer effect.\n\nThis method is mainly used in spatial audio scenarios. You can select a preset headphone equalizer to listen to audio and achieve the desired audio experience. If your headphones already have a good equalizer effect, calling this method may not significantly improve the experience and may even degrade it.",
    "parameters": [
      {
        "preset": "Preset headphone equalizer effect. See HEADPHONE_EQUALIZER_PRESET."
      }
    ],
    "returns": "0: Success.\n < 0: Failure\n -1: General error (not specifically categorized).",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setinearmonitoringvolume",
    "name": "SetInEarMonitoringVolume",
    "description": "Sets the in-ear monitoring volume.",
    "parameters": [
      {
        "volume": "Volume, range is [0,400].\n 0: Mute.\n 100: (Default) Original volume.\n 400: Four times the original volume, with built-in overflow protection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter setting, e.g., in-ear monitoring volume is out of range (< 0 or > 400).",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalrendermode1",
    "name": "SetLocalRenderMode [1/2]",
    "description": "Sets the local view display mode.\n\nDeprecated Deprecated: This method is deprecated. Use SetLocalRenderMode [2/2] instead. This method sets the local view display mode. The app can call this method multiple times to change the display mode.",
    "parameters": [
      {
        "renderMode": "Local view display mode. See RENDER_MODE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalrendermode2",
    "name": "SetLocalRenderMode [2/2]",
    "description": "Updates the local view display mode.\n\nAfter initializing the local user view, you can call this method to update the rendering and mirror mode of the local user view. This method only affects what the local user sees and does not affect the publishing of the local video.",
    "parameters": [
      {
        "renderMode": "Local view display mode. See RENDER_MODE_TYPE."
      },
      {
        "mirrorMode": "Mirror mode of the local view. See VIDEO_MIRROR_MODE_TYPE. This parameter only takes effect when the SDK handles rendering. If you want to set view mirroring, you can set the GameObject's scaleX to -1 or +1.\nIf you use the front camera, the local user view mirror mode is enabled by default; if you use the rear camera, it is disabled by default."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalrendertargetfps",
    "name": "SetLocalRenderTargetFps",
    "description": "Sets the maximum frame rate for local video rendering.",
    "parameters": [
      {
        "sourceType": "The type of video source. See VIDEO_SOURCE_TYPE."
      },
      {
        "targetFps": "Maximum rendering frame rate (fps). Supported values: 1, 7, 10, 15, 24, 30, 60. Set this parameter to a value lower than the actual video frame rate. Otherwise, the setting will not take effect."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalvideodatasourceposition",
    "name": "SetLocalVideoDataSourcePosition",
    "description": "Sets the observation position of the local video frame.\n\nThis method only supports observing local video data rendered through VideoSurface and its subclasses.",
    "parameters": [
      {
        "position": "Observation position of the video frame. See VIDEO_MODULE_POSITION.\n Currently, this method only supports setting the observation position to POSITION_POST_CAPTURER or POSITION_PRE_ENCODER.\n Video frames obtained at POSITION_POST_CAPTURER are uncropped and have higher frame rates, while frames at POSITION_PRE_ENCODER are cropped before sending and have frame rates less than or equal to the camera capture rate."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalvideomirrormode",
    "name": "SetLocalVideoMirrorMode",
    "description": "Sets the local video mirror mode.\n\nDeprecated Deprecated: This method is deprecated.",
    "parameters": [
      {
        "mirrorMode": "Local video mirror mode. See VIDEO_MIRROR_MODE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalvoiceequalization",
    "name": "SetLocalVoiceEqualization",
    "description": "Sets the local voice equalization.",
    "parameters": [
      {
        "bandFrequency": "Index of the band frequency. The value range is [0,9], representing 10 bands of the equalizer. The corresponding center frequencies are [31, 62, 125, 250, 500, 1k, 2k, 4k, 8k, 16k] Hz. See AUDIO_EQUALIZATION_BAND_FREQUENCY."
      },
      {
        "bandGain": "Gain of each band in dB. The value range is [-15,15], with a default of 0."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalvoiceformant",
    "name": "SetLocalVoiceFormant",
    "description": "Sets the formant ratio to change the voice timbre.\n\nThe formant ratio is a parameter that affects the timbre of the voice. A smaller value results in a deeper sound, while a larger value results in a sharper sound. After setting the formant ratio, all users in the channel can hear the effect. If you want to change both the timbre and pitch, Agora recommends using SetLocalVoicePitch together.",
    "parameters": [
      {
        "formantRatio": "Formant ratio, value range [-1.0, 1.0]. Default is 0.0, which means no change to the original timbre. Agora recommends using values in the range [-0.4, 0.6]. Values outside this range may result in poor audio quality."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalvoicepitch",
    "name": "SetLocalVoicePitch",
    "description": "Sets the local voice pitch.",
    "parameters": [
      {
        "pitch": "Voice frequency. Can be set within the range [0.5, 2.0]. The smaller the value, the lower the pitch. The default value is 1.0, which means no pitch change."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlocalvoicereverb",
    "name": "SetLocalVoiceReverb",
    "description": "Sets the local audio reverb.\n\nThe SDK provides a simpler method SetAudioEffectPreset to directly apply preset reverb effects such as Pop, R&B, and KTV. This method can be called before and after joining a channel.",
    "parameters": [
      {
        "reverbKey": "Reverb effect key. This method supports 5 reverb effect keys. See AUDIO_REVERB_TYPE."
      },
      {
        "value": "Value corresponding to each reverb effect key."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlogfile",
    "name": "SetLogFile",
    "description": "Sets the log file.\n\nDeprecated Deprecated: This method is deprecated. Please set the log file path via the context parameter when calling Initialize. Sets the output log file for the SDK. All logs generated during SDK runtime will be written to this file. The app must ensure that the specified directory exists and is writable.",
    "parameters": [
      {
        "filePath": "Full path of the log file. The log file is UTF-8 encoded."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlogfilesize",
    "name": "SetLogFileSize",
    "description": "Sets the size of the SDK output log file.\n\nDeprecated Deprecated: This method is deprecated. Please use the logConfig parameter in Initialize to set the log file size. By default, the SDK generates 5 SDK log files and 5 API call log files, as follows:\n SDK log file names: agorasdk.log, agorasdk.1.log, agorasdk.2.log, agorasdk.3.log, agorasdk.4.log.\n API call log file names: agoraapi.log, agoraapi.1.log, agoraapi.2.log, agoraapi.3.log, agoraapi.4.log.\n Each SDK log file has a default size of 2,048 KB; each API call log file also has a default size of 2,048 KB. All log files are UTF-8 encoded.\n The latest logs are always written to agorasdk.log and agoraapi.log.\n When agorasdk.log is full, the SDK performs the following operations:\n Delete the agorasdk.4.log file (if it exists).\n Rename agorasdk.3.log to agorasdk.4.log.\n Rename agorasdk.2.log to agorasdk.3.log.\n Rename agorasdk.1.log to agorasdk.2.log.\n Create a new agorasdk.log file.\n The overwrite rules for agoraapi.log are the same as for agorasdk.log. This method only sets the size of the agorasdk.log file and does not affect agoraapi.log.",
    "parameters": [
      {
        "fileSizeInKBytes": "Size of a single agorasdk.log file in KB. The valid range is [128,20480], and the default value is 2,048 KB. If you set fileSizeInKByte to less than 128 KB, the SDK automatically adjusts it to 128 KB; if you set it to more than 20,480 KB, the SDK automatically adjusts it to 20,480 KB."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlogfilter",
    "name": "SetLogFilter",
    "description": "Sets the log output level.\n\nDeprecated Deprecated: Please use logConfig in Initialize instead.",
    "parameters": [
      {
        "filter": "Log filter level."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setloglevel",
    "name": "SetLogLevel",
    "description": "Sets the SDK log output level.\n\nDeprecated Deprecated: This method is deprecated. Please set the log output level via the context parameter when calling Initialize. Select a level to see log information of that level.",
    "parameters": [
      {
        "level": "Log level. See LOG_LEVEL."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setlowlightenhanceoptions",
    "name": "SetLowlightEnhanceOptions",
    "description": "Sets the low-light enhancement feature.\n\nYou can call this method to enable the low-light enhancement feature and set its effect.\n This method depends on the video enhancement dynamic library libagora_clear_vision_extension.dll. Deleting this library will cause the feature to fail.\n Low-light enhancement requires certain device performance. If the device overheats after enabling this feature, it is recommended to reduce the enhancement level or disable the feature.\n To achieve high-quality low-light enhancement (LOW_LIGHT_ENHANCE_LEVEL_HIGH_QUALITY), you must first call SetVideoDenoiserOptions to enable video denoising. The specific mapping is as follows:\n When low-light enhancement is in auto mode (LOW_LIGHT_ENHANCE_AUTO), video denoising must be set to high quality (VIDEO_DENOISER_LEVEL_HIGH_QUALITY) and auto mode (VIDEO_DENOISER_AUTO).\n When low-light enhancement is in manual mode (LOW_LIGHT_ENHANCE_MANUAL), video denoising must be set to high quality (VIDEO_DENOISER_LEVEL_HIGH_QUALITY) and manual mode (VIDEO_DENOISER_MANUAL).",
    "parameters": [
      {
        "enabled": "Whether to enable low-light enhancement: true : Enable low-light enhancement. false : (Default) Disable low-light enhancement."
      },
      {
        "options": "Low-light enhancement options for setting the effect. See LowlightEnhanceOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When capturing local video using the camera, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setmaxmetadatasize",
    "name": "SetMaxMetadataSize",
    "description": "Sets the maximum size of media metadata.\n\nAfter calling RegisterMediaMetadataObserver, you can call this method to set the maximum size of media metadata.",
    "parameters": [
      {
        "size": "Maximum size of the media metadata."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setmixedaudioframeparameters",
    "name": "SetMixedAudioFrameParameters",
    "description": "Sets the raw audio data format after mixing the captured and playback audio.\n\nThe SDK calculates the sampling interval using the samplesPerCall, sampleRate, and channel parameters in this method. The formula is: sampling interval = samplesPerCall / (sampleRate Ã— channel). Make sure the sampling interval is no less than 0.01 seconds. The SDK triggers the OnMixedAudioFrame callback based on this sampling interval.",
    "parameters": [
      {
        "sampleRate": "The sampling rate (Hz) of the audio data. Can be set to 8000, 16000, 32000, 44100, or 48000."
      },
      {
        "channel": "The number of channels of the audio data. Can be set to 1 or 2:\n 1: Mono.\n 2: Stereo."
      },
      {
        "samplesPerCall": "The number of audio samples. Typically 1024 in RTMP streaming scenarios."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggested solutions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setparameters",
    "name": "SetParameters [1/2]",
    "description": "The SDK's JSON configuration used for technical preview or custom features.",
    "parameters": [
      {
        "key": "Key value."
      },
      {
        "value": "Value."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setplaybackaudioframebeforemixingparameters",
    "name": "SetPlaybackAudioFrameBeforeMixingParameters [1/2]",
    "description": "Sets the raw audio playback data format before mixing.\n\nThe SDK triggers the OnPlaybackAudioFrameBeforeMixing callback based on this sampling interval.",
    "parameters": [
      {
        "sampleRate": "The sampling rate (Hz) of the audio data. Can be set to 8000, 16000, 32000, 44100, or 48000."
      },
      {
        "channel": "The number of channels of the audio data. Can be set to 1 or 2:\n 1: Mono.\n 2: Stereo."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggested solutions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setplaybackaudioframebeforemixingparameters1",
    "name": "SetPlaybackAudioFrameBeforeMixingParameters [2/2]",
    "description": "Sets the raw audio playback data format before mixing.\n\nThe SDK triggers the OnPlaybackAudioFrameBeforeMixing callback based on this sampling interval.",
    "parameters": [
      {
        "sampleRate": "The sampling rate (Hz) of the audio data. Can be set to 8000, 16000, 32000, 44100, or 48000."
      },
      {
        "channel": "The number of channels of the audio data. Can be set to 1 or 2:\n 1: Mono.\n 2: Stereo."
      },
      {
        "samplesPerCall": "Sets the number of audio samples returned in the onPlaybackAudioFrameBeforeMixing callback. In RTMP streaming scenarios, it is recommended to set this to 1024."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggested solutions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setplaybackaudioframeparameters",
    "name": "SetPlaybackAudioFrameParameters",
    "description": "Sets the format of the playback raw audio data.\n\nThe SDK calculates the sampling interval using the samplesPerCall, sampleRate, and channel parameters in this method. The formula is: sampling interval = samplesPerCall / (sampleRate Ã— channel). Make sure the sampling interval is no less than 0.01 seconds. The SDK triggers the OnPlaybackAudioFrame callback based on this sampling interval.",
    "parameters": [
      {
        "sampleRate": "The sample rate (Hz) of the audio data. You can set it to 8000, 16000, 24000, 32000, 44100, or 48000."
      },
      {
        "channel": "The number of audio channels. You can set it to 1 or 2:\n 1: Mono.\n 2: Stereo."
      },
      {
        "mode": "The operation mode of the audio frame. See RAW_AUDIO_FRAME_OP_MODE_TYPE."
      },
      {
        "samplesPerCall": "The number of audio samples per call, typically 1024 in scenarios such as CDN streaming."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setrecordingaudioframeparameters",
    "name": "SetRecordingAudioFrameParameters",
    "description": "Sets the format of the recorded raw audio data.\n\nThe SDK calculates the sampling interval using the samplesPerCall, sampleRate, and channel parameters in this method. The formula is: sampling interval = samplesPerCall / (sampleRate Ã— channel). Make sure the sampling interval is no less than 0.01 seconds. The SDK triggers the OnRecordAudioFrame callback based on this sampling interval.",
    "parameters": [
      {
        "sampleRate": "The sample rate (Hz) of the audio data. You can set it to 8000, 16000, 32000, 44100, or 48000."
      },
      {
        "channel": "The number of audio channels. You can set it to 1 or 2:\n 1: Mono.\n 2: Stereo."
      },
      {
        "mode": "The operation mode of the audio frame. See RAW_AUDIO_FRAME_OP_MODE_TYPE."
      },
      {
        "samplesPerCall": "The number of audio samples per call, typically 1024 in scenarios such as CDN streaming."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremotedefaultvideostreamtype",
    "name": "SetRemoteDefaultVideoStreamType",
    "description": "Sets the default video stream type to subscribe to.\n\nDepending on the sender's default behavior and the specific configuration of SetDualStreamMode [2/2], the receiver's behavior when calling this method is as follows:\n By default, the SDK enables small stream adaptive mode (AUTO_SIMULCAST_STREAM) on the sender side, meaning the sender only sends the high-quality stream. Only receivers with host roles can call this method to request the low-quality stream. Once the sender receives the request, it starts sending the low-quality stream automatically. At this point, all users in the channel can call this method to switch to the low-quality stream subscription mode.\n If the sender calls SetDualStreamMode [2/2] and sets mode to DISABLE_SIMULCAST_STREAM (never send low-quality stream), this method has no effect.\n If the sender calls SetDualStreamMode [2/2] and sets mode to ENABLE_SIMULCAST_STREAM (always send low-quality stream), both host and audience roles on the receiver side can call this method to switch to low-quality stream subscription mode. When receiving a low-quality video stream, the SDK dynamically adjusts the video stream size based on the size of the video window to save bandwidth and computing resources. The aspect ratio of the low-quality stream is the same as that of the high-quality stream. Based on the current high-quality stream's aspect ratio, the system automatically assigns resolution, frame rate, and bitrate for the low-quality stream. If you call both this method and SetRemoteVideoStreamType, the SDK uses the configuration in SetRemoteVideoStreamType.",
    "parameters": [
      {
        "streamType": "The default video stream type to subscribe to: VIDEO_STREAM_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremoterendermode2",
    "name": "SetRemoteRenderMode",
    "description": "Updates the remote view display mode.\n\nAfter initializing the remote user view, you can call this method to update the rendering and mirror mode of the remote user view as displayed locally. This method only affects what the local user sees.\n You can call this method multiple times during a call to update the remote user view display mode.",
    "parameters": [
      {
        "uid": "Remote user ID."
      },
      {
        "renderMode": "Rendering mode of the remote user view. See RENDER_MODE_TYPE."
      },
      {
        "mirrorMode": "Mirror mode of the remote user view. See VIDEO_MIRROR_MODE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremoterendertargetfps",
    "name": "SetRemoteRenderTargetFps",
    "description": "Sets the maximum frame rate for remote video rendering.",
    "parameters": [
      {
        "targetFps": "Maximum rendering frame rate (fps). Supported values: 1, 7, 10, 15, 24, 30, 60. Set this parameter to a value lower than the actual video frame rate. Otherwise, the setting will not take effect."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremotesubscribefallbackoption",
    "name": "SetRemoteSubscribeFallbackOption",
    "description": "Sets the fallback option for subscribed audio and video streams under poor network conditions.\n\nIn poor network conditions, the quality of real-time audio and video communication deteriorates. You can call this method and set option to STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW or STREAM_FALLBACK_OPTION_AUDIO_ONLY. The SDK will switch the video stream to a lower stream or disable the video stream when the downlink network is poor and the audio/video quality is severely affected, ensuring audio quality. Meanwhile, the SDK continuously monitors network conditions and resumes subscription to audio and video streams when the network improves.\nWhen the subscribed stream falls back to audio only or recovers from audio to audio and video, the SDK triggers the OnRemoteSubscribeFallbackToAudioOnly callback.",
    "parameters": [
      {
        "option": "Fallback option for the subscribed stream. See STREAM_FALLBACK_OPTIONS."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremoteuserspatialaudioparams",
    "name": "SetRemoteUserSpatialAudioParams",
    "description": "Sets the spatial audio parameters for a remote user.\n\nThis method must be called after EnableSpatialAudio. After successfully setting the spatial audio parameters for the remote user, the local user will hear the remote user with spatial effects.",
    "parameters": [
      {
        "uid": "User ID. Must match the user ID used when joining the channel."
      },
      {
        "param": "Spatial audio parameters. See SpatialAudioParams."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremotevideostreamtype",
    "name": "SetRemoteVideoStreamType",
    "description": "Sets the video stream type to subscribe to.\n\nDepending on the sender's default behavior and the specific configuration of SetDualStreamMode [2/2], the receiver's behavior when calling this method is as follows:\n By default, the SDK enables small stream adaptive mode (AUTO_SIMULCAST_STREAM) on the sender side, meaning the sender only sends the high-quality stream. Only receivers with host roles can call this method to request the low-quality stream. Once the sender receives the request, it starts sending the low-quality stream automatically. At this point, all users in the channel can call this method to switch to the low-quality stream subscription mode.\n If the sender calls SetDualStreamMode [2/2] and sets mode to DISABLE_SIMULCAST_STREAM (never send low-quality stream), this method has no effect.\n If the sender calls SetDualStreamMode [2/2] and sets mode to ENABLE_SIMULCAST_STREAM (always send low-quality stream), both host and audience roles on the receiver side can call this method to switch to low-quality stream subscription mode. When receiving a low-quality video stream, the SDK dynamically adjusts the video stream size based on the size of the video window to save bandwidth and computing resources. The aspect ratio of the low-quality stream is the same as that of the high-quality stream. Based on the current high-quality stream's aspect ratio, the system automatically assigns resolution, frame rate, and bitrate for the low-quality stream.\n This method can be called before or after joining a channel.\n If you call both this method and SetRemoteDefaultVideoStreamType, the SDK uses the configuration in this method.",
    "parameters": [
      {
        "uid": "User ID."
      },
      {
        "streamType": "Video stream type: VIDEO_STREAM_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremotevideosubscriptionoptions",
    "name": "SetRemoteVideoSubscriptionOptions",
    "description": "Sets the subscription options for the remote video stream.\n\nWhen the remote user sends dual streams, you can call this method to set the subscription options for the remote video stream. The SDK's default subscription behavior for remote video streams depends on the type of video observer registered:\n If IVideoFrameObserver is registered, both raw and encoded data are subscribed to by default.\n If IVideoEncodedFrameObserver is registered, only encoded data is subscribed to by default.\n If both observers are registered, the default follows the one registered later. For example, if IVideoFrameObserver is registered later, both raw and encoded data are subscribed to by default. If you want to change the default behavior above or set different subscription options for different uid s, you can call this method.",
    "parameters": [
      {
        "uid": "The remote user ID."
      },
      {
        "options": "Subscription settings for the video stream. See VideoSubscriptionOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setremotevoiceposition",
    "name": "SetRemoteVoicePosition",
    "description": "Sets the 2D position of a remote user's voice, i.e., horizontal plane position.\n\nSets the 2D position and volume of a remote user's voice to help the local user perceive directionality.\nBy calling this API to set the position of a remote user's voice, the difference between the left and right audio channels creates a sense of direction, allowing the user to determine the real-time position of the remote user. In multiplayer online games, such as battle royale games, this method can effectively enhance the spatial awareness of game characters and simulate real scenarios.\n Before using this method, call EnableSoundPositionIndication to enable stereo sound for remote users.\n For the best listening experience, it is recommended to use wired headphones when using this method.\n This method must be called after joining a channel.",
    "parameters": [
      {
        "uid": "The ID of the remote user"
      },
      {
        "pan": "Sets the 2D position of the remote user's voice. Range: [-1.0, 1.0]:\n (Default) 0.0: Voice appears in front.\n -1.0: Voice appears on the left.\n 1.0: Voice appears on the right."
      },
      {
        "gain": "Sets the volume of the remote user's voice. Range: [0.0, 100.0], default is 100.0, indicating the user's original volume. The smaller the value, the lower the volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setrouteincommunicationmode",
    "name": "SetRouteInCommunicationMode",
    "description": "Selects the audio route in communication volume mode.\n\nThis method is used in communication volume mode ([MODE_IN_COMMUNICATION](https://developer.android.google.cn/reference/kotlin/android/media/AudioManager?hl=en#mode_in_communication)) to switch the audio route from a Bluetooth headset to the earpiece, wired headset, or speaker. This method is for Android only.\nUsing this method together with SetEnableSpeakerphone may cause conflicts. Agora recommends using SetRouteInCommunicationMode alone.",
    "parameters": [
      {
        "route": "The desired audio route:\n -1: System default audio route.\n 0: Headset with microphone.\n 1: Earpiece.\n 2: Headset without microphone.\n 3: Built-in speaker.\n 4: (Not supported yet) External speaker.\n 5: Bluetooth headset.\n 6: USB device."
      }
    ],
    "returns": "No practical significance.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setscreencapturecontenthint",
    "name": "SetScreenCaptureContentHint",
    "description": "Sets the content type for screen sharing.\n\nThe SDK uses different algorithms to optimize the sharing experience based on the content type. If you do not call this method, the SDK sets the content type to CONTENT_HINT_NONE by default. This method can be called before or after starting screen sharing.",
    "parameters": [
      {
        "contentHint": "The content type for screen sharing. See VIDEO_CONTENT_HINT."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameter.\n -8: Invalid screen sharing state. Possibly because you are already sharing another screen or window. Try calling StopScreenCapture [1/2] to stop the current sharing and then restart screen sharing.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setscreencapturescenario",
    "name": "SetScreenCaptureScenario",
    "description": "Sets the screen sharing scenario.\n\nWhen starting screen or window sharing, you can call this method to set the screen sharing scenario. The SDK adjusts the quality of the shared content based on the scenario. Agora recommends calling this method before joining a channel.",
    "parameters": [
      {
        "screenScenario": "The screen sharing scenario. See SCREEN_SCENARIO_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setsubscribeaudioallowlist",
    "name": "SetSubscribeAudioAllowlist",
    "description": "Sets the audio subscription allowlist.\n\nYou can call this method to specify the audio streams you want to subscribe to.\n You can call this method either before or after joining a channel.\n The audio subscription allowlist is not affected by MuteRemoteAudioStream, MuteAllRemoteAudioStreams, or the autoSubscribeAudio setting in ChannelMediaOptions.\n After setting the allowlist, it remains effective even if you leave and rejoin the channel.\n If a user is in both the audio subscription allowlist and blocklist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the audio subscription allowlist.\nIf you want to subscribe to the audio stream of a specific user, add the user's ID to this list. To remove a user from the allowlist, you need to call SetSubscribeAudioAllowlist again with an updated list that does not include the uid of the user you want to remove."
      },
      {
        "uidNumber": "The number of users in the allowlist."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setsubscribeaudioblocklist",
    "name": "SetSubscribeAudioBlocklist",
    "description": "Sets the audio subscription blocklist.\n\nYou can call this method to specify the audio streams you do not want to subscribe to.\n You can call this method before or after joining a channel.\n The audio subscription blocklist is not affected by MuteRemoteAudioStream, MuteAllRemoteAudioStreams, or autoSubscribeAudio in ChannelMediaOptions.\n After setting the blocklist, it remains effective even if you leave and rejoin the channel.\n If a user appears in both the audio subscription blocklist and allowlist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the audio subscription blocklist.\nIf you want to block the audio stream from a specific user, add the user's ID to this list. To remove a user from the blocklist, you need to call SetSubscribeAudioBlocklist again to update the list so that it no longer includes the user's uid."
      },
      {
        "uidNumber": "The number of users in the audio subscription blocklist."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setsubscribevideoallowlist",
    "name": "SetSubscribeVideoAllowlist",
    "description": "Sets the video subscription allowlist.\n\nYou can call this method to specify the video streams you want to subscribe to.\n You can call this method before or after joining a channel.\n The video subscription allowlist is not affected by MuteRemoteVideoStream, MuteAllRemoteVideoStreams, or autoSubscribeVideo in ChannelMediaOptions.\n After setting the allowlist, it remains effective even if you leave and rejoin the channel.\n If a user appears in both the audio subscription blocklist and allowlist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the video subscription allowlist.\nIf you want to subscribe only to the video stream from a specific user, add the user's ID to this list. To remove a user from the allowlist, you need to call SetSubscribeVideoAllowlist again to update the video subscription allowlist so that it no longer includes the user's uid."
      },
      {
        "uidNumber": "The number of users in the video subscription allowlist."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setsubscribevideoblocklist",
    "name": "SetSubscribeVideoBlocklist",
    "description": "Sets the video subscription blocklist.\n\nYou can call this method to specify the video streams you do not want to subscribe to.\n You can call this method before or after joining a channel.\n The video subscription blocklist is not affected by MuteRemoteVideoStream, MuteAllRemoteVideoStreams, or autoSubscribeVideo in ChannelMediaOptions.\n After setting the blocklist, it remains effective even if you leave and rejoin the channel.\n If a user appears in both the audio subscription blocklist and allowlist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the video subscription blocklist.\nIf you want to block the video stream from a specific user, add the user's ID to this list. To remove a user from the blocklist, you need to call SetSubscribeVideoBlocklist again to update the list so that it no longer includes the user's uid."
      },
      {
        "uidNumber": "The number of users in the video subscription blocklist."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setuplocalvideo",
    "name": "SetupLocalVideo",
    "description": "Initializes the local view.\n\nThis method initializes the local view and sets the display properties of the local user's video. It only affects the video image seen by the local user and does not affect the publishing of the local video. Calling this method binds the display window (view) of the local video stream and sets the rendering and mirror mode of the local user view.\nThe binding remains effective after leaving the channel. To stop rendering or unbind, you can call this method and set the view parameter to NULL to stop rendering and clear the rendering cache.\n In Flutter, you do not need to call this method manually. Use AgoraVideoView to render local and remote views.\n If you want to render images in a native window, call this method; if you only need to render images within a Unity project, you can use the VideoSurface class directly.\n If you only want to update the rendering or mirror mode of the local user view during a call, use the SetLocalRenderMode [2/2] method.",
    "parameters": [
      {
        "canvas": "Local video display properties. See VideoCanvas."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setupremotevideo",
    "name": "SetupRemoteVideo",
    "description": "Initializes the remote user view.\n\nThis method binds the remote user and the display view, and sets the rendering and mirror mode of the remote user view when displayed locally. It only affects the video image seen by the local user.\nYou need to specify the user ID of the remote video when calling this method. It is generally recommended to set it before joining the channel. If you cannot obtain the remote user's ID before joining the channel, you can call this method upon receiving the OnUserJoined callback.\nTo unbind a remote user's view, call this method and set view to null.\nAfter leaving the channel, the SDK will clear the binding of the remote user view.\nIn mobile custom composite layout scenarios, you can call this method and set a separate view for each sub-video stream of the composite video stream for rendering.\n If you want to render images in a native window, call this method; if you only need to render images within a Unity project, you can use the VideoSurface class directly.\n If you want to update the rendering or mirror mode of the remote user view during a call, use the SetRemoteRenderMode method.\n When using the recording service, since it does not send video streams, the app does not need to bind a view for it. If the app cannot identify the recording service, it can bind the remote user view upon receiving the OnFirstRemoteVideoDecoded callback.",
    "parameters": [
      {
        "canvas": "Remote video display properties. See VideoCanvas."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setvideodenoiseroptions",
    "name": "SetVideoDenoiserOptions",
    "description": "Sets the video denoising feature.\n\nYou can call this method to enable the video denoising feature and set its effect. If the denoising strength provided by this method does not meet your needs, Agora recommends that you call the SetBeautyEffectOptions method to enable the beauty smoothing feature for better video denoising. Recommended BeautyOptions settings for strong denoising effect: lighteningContrastLevel : LIGHTENING_CONTRAST_NORMAL lighteningLevel : 0.0 smoothnessLevel : 0.5 rednessLevel : 0.0 sharpnessLevel : 0.1\n This method depends on the video enhancement dynamic library libagora_clear_vision_extension.dll. Deleting this library will cause the feature to fail.\n Video denoising requires certain device performance. If the device overheats after enabling this feature, it is recommended to reduce the denoising level or disable the feature.",
    "parameters": [
      {
        "enabled": "Whether to enable video denoising: true : Enable video denoising. false : (Default) Disable video denoising."
      },
      {
        "options": "Video denoising options for setting the effect. See VideoDenoiserOptions."
      },
      {
        "type": "The media source type to which the effect is applied. See MEDIA_SOURCE_TYPE. In this method, this parameter only supports the following two settings:\n When capturing local video using the camera, keep the default value PRIMARY_CAMERA_SOURCE.\n To use custom captured video, set this parameter to CUSTOM_VIDEO_SOURCE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setvideoencoderconfiguration",
    "name": "SetVideoEncoderConfiguration",
    "description": "Sets the video encoding properties.\n\nSets the encoding properties for the local video. Each video encoding configuration corresponds to a set of video-related parameters, including resolution, frame rate, and bitrate.\n The config parameter of this method specifies the maximum values achievable under ideal network conditions. If the network condition is poor, the video engine may not use this config to render the local video and will automatically downgrade to a suitable video parameter setting.",
    "parameters": [
      {
        "config": "Video encoding parameter configuration. See VideoEncoderConfiguration."
      }
    ],
    "returns": "0: Method call succeeded.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setvideoscenario",
    "name": "SetVideoScenario",
    "description": "Sets the video application scenario.\n\nAfter successfully setting the video application scenario using this method, the SDK enables best practice strategies based on the specified scenario, automatically adjusting key performance indicators to optimize video experience quality. This method must be called before joining a channel.",
    "parameters": [
      {
        "scenarioType": "Video application scenario. See VIDEO_APPLICATION_SCENARIO_TYPE. APPLICATION_SCENARIO_MEETING (1) is suitable for meeting scenarios. If the user has called SetDualStreamMode [2/2] to set the low stream to never send (DISABLE_SIMULCAST_STREAM), the meeting scenario does not support dynamic switching of the low stream.\nThis enum value is only applicable to broadcaster vs broadcaster scenarios. The SDK enables the following strategies for this scenario:\n For meetings with high bitrate requirements for the low stream, multiple weak network resistance technologies are automatically enabled to enhance the low stream's resistance and ensure smoothness when subscribing to multiple streams.\n Real-time monitoring of the number of subscribers to the high stream, dynamically adjusting the high stream configuration:\n When no one subscribes to the high stream, the bitrate and frame rate of the high stream are automatically reduced to save uplink bandwidth and consumption.\n When someone subscribes to the high stream, it resets to the VideoEncoderConfiguration from the most recent SetVideoEncoderConfiguration call. If no configuration was previously set, the following defaults are used:\n Video resolution: 1280 Ã— 720 for desktop; 960 Ã— 540 for mobile\n Frame rate: 15 fps\n Bitrate: 1600 Kbps for desktop; 1000 Kbps for mobile\n Real-time monitoring of the number of subscribers to the low stream, dynamically enabling or disabling the low stream:\n When no one subscribes to the low stream, it is automatically disabled to save uplink bandwidth and consumption.\n When someone subscribes to the low stream, it is enabled and reset to the SimulcastStreamConfig from the most recent SetDualStreamMode [2/2] call. If no configuration was previously set, the following defaults are used:\n Video resolution: 480 Ã— 272\n Frame rate: 15 fps\n Bitrate: 500 Kbps APPLICATION_SCENARIO_1V1 (2) is suitable for [1v1 video call](https://doc.shengwang.cn/doc/one-to-one-live/android/rtm/overview/product-overview) scenarios. The SDK optimizes strategies for low latency and high-quality experience, improving video quality, first frame rendering, latency on mid- and low-end devices, and smoothness under weak networks. APPLICATION_SCENARIO_LIVESHOW (3) is suitable for [showroom live streaming](https://doc.shengwang.cn/doc/showroom/android/overview/product-overview) scenarios. For this scenario's high demands on first frame rendering time and image clarity, the SDK optimizes strategies such as enabling audio and video frame accelerated rendering by default to improve first frame experience, removing the need to call EnableInstantMediaRendering, and enabling B-frames by default to ensure high image quality and transmission efficiency. It also enhances video quality and smoothness under weak networks and on low-end devices."
      }
    ],
    "returns": "0: Method call succeeded.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -1: General error (not specifically categorized).\n -4: Setting the video scenario is not supported. This may be because the current SDK is audio-only.\n -7: The IRtcEngine object has not been initialized. You must initialize the IRtcEngine object successfully before calling this method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setvoicebeautifierparameters",
    "name": "SetVoiceBeautifierParameters",
    "description": "Sets the parameters for preset voice beautifier effects.\n\nCall this method to set the gender characteristics and reverb effect for the singing beautifier. This method applies to the local publishing user. After setting, all users in the channel can hear the effect.\nTo achieve better vocal effects, it is recommended to perform the following before calling this method:\n Call SetAudioScenario to set the audio scenario to high-quality, i.e., AUDIO_SCENARIO_GAME_STREAMING (3).\n Call SetAudioProfile [2/2] to set profile to AUDIO_PROFILE_MUSIC_HIGH_QUALITY (4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5).\n This method can be called before and after joining a channel.\n Do not set the profile parameter of SetAudioProfile [2/2] to AUDIO_PROFILE_SPEECH_STANDARD (1) or AUDIO_PROFILE_IOT (6), otherwise this method will not take effect.\n This method is optimized for vocal processing and is not recommended for audio data containing music.\n After calling SetVoiceBeautifierParameters, do not call the following methods, otherwise the effect set by SetVoiceBeautifierParameters will be overridden: SetAudioEffectPreset SetAudioEffectParameters SetVoiceBeautifierPreset SetLocalVoicePitch SetLocalVoiceEqualization SetLocalVoiceReverb SetVoiceConversionPreset\n This method depends on the voice beautifier dynamic library libagora_audio_beauty_extension.dll. Deleting this library will cause the feature to fail.",
    "parameters": [
      {
        "preset": "Preset effect: SINGING_BEAUTIFIER : Singing beautifier."
      },
      {
        "param1": "Gender characteristic of the singing voice: 1 : Male voice. 2 : Female voice."
      },
      {
        "param2": "Reverb effect of the singing voice: 1 : Small room reverb. 2 : Large room reverb. 3 : Hall reverb."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setvoicebeautifierpreset",
    "name": "SetVoiceBeautifierPreset",
    "description": "Sets the preset voice beautifier effect.\n\nCall this method to set a preset vocal beautifier effect for the local publishing user. After setting the beautifier effect, all users in the channel can hear the effect. You can set different beautifier effects for users based on different scenarios.\n Do not set the profile parameter of SetAudioProfile [2/2] to AUDIO_PROFILE_SPEECH_STANDARD (1) or AUDIO_PROFILE_IOT (6), otherwise this method will not take effect.\n This method is optimized for vocal processing and is not recommended for audio data containing music.\n After calling SetVoiceBeautifierPreset, do not call the following methods, otherwise the effect set by SetVoiceBeautifierPreset will be overridden: SetAudioEffectPreset SetAudioEffectParameters SetLocalVoicePitch SetLocalVoiceEqualization SetLocalVoiceReverb SetVoiceBeautifierParameters SetVoiceConversionPreset\n This method depends on the voice beautifier dynamic library libagora_audio_beauty_extension.dll. Deleting this library will cause the feature to fail.",
    "parameters": [
      {
        "preset": "Preset beautifier effect option. See VOICE_BEAUTIFIER_PRESET."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setvoiceconversionpreset",
    "name": "SetVoiceConversionPreset",
    "description": "Sets a preset voice conversion effect.\n\nCall this method to set a preset voice conversion effect provided by the SDK for the local user who is sending audio. Once set, all users in the channel can hear the effect. You can apply different voice conversion effects depending on the scenario.\n Do not set the profile parameter of SetAudioProfile [2/2] to AUDIO_PROFILE_SPEECH_STANDARD (1) or AUDIO_PROFILE_IOT (6), or this method will not take effect.\n This method provides the best effect for voice. It is not recommended to use it for audio data containing music.\n After calling SetVoiceConversionPreset, do not call the following methods, or the effect set by SetVoiceConversionPreset will be overridden: SetAudioEffectPreset SetAudioEffectParameters SetVoiceBeautifierPreset SetVoiceBeautifierParameters SetLocalVoicePitch SetLocalVoiceFormant SetLocalVoiceEqualization SetLocalVoiceReverb\n This method depends on the voice beautifier dynamic library libagora_audio_beauty_extension.dll. Deleting this library will cause this feature to fail to work properly.",
    "parameters": [
      {
        "preset": "The preset voice conversion effect option: VOICE_CONVERSION_PRESET."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_setvolumeofeffect",
    "name": "SetVolumeOfEffect",
    "description": "Sets the playback volume of the specified audio effect file.",
    "parameters": [
      {
        "soundId": "The ID of the specified audio effect. Each audio effect has a unique ID."
      },
      {
        "volume": "Playback volume. The range is [0,100]. The default value is 100, which means the original volume."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startaudiomixing",
    "name": "StartAudioMixing [1/2]",
    "description": "Starts playing a music file.\n\nFor supported audio file formats, see [What audio formats does the RTC SDK support for playback](https://doc.shengwang.cn/faq/general-product-inquiry/audio-format). If the local music file does not exist, the file format is not supported, or the online music file URL is inaccessible, the SDK reports AUDIO_MIXING_REASON_CAN_NOT_OPEN.\n Using this method to play short sound effect files may result in playback failure. To play sound effects, use PlayEffect instead.\n If you need to call this method multiple times, ensure the interval between calls is greater than 500 ms.\n When calling this method on Android, note the following:\n Ensure the device runs Android 4.2 or above, with API Level not lower than 16.\n If playing an online music file, avoid using redirect URLs. Redirects may not work on some devices.\n If calling this method on an emulator, ensure the music file is located under /sdcard/ and is in MP3 format.",
    "parameters": [
      {
        "filePath": "The path to the file to play. Supports URLs for online files and absolute paths for local files, including the file name and extension. Supported formats include MP3, AAC, M4A, MP4, WAV, 3GP, etc. If you have preloaded the sound effect into memory using PreloadEffect, ensure this parameter matches the filePath specified in PreloadEffect."
      },
      {
        "loopback": "Whether to play the music file locally only: true : Play locally only. Only the local user hears the music. false : Publish the music to remote users. Both local and remote users hear the music."
      },
      {
        "cycle": "The number of times to play the music file.\n > 0: Number of times to play. For example, 1 means play once.\n -1: Loop playback indefinitely."
      }
    ],
    "returns": "0: Success.\n < 0: Failure:\n -1: General error (unspecified).\n -2: Invalid parameter.\n -3: SDK not ready:\n Check if the audio module is enabled.\n Check the integrity of the assembly. IRtcEngine initialization failed. Reinitialize IRtcEngine.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startaudiomixing2",
    "name": "StartAudioMixing [2/2]",
    "description": "Starts playing a music file.\n\nFor supported audio file formats, see [Which audio file formats does the RTC SDK support](https://doc.shengwang.cn/faq/general-product-inquiry/audio-format). If the local music file does not exist, the file format is not supported, or the online music file URL is inaccessible, the SDK reports AUDIO_MIXING_REASON_CAN_NOT_OPEN.\n Using this method to play short sound effect files may result in playback failure. To play sound effects, use PlayEffect instead.\n If you need to call this method multiple times, ensure that the interval between calls is greater than 500 ms.\n When calling this method on Android, note the following:\n Ensure that the device runs Android 4.2 or later, and the API Level is at least 16.\n If playing an online music file, avoid using a redirect URL. Redirect URLs may not work on some devices.\n If calling this method on an emulator, ensure the music file is located in the /sdcard/ directory and is in MP3 format.",
    "parameters": [
      {
        "filePath": "File path:\n Android: File path, including the file name and extension. Supports URL of online files, URI of local files, absolute path, or path starting with /assets/. Accessing local files via absolute path may cause permission issues. It is recommended to use URI to access local files. For example: content://com.android.providers.media.documents/document/audio%3A14441.\n Windows: Absolute path or URL of the audio file, including the file name and extension. For example: C:\\music\\audio.mp4.\n iOS or macOS: Absolute path or URL of the audio file, including the file name and extension. For example: /var/mobile/Containers/Data/audio.mp4."
      },
      {
        "loopback": "Whether to play the music file only locally: true : Plays the music file locally only. Only the local user can hear the music. false : Publishes the music file to remote users. Both local and remote users can hear the music."
      },
      {
        "cycle": "Number of times the music file is played.\n > 0: Number of times to play. For example, 1 means play once.\n -1: Play in an infinite loop."
      },
      {
        "startPos": "The playback position of the music file, in milliseconds."
      }
    ],
    "returns": "0: Success.\n < 0: Failure:\n -1: General error (not specifically classified).\n -2: Invalid parameter.\n -3: SDK not ready:\n Check if the audio module is enabled.\n Check the integrity of the assembly. IRtcEngine failed to initialize. Reinitialize IRtcEngine.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startcameracapture",
    "name": "StartCameraCapture",
    "description": "Starts video capture using the camera.\n\nYou can call this method to start multiple camera captures simultaneously by specifying sourceType. On iOS, to enable multiple camera captures, you must call EnableMultiCamera and set enabled to true before calling this method.",
    "parameters": [
      {
        "sourceType": "The type of video source. See VIDEO_SOURCE_TYPE.\n iOS devices support up to 2 video streams from camera capture (requires devices with multiple cameras or external camera support).\n Android devices support up to 4 video streams from camera capture (requires devices with multiple cameras or external camera support).\n Desktop supports up to 4 video streams from camera capture."
      },
      {
        "config": "Video capture configuration. See CameraCapturerConfiguration. On iOS, this parameter has no effect. Use the config parameter in EnableMultiCamera to configure video capture."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startdirectcdnstreaming",
    "name": "StartDirectCdnStreaming",
    "description": "Starts pushing the stream directly to the CDN from the host.\n\nDeprecated Deprecated since v4.6.2. The SDK does not support pushing to the same URL multiple times simultaneously.\nMedia option notes:\nThe SDK does not support setting both publishCameraTrack and publishCustomVideoTrack to true, nor does it support setting both publishMicrophoneTrack and publishCustomAudioTrack to true. You can configure the media options (DirectCdnStreamingMediaOptions) based on your scenario. For example:\nIf you want to push custom audio and video streams from the host, configure the media options as follows:\n Set publishCustomAudioTrack to true and call PushAudioFrame\n Set publishCustomVideoTrack to true and call PushVideoFrame\n Ensure publishCameraTrack is false (default)\n Ensure publishMicrophoneTrack is false (default) Since v4.2.0, the SDK supports pushing audio-only streams. You can set publishCustomAudioTrack or publishMicrophoneTrack to true in DirectCdnStreamingMediaOptions and call PushAudioFrame to push audio-only streams.",
    "parameters": [
      {
        "publishUrl": "CDN streaming URL."
      },
      {
        "options": "Media options for the host. See DirectCdnStreamingMediaOptions."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startechotest3",
    "name": "StartEchoTest",
    "description": "Starts an audio and video loop test.\n\nTo test whether local audio and video transmission is functioning properly, you can call this method to perform an audio and video loop test. This tests whether the system's audio/video devices and the user's uplink/downlink network are functioning correctly.\nAfter starting the test, the user should speak or face the camera. The audio or video will be played back in about 2 seconds. If audio plays back correctly, the system's audio devices and the user's network are functioning properly. If video plays back correctly, the system's video devices and the user's network are functioning properly.\n When calling this method in a channel, ensure that no audio/video stream is being published.\n After calling this method, you must call StopEchoTest to end the test. Otherwise, the user will not be able to perform the next loop test or join a channel.\n In a live broadcast scenario, only the host can call this method.",
    "parameters": [
      {
        "config": "Configuration for the audio and video loop test. See EchoTestConfiguration."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startlastmileprobetest",
    "name": "StartLastmileProbeTest",
    "description": "Starts last-mile network quality probe before a call.\n\nPerforms a last-mile network quality probe before a call, providing feedback on uplink and downlink bandwidth, packet loss, jitter, and round-trip time.",
    "parameters": [
      {
        "config": "Last-mile network probe configuration. See LastmileProbeConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startlocalaudiomixer",
    "name": "StartLocalAudioMixer",
    "description": "Starts local audio mixing.\n\nThis method supports merging multiple audio streams locally into a single audio stream. For example: merge audio from the local microphone, media player, sound card, and remote audio streams into one, and then publish the mixed audio stream to the channel.\n To mix locally captured audio streams, set publishMixedAudioTrack in ChannelMediaOptions to true to publish the mixed audio stream to the channel.\n To mix remote audio streams, ensure the remote audio streams are published in the channel and have been subscribed to. To ensure audio quality, it is recommended that no more than 10 audio streams participate in local mixing.",
    "parameters": [
      {
        "config": "Configuration for local audio mixing. See LocalAudioMixerConfiguration."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -7: The IRtcEngine object is not initialized. You need to initialize the IRtcEngine object successfully before calling this method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startlocalvideotranscoder",
    "name": "StartLocalVideoTranscoder",
    "description": "Starts local video transcoding.\n\nAfter calling this method, you can merge multiple video streams into a single stream locally. For example, merge camera-captured video, screen sharing, media player video, remote video, video files, images, etc., into one video stream, and then publish the merged stream to the channel.\n Local video transcoding consumes high CPU resources. Agora recommends using this feature on high-performance devices.\n If you want to transcode locally captured video streams, the SDK supports the following combinations:\n On Windows: up to 4 camera streams + 4 screen sharing streams.\n On macOS: up to 4 camera streams + 1 screen sharing stream.\n On Android and iOS: up to 2 camera streams (requires dual camera support or external camera) + 1 screen sharing stream.\n When configuring the transcoding layout, ensure that the layer ID of the camera stream capturing the portrait is greater than that of the screen sharing stream. Otherwise, the portrait may be covered and not appear in the final merged stream.",
    "parameters": [
      {
        "config": "Configuration for local video transcoding. See LocalTranscoderConfiguration.\n The maximum resolution for each video stream in the transcoding is 4096 Ã— 2160. Exceeding this limit will cause transcoding to fail.\n The maximum resolution of the merged video stream is 4096 Ã— 2160."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startmediarenderingtracing",
    "name": "StartMediaRenderingTracing",
    "description": "Starts video frame rendering tracing.\n\nAfter successfully calling this method, the SDK uses the time of the call as the starting point and reports video frame rendering information through the OnVideoRenderingTracingResult callback.\n If you do not call this method, the SDK uses the time of calling JoinChannel [2/2] to join the channel as the default starting point and automatically starts tracing video rendering events. You can call this method at an appropriate time based on your business scenario to perform custom tracing.\n After leaving the current channel, the SDK automatically resets the starting point to the time of the next channel join.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -7: IRtcEngine is not initialized when the method is called.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startorupdatechannelmediarelay",
    "name": "StartOrUpdateChannelMediaRelay",
    "description": "Starts or updates cross-channel media stream forwarding.\n\nThe first successful call to this method starts forwarding media streams across channels. To forward streams to multiple destination channels or leave a current forwarding channel, you can call this method again to add or remove destination channels. This feature supports forwarding to up to 6 destination channels.\nAfter a successful call, the SDK triggers the OnChannelMediaRelayStateChanged callback to report the current state of cross-channel media stream forwarding. Common states include:\n If the OnChannelMediaRelayStateChanged callback reports RELAY_STATE_RUNNING (2) and RELAY_OK (0), it means the SDK has started forwarding media streams between the source and destination channels.\n If the callback reports RELAY_STATE_FAILURE (3), it means an error occurred during cross-channel media stream forwarding.\n Call this method after successfully joining a channel.\n In a live streaming scenario, only users with the host role can call this method.\n Cross-channel media stream forwarding requires [contacting technical support](https://ticket.shengwang.cn/) to enable.\n This feature does not support String-type UIDs.",
    "parameters": [
      {
        "configuration": "Configuration for cross-channel media stream forwarding. See ChannelMediaRelayConfiguration."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -1: General error (not specifically classified).\n -2: Invalid parameter.\n -8: Internal state error. Possibly because the user role is not host.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startpreview",
    "name": "StartPreview [1/2]",
    "description": "Starts video preview.\n\nThis method starts the local video preview.\n Local preview enables mirror mode by default.\n After leaving the channel, the local preview remains active. You need to call StopPreview [1/2] to stop the local preview.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startpreview2",
    "name": "StartPreview [2/2]",
    "description": "Starts video preview and specifies the video source.\n\nThis method starts the local video preview and specifies the video source to appear in the preview.\n Local preview enables mirror mode by default.\n After leaving the channel, the local preview remains active. You need to call StopPreview [1/2] to stop the local preview.",
    "parameters": [
      {
        "sourceType": "The type of video source. See VIDEO_SOURCE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startrhythmplayer",
    "name": "StartRhythmPlayer",
    "description": "Starts the virtual metronome.\n\nDeprecated Deprecated since v4.6.2.\n Once the virtual metronome is enabled, the SDK starts playing the specified audio files from the beginning and controls the duration of each file based on the beatsPerMinute setting in AgoraRhythmPlayerConfig. For example, if beatsPerMinute is set to 60, the SDK plays 1 beat per second. If the file duration exceeds the beat duration, the SDK only plays the portion of the audio corresponding to the beat duration.\n By default, the virtual metronome sound is not published to the remote. If you want remote users to hear the metronome, set publishRhythmPlayerTrack in ChannelMediaOptions to true after calling this method.",
    "parameters": [
      {
        "sound1": "The absolute path or URL of the strong beat file, including the file name and extension. For example, C:\\music\\audio.mp4. Supported audio formats are listed in [What audio formats does the RTC SDK support](https://doc.shengwang.cn/faq/general-product-inquiry/audio-format)."
      },
      {
        "sound2": "The absolute path or URL of the weak beat file, including the file name and extension. For example, C:\\music\\audio.mp4. Supported audio formats are listed in [What audio formats does the RTC SDK support](https://doc.shengwang.cn/faq/general-product-inquiry/audio-format)."
      },
      {
        "config": "Metronome configuration. See AgoraRhythmPlayerConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure\n -22: Audio file not found. Please provide correct sound1 and sound2.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startrtmpstreamwithouttranscoding",
    "name": "StartRtmpStreamWithoutTranscoding",
    "description": "Starts RTMP streaming without transcoding.\n\nAgora recommends using a more comprehensive server-side streaming feature. See [Implement server-side streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nBy calling this method, you can push live audio and video streams to the specified RTMP address. This method can only push to one address at a time. If you need to push to multiple addresses, call this method multiple times.\nAfter calling this method, the SDK triggers the OnRtmpStreamingStateChanged callback locally to report the streaming state.\n Call this method after joining a channel.\n Only hosts in a live broadcast scenario can call this method.\n If the streaming fails and you want to restart it, make sure to call StopRtmpStream before calling this method again, otherwise the SDK returns the same error code as the last failure.",
    "parameters": [
      {
        "url": "The RTMP or RTMPS streaming URL. The character length must not exceed 1024 bytes. Chinese characters and other special characters are not supported."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid URL or transcoding parameters. Please check your URL or parameter settings.\n -7: The SDK was not initialized before calling this method.\n -19: The RTMP URL is already in use. Please use another RTMP URL.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startrtmpstreamwithtranscoding",
    "name": "StartRtmpStreamWithTranscoding",
    "description": "Starts RTMP streaming with transcoding settings.\n\nAgora recommends using a more comprehensive server-side streaming feature. See [Implement server-side streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nBy calling this method, you can push live audio and video streams to the specified RTMP address and set transcoding parameters. This method can only push to one address at a time. If you need to push to multiple addresses, call this method multiple times.\nEach stream represents a streaming task. The default maximum number of concurrent tasks is 200, meaning you can run up to 200 streaming tasks simultaneously under one Agora project. For higher quotas, please [contact technical support](https://ticket.shengwang.cn/).\nAfter calling this method, the SDK triggers the OnRtmpStreamingStateChanged callback locally to report the streaming state.\n Call this method after joining a channel.\n Only hosts in a live broadcast scenario can call this method.\n If the streaming fails and you want to restart it, make sure to call StopRtmpStream before calling this method again, otherwise the SDK returns the same error code as the last failure.",
    "parameters": [
      {
        "url": "The RTMP or RTMPS streaming URL. The character length must not exceed 1024 bytes. Chinese characters and other special characters are not supported."
      },
      {
        "transcoding": "The transcoding settings for RTMP streaming. See LiveTranscoding."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid URL or transcoding parameters. Please check your URL or parameter settings.\n -7: The SDK was not initialized before calling this method.\n -19: The RTMP URL is already in use. Please use another RTMP URL.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startscreencapture",
    "name": "StartScreenCapture [1/2]",
    "description": "Starts screen capture.\n\nThis method applies to Android and iOS only.\n The billing standard for the screen sharing stream is based on the dimensions value in ScreenVideoParameters :\n If you do not pass a value, billing is based on 1280 Ã— 720.\n If you pass a value, billing is based on the value you provide.\n On iOS, screen sharing is supported on iOS 12.0 and above only.\n On iOS, if you use custom audio capture instead of SDK audio capture, to prevent screen sharing from stopping when the app goes to the background, it is recommended to add keep-alive logic to your app.\n On iOS, this feature requires high device performance. It is recommended to use it on iPhone X and later models.\n On iOS, this method depends on the screen sharing dynamic library AgoraReplayKitExtension.xcframework. Removing this library will cause screen sharing to fail.\n On Android, if the user does not grant screen capture permission to the app, the SDK will report the OnPermissionError(2) callback.\n On Android 9 and later, to prevent the app from being killed when going to the background, it is recommended to add the foreground service permission android.permission.FOREGROUND_SERVICE in the /app/Manifests/AndroidManifest.xml file.\n Due to Android performance limitations, screen sharing is not supported on Android TV.\n Due to Android system limitations, when using Huawei phones for screen sharing, to avoid crashes, do not change the video encoding resolution of the screen sharing stream during sharing.\n Due to Android system limitations, some Xiaomi phones do not support capturing system audio during screen sharing.\n To improve the success rate of capturing system audio during screen sharing, it is recommended to set the audio scenario to AUDIO_SCENARIO_GAME_STREAMING using the SetAudioScenario method before joining the channel.",
    "parameters": [
      {
        "captureParams": "Configuration of encoding parameters for screen sharing. See ScreenCaptureParameters2."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2 (iOS): Parameter is null.\n -2 (Android): System version too low. Ensure the Android API level is at least 21.\n -3 (Android): Unable to capture system audio. Ensure the Android API level is at least 29.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startscreencapture2",
    "name": "StartScreenCapture [2/2]",
    "description": "Starts screen capture and specifies the video source.\n\nThis method applies to macOS and Windows only.\n If you call this method to start screen capture, you need to call StopScreenCapture [2/2] to stop it.\n On Windows, up to 4 screen capture video streams are supported.\n On macOS, only 1 screen capture video stream is supported.",
    "parameters": [
      {
        "sourceType": "Type of video source. See VIDEO_SOURCE_TYPE. On macOS, only VIDEO_SOURCE_SCREEN (2) is supported for this parameter."
      },
      {
        "config": "Screen capture configuration. See ScreenCaptureConfiguration."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startscreencapturebydisplayid",
    "name": "StartScreenCaptureByDisplayId",
    "description": "Starts capturing the video stream of the specified screen.\n\nCaptures the video stream of a screen or a region of the screen. This method applies to Windows and macOS only.",
    "parameters": [
      {
        "displayId": "Specifies the ID of the screen to be shared. On Windows, if you want to share two screens (main + secondary), you can set displayId to -1 when calling this method."
      },
      {
        "regionRect": "(Optional) Specifies the region to be shared relative to the entire screen. To share the full screen, set to nil.\nSee Rectangle."
      },
      {
        "captureParams": "Configuration parameters for screen sharing. The default video encoding resolution is 1920 Ã— 1080, i.e., 2,073,600 pixels. This pixel count is used for billing. See ScreenCaptureParameters. The video properties of the screen sharing stream should be set only through this parameter and are unrelated to SetVideoEncoderConfiguration."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameters.\n -8: Invalid screen sharing state. You may already be sharing another screen or window. Try calling StopScreenCapture [1/2] to stop the current sharing before starting again.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startscreencapturebyscreenrect",
    "name": "StartScreenCaptureByScreenRect",
    "description": "Starts capturing the video stream of a specified screen region.\n\nDeprecated Deprecated: This method is deprecated. Use StartScreenCaptureByDisplayId instead. If you need to enable screen sharing when an external display is connected, it is strongly recommended to use StartScreenCaptureByDisplayId. Shares a screen or a region of the screen. You need to specify the screen region to share in this method.\nThis method can be called before or after joining a channel, with the following differences:\n If you call this method before joining the channel, then call JoinChannel [2/2] and set publishScreenTrack or publishSecondaryScreenTrack to true, screen sharing starts.\n If you call this method after joining the channel, then call UpdateChannelMediaOptions and set publishScreenTrack or publishSecondaryScreenTrack to true, screen sharing starts. This method applies to Windows only.",
    "parameters": [
      {
        "screenRect": "Specifies the position of the screen to be shared relative to the virtual screen."
      },
      {
        "regionRect": "(Optional) Specifies the region to be shared relative to the entire screen. If not set, the entire screen is shared. See Rectangle. If the specified region exceeds the screen boundaries, only the content within the screen is shared. If width or height is set to 0, the entire screen is shared."
      },
      {
        "captureParams": "Configuration of encoding parameters for screen sharing. The default resolution is 1920 x 1080, i.e., 2,073,600 pixels. This pixel count is used for billing. See ScreenCaptureParameters."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid parameters.\n -8: Invalid screen sharing state. You may already be sharing another screen or window. Try calling StopScreenCapture [1/2] to stop the current sharing before starting again.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_startscreencapturebywindowid",
    "name": "StartScreenCaptureByWindowId",
    "description": "Starts capturing the video stream of the specified window.\n\nShares a window or a portion of it. You need to specify the window ID to be shared in this method.\nThis method supports sharing Universal Windows Platform (UWP) application windows. Agora has tested mainstream UWP applications using the latest SDK, with the following results: OS Version Application Compatible Version Supported Windows 10 Chrome 76.0.3809.100 No Office Word 18.1903.1152.0 Yes Office Excel 18.1903.1152.0 No Office PPT 18.1903.1152.0 Yes WPS Word 11.1.0.9145 Yes WPS Excel 11.1.0.9145 Yes WPS PPT 11.1.0.9145 Yes Built-in Media Player All versions Yes Windows 8 Chrome All versions Yes Office Word All versions Yes Office Excel All versions Yes Office PPT All versions Yes WPS Word 11.1.0.9098 Yes WPS Excel 11.1.0.9098 Yes WPS PPT 11.1.0.9098 Yes Built-in Media Player All versions Yes Windows 7 Chrome 73.0.3683.103 No Office Word All versions Yes Office Excel All versions Yes Office PPT All versions Yes WPS Word 11.1.0.9098 No WPS Excel 11.1.0.9098 No WPS PPT 11.1.0.9098 Yes Built-in Media Player All versions No This method is only applicable to macOS and Windows platforms.\nThe SDK's window sharing feature relies on WGC (Windows Graphics Capture) or GDI (Graphics Device Interface). On systems earlier than Windows 10 2004, WGC cannot disable mouse capture, so when sharing a window on such systems, captureMouseCursor(false) may not take effect. See ScreenCaptureParameters.",
    "parameters": [
      {
        "windowId": "Specifies the ID of the window to be shared."
      },
      {
        "regionRect": "(Optional) Specifies the position of the region to be shared relative to the entire screen. If not set, the entire screen is shared. See Rectangle. If the specified region exceeds the window boundaries, only the content within the window is shared; if the width or height is 0, the entire window is shared."
      },
      {
        "captureParams": "Configuration parameters for screen sharing. The default resolution is 1920 x 1080, i.e., 2,073,600 pixels. This pixel count is used for billing. See ScreenCaptureParameters."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: The input parameter is invalid.\n -8: The screen sharing state is invalid. This may occur if you are already sharing another screen or window. Try calling StopScreenCapture [1/2] to stop the current sharing and then restart screen sharing.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopalleffects",
    "name": "StopAllEffects",
    "description": "Stops playback of all audio effect files.\n\nWhen you no longer need to play audio effect files, you can call this method to stop playback. If you only need to pause, call PauseAllEffects.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopaudiomixing",
    "name": "StopAudioMixing",
    "description": "Stops playing the music file.\n\nAfter calling the StartAudioMixing [2/2] method to play a music file, call this method to stop playback. To pause playback, call PauseAudioMixing.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopcameracapture",
    "name": "StopCameraCapture",
    "description": "Stops video capture using the camera.\n\nAfter calling StartCameraCapture to start one or more video streams from camera capture, you can call this method and specify sourceType to stop one or more of them. On iOS, to disable multiple camera captures, you must call EnableMultiCamera and set enabled to false after calling this method.\nIf you are using the local composite feature, stopping the first camera capture using this method will interrupt the local composition.",
    "parameters": [
      {
        "sourceType": "The type of video source. See VIDEO_SOURCE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopchannelmediarelay",
    "name": "StopChannelMediaRelay",
    "description": "Stops cross-channel media stream forwarding. Once stopped, the host leaves all destination channels.\n\nAfter a successful call to this method, the SDK triggers the OnChannelMediaRelayStateChanged callback. If it reports RELAY_STATE_IDLE (0) and RELAY_OK (0), it indicates that media stream forwarding has stopped. If the method call fails, the SDK will trigger the OnChannelMediaRelayStateChanged callback and report the status code RELAY_ERROR_SERVER_NO_RESPONSE (2) or RELAY_ERROR_SERVER_CONNECTION_LOST (8). You can call the LeaveChannel [2/2] method to leave the channel, and cross-channel media stream forwarding will stop automatically.",
    "parameters": [],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -5: This method call was rejected. No cross-channel media stream forwarding is currently in progress.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopdirectcdnstreaming",
    "name": "StopDirectCdnStreaming",
    "description": "Stops pushing the stream directly to the CDN from the host.\n\nDeprecated Deprecated since v4.6.2.",
    "parameters": [],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopechotest",
    "name": "StopEchoTest",
    "description": "Stops the audio loop test.\n\nAfter calling StartEchoTest, you must call this method to end the test. Otherwise, the user will not be able to perform the next audio and video loop test or join a channel.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -5(ERR_REFUSED): Failed to stop the test. The test may not be running.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopeffect",
    "name": "StopEffect",
    "description": "Stops playback of the specified audio effect file.\n\nWhen you no longer need to play a specific audio effect file, you can call this method to stop playback. If you only need to pause, call PauseEffect.",
    "parameters": [
      {
        "soundId": "The ID of the specified audio effect file. Each audio effect file has a unique ID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stoplastmileprobetest",
    "name": "StopLastmileProbeTest",
    "description": "Stops the last-mile network quality probe before a call.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stoplocalaudiomixer",
    "name": "StopLocalAudioMixer",
    "description": "Stops local audio mixing.\n\nAfter calling StartLocalAudioMixer, if you want to stop local audio mixing, call this method.",
    "parameters": [],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -7: The IRtcEngine object is not initialized. You need to initialize the IRtcEngine object successfully before calling this method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stoplocalvideotranscoder",
    "name": "StopLocalVideoTranscoder",
    "description": "Stops local video transcoding.\n\nAfter calling StartLocalVideoTranscoder, call this method to stop local video transcoding.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stoppreview",
    "name": "StopPreview [1/2]",
    "description": "Stops video preview.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stoppreview2",
    "name": "StopPreview [2/2]",
    "description": "Stops video preview.",
    "parameters": [
      {
        "sourceType": "The type of video source. See VIDEO_SOURCE_TYPE."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stoprhythmplayer",
    "name": "StopRhythmPlayer",
    "description": "Stops the virtual metronome.\n\nAfter calling StartRhythmPlayer, you can call this method to stop the virtual metronome. (Android and iOS only)",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stoprtmpstream",
    "name": "StopRtmpStream",
    "description": "Stops the RTMP stream.\n\nAgora recommends using a more complete server-side streaming service. See [Implement Server-Side RTMP Streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nCall this method to stop the live stream at the specified RTMP streaming URL. This method can only stop one stream at a time. To stop multiple streams, call this method multiple times.\nAfter calling this method, the SDK triggers the OnRtmpStreamingStateChanged callback locally to report the streaming status.",
    "parameters": [
      {
        "url": "The RTMP streaming URL. Must be in RTMP or RTMPS format. The character length cannot exceed 1024 bytes. Special characters such as Chinese characters are not supported."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopscreencapture",
    "name": "StopScreenCapture [1/2]",
    "description": "Stops screen capture.",
    "parameters": [],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_stopscreencapture2",
    "name": "StopScreenCapture [2/2]",
    "description": "Stops screen capture for the specified video source.\n\nThis method is only applicable to macOS and Windows platforms.",
    "parameters": [
      {
        "sourceType": "The type of video source. See VIDEO_SOURCE_TYPE."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_switchcamera",
    "name": "SwitchCamera",
    "description": "Switches between front and rear cameras.\n\nYou can call this method during app runtime to dynamically switch cameras based on the actual availability without restarting the video stream or reconfiguring the video source. This method is applicable to Android and iOS only.\nThis method only switches the camera for the first video stream captured by the camera, i.e., the video source set to VIDEO_SOURCE_CAMERA (0) when calling StartCameraCapture.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_takesnapshot",
    "name": "TakeSnapshot [1/2]",
    "description": "Captures a video snapshot.\n\nThis method captures a snapshot of the specified user's video stream, generates a JPG image, and saves it to the specified path.\n This method is asynchronous. When the call returns, the SDK has not yet completed the snapshot.\n When used for local video snapshots, it captures the video stream specified in ChannelMediaOptions.\n If the video has been post-processed (e.g., with watermark or beautification), the snapshot will include the effects.",
    "parameters": [
      {
        "uid": "User ID. Set to 0 to capture a snapshot of the local user's video."
      },
      {
        "filePath": "Make sure the directory exists and is writable. Local path to save the snapshot, including file name and format. For example:\n Windows: C:\\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\example.jpg\n iOS: /App Sandbox/Library/Caches/example.jpg\n macOS: ï½ž/Library/Logs/example.jpg\n Android: /storage/emulated/0/Android/data/<package name>/files/example.jpg"
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_takesnapshot2",
    "name": "TakeSnapshot [2/2]",
    "description": "Captures a video snapshot at a specified observation point.\n\nThis method captures a snapshot of the specified user's video stream, generates a JPG image, and saves it to the specified path.\n This method is asynchronous. When the call returns, the SDK has not yet completed the snapshot.\n When used for local video snapshots, it captures the video stream specified in ChannelMediaOptions.",
    "parameters": [
      {
        "uid": "User ID. Set to 0 to capture a snapshot of the local user's video."
      },
      {
        "config": "Snapshot configuration. See SnapshotConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_unloadalleffects",
    "name": "UnloadAllEffects",
    "description": "Releases all preloaded audio effect files from memory.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_unloadeffect",
    "name": "UnloadEffect",
    "description": "Releases a preloaded audio effect file from memory.\n\nAfter calling PreloadEffect to load an audio effect file into memory, you can call this method to release it.",
    "parameters": [
      {
        "soundId": "The ID of the specified audio effect file. Each audio effect file has a unique ID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_unregisteraudioencodedframeobserver",
    "name": "UnRegisterAudioEncodedFrameObserver",
    "description": "Unregisters the audio encoded frame observer.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_unregisteraudioframeobserver",
    "name": "UnRegisterAudioFrameObserver",
    "description": "Unregisters the audio frame observer.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_unregisteraudiospectrumobserver",
    "name": "UnregisterAudioSpectrumObserver",
    "description": "Unregisters the audio spectrum observer.\n\nAfter calling RegisterAudioSpectrumObserver, if you want to unregister the audio spectrum observer, call this method. This method can be called either before or after joining a channel.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_unregistermediametadataobserver",
    "name": "UnregisterMediaMetadataObserver",
    "description": "Unregisters the media metadata observer.",
    "parameters": [],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatechannelmediaoptions",
    "name": "UpdateChannelMediaOptions",
    "description": "Updates channel media options after joining the channel.",
    "parameters": [
      {
        "options": "Channel media options. See ChannelMediaOptions."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid ChannelMediaOptions member values. For example, using an invalid token or setting an invalid user role. You need to provide valid parameters.\n -7: The IRtcEngine object is not initialized. You must successfully initialize the IRtcEngine object before calling this method.\n -8: Internal state error of the IRtcEngine object. This may be because the user is not in the channel. It is recommended to use the OnConnectionStateChanged callback to determine whether the user is in the channel. If you receive CONNECTION_STATE_DISCONNECTED (1) or CONNECTION_STATE_FAILED (5), it means the user is not in the channel. You need to call JoinChannel [2/2] before calling this method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatelocalaudiomixerconfiguration",
    "name": "UpdateLocalAudioMixerConfiguration",
    "description": "Updates the configuration for local audio mixing.\n\nAfter calling StartLocalAudioMixer, if you want to update the configuration for local audio mixing, call this method. To ensure audio quality, it is recommended that no more than 10 audio streams participate in local mixing.",
    "parameters": [
      {
        "config": "Configuration for local audio mixing. See LocalAudioMixerConfiguration."
      }
    ],
    "returns": "0: Method call succeeds.\n < 0: Method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -7: The IRtcEngine object is not initialized. You need to initialize the IRtcEngine object successfully before calling this method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatelocaltranscoderconfiguration",
    "name": "UpdateLocalTranscoderConfiguration",
    "description": "Updates local video transcoding configuration.\n\nAfter calling StartLocalVideoTranscoder, call this method to update the local video transcoding configuration. If you want to update the type of local video source used for transcoding, such as adding a second camera or screen capture, call this method after StartCameraCapture or StartScreenCapture [2/2].",
    "parameters": [
      {
        "config": "Configuration for local video transcoding. See LocalTranscoderConfiguration."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatepreloadchanneltoken",
    "name": "UpdatePreloadChannelToken",
    "description": "Updates the wildcard token for the preloaded channel.\n\nYou need to manage the lifecycle of the wildcard token yourself. When the wildcard token expires, you need to generate a new one on your server and pass it in using this method.",
    "parameters": [
      {
        "token": "The new token."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: The input parameter is invalid. For example, an invalid token is used. You need to provide valid parameters and rejoin the channel.\n -7: The IRtcEngine object is not initialized. You must successfully initialize the IRtcEngine object before calling this method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatertmptranscoding",
    "name": "UpdateRtmpTranscoding",
    "description": "Updates the RTMP transcoding configuration.\n\nAgora recommends using a more complete server-side streaming service. See [Implement Server-Side RTMP Streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nAfter enabling transcoding streaming, you can dynamically update the transcoding configuration based on your scenario. After the transcoding configuration is updated, the SDK triggers the OnTranscodingUpdated callback.",
    "parameters": [
      {
        "transcoding": "The RTMP transcoding configuration. See LiveTranscoding."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatescreencapture",
    "name": "UpdateScreenCapture",
    "description": "Updates the configuration parameters for screen capture.\n\nIf system audio was not captured when screen sharing started and you want to update the configuration to publish system audio, follow these steps:\n Call this method and set captureAudio to true.\n Call UpdateChannelMediaOptions and set publishScreenCaptureAudio to true to publish the captured audio.\n This method is only applicable to Android and iOS platforms.\n On iOS, screen sharing is only supported on iOS 12.0 and later.",
    "parameters": [
      {
        "captureParams": "Encoding configuration parameters for screen sharing. See ScreenCaptureParameters2."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails.\n -2: The input parameter is invalid.\n -8: The screen sharing state is invalid. This may occur if you are already sharing another screen or window. Try calling StopScreenCapture [1/2] to stop the current sharing and then restart screen sharing.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatescreencaptureparameters",
    "name": "UpdateScreenCaptureParameters",
    "description": "Updates the configuration parameters for screen capture.\n\nThis method is only applicable to Windows and macOS platforms.\n Call this method after starting screen or window sharing.",
    "parameters": [
      {
        "captureParams": "Encoding configuration parameters for screen sharing. See ScreenCaptureParameters. The video properties of the screen sharing stream should be set only through this parameter and are unrelated to SetVideoEncoderConfiguration."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: The input parameter is invalid.\n -8: The screen sharing state is invalid. This may occur if you are already sharing another screen or window. Try calling StopScreenCapture [1/2] to stop the current sharing and then restart screen sharing.",
    "is_hide": false
  },
  {
    "id": "api_irtcengine_updatescreencaptureregion1",
    "name": "UpdateScreenCaptureRegion",
    "description": "Updates the region for screen capture.\n\nCall this method after starting screen or window sharing.",
    "parameters": [
      {
        "regionRect": "The position of the region to be shared relative to the entire screen or window. If not set, the entire screen or window is shared. See Rectangle. If the specified region exceeds the screen or window boundaries, only the content within the screen or window is shared; if width or height is set to 0, the entire screen or window is shared."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: The input parameter is invalid.\n -8: The screen sharing state is invalid. This may occur if you are already sharing another screen or window. Try calling StopScreenCapture [1/2] to stop the current sharing and then restart screen sharing.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_addvideowatermarkex",
    "name": "AddVideoWatermarkEx [1/2]",
    "description": "Adds a local video watermark.\n\nDeprecated Deprecated: This method is deprecated. Use addVideoWatermarkEx [2/2] instead. This method adds a PNG image as a watermark to the local published live video stream. Users in the same live channel, CDN audience, and capture devices can see or capture the watermark image. Currently, only one watermark is supported in the live video stream. Adding a new watermark will replace the previous one.\nThe watermark coordinates depend on the settings in SetVideoEncoderConfigurationEx :\n If the video orientation (ORIENTATION_MODE) is fixed to landscape or adaptive landscape, landscape coordinates are used.\n If the video orientation is fixed to portrait or adaptive portrait, portrait coordinates are used.\n When setting watermark coordinates, the image area must not exceed the video dimensions set in SetVideoEncoderConfigurationEx, otherwise the excess will be cropped.\n You must call this method after calling EnableVideo.\n The watermark image must be in PNG format. This method supports all PNG pixel formats: RGBA, RGB, Palette, Gray, and Alpha_gray.\n If the size of the PNG image differs from the size set in this method, the SDK will scale or crop the image to match the settings.\n If you have already started local video preview using StartPreview [2/2], the visibleInPreview parameter in this method can control whether the watermark is visible during preview.\n If local video is set to mirror mode, the local watermark will also be mirrored. To avoid mirrored watermark for local users, it is recommended not to use both mirror and watermark features together. Implement watermark at the application layer instead.",
    "parameters": [
      {
        "watermarkUrl": "The local path of the watermark image to be added. This method supports adding watermark images from absolute/relative local paths."
      },
      {
        "options": "Settings for the watermark image. See WatermarkOptions."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_adjustuserplaybacksignalvolumeex",
    "name": "AdjustUserPlaybackSignalVolumeEx",
    "description": "Adjusts the playback volume of a specified remote user locally.\n\nYou can call this method during a call to adjust the playback volume of a specified remote user locally. To adjust the volume for multiple users, call this method multiple times.",
    "parameters": [
      {
        "uid": "Remote user ID."
      },
      {
        "volume": "Volume, ranging from [0,400].\n 0: Mute.\n 100: (Default) Original volume.\n 400: Four times the original volume, with built-in overflow protection."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_clearvideowatermarkex",
    "name": "ClearVideoWatermarkEx",
    "description": "Removes added video watermarks.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_createagorartcengineex",
    "name": "CreateAgoraRtcEngineEx",
    "description": "Creates an IRtcEngineEx object.\n\nCurrently, RTC v4.x SDK supports creating only one IRtcEngineEx object per App.",
    "parameters": [],
    "returns": "IRtcEngineEx object.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_createdatastreamex1",
    "name": "CreateDataStreamEx [1/2]",
    "description": "Creates a data stream.\n\nDeprecated Deprecated: This method is deprecated. Use CreateDataStreamEx [2/2] instead. You can call this method to create a data stream and improve the reliability and ordering of data transmission. During the lifecycle of IRtcEngine, each user can create up to 5 data streams. The data streams are destroyed when leaving the channel. To use them again, you need to recreate the data streams.",
    "parameters": [
      {
        "streamId": "Output parameter. The ID of the created data stream."
      },
      {
        "reliable": "Make sure to set reliable and ordered both to true or both to false. Whether to guarantee data reliability, i.e., whether the receiver must receive the data within 5 seconds after it is sent: true : The receiver will receive the data sent by the sender within 5 seconds, otherwise the OnStreamMessageError callback is triggered and the corresponding error message is returned. false : The receiver is not guaranteed to receive the data, and no error is reported even if the data is lost."
      },
      {
        "ordered": "Whether to guarantee data ordering, i.e., whether the receiver must receive the data in the order it was sent: true : The receiver receives the data packets in the order they were sent by the sender. false : The receiver is not guaranteed to receive the data packets in order."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Data stream created successfully.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_createdatastreamex2",
    "name": "CreateDataStreamEx [2/2]",
    "description": "Creates a data stream.\n\nCompared with CreateDataStreamEx [1/2], this method does not guarantee the reliability of data transmission. The receiver discards packets that are received more than 5 seconds after being sent. If you need a more comprehensive low-latency, high-concurrency, and scalable real-time messaging and state synchronization solution, we recommend using [Real-time Messaging](https://doc.shengwang.cn/doc/rtm2/unity/landing-page).\nDuring the lifecycle of IRtcEngine, each user can create up to 5 data streams. The data streams are destroyed when leaving the channel. To use them again, you need to recreate the data streams.",
    "parameters": [
      {
        "streamId": "Output parameter. The ID of the created data stream."
      },
      {
        "config": "Data stream configuration. See DataStreamConfig."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Data stream created successfully.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_enableaudiovolumeindicationex",
    "name": "EnableAudioVolumeIndicationEx",
    "description": "Enables audio volume indication.\n\nThis method allows the SDK to periodically report volume information of the local user and up to three remote users with the highest instantaneous volume to the app.",
    "parameters": [
      {
        "interval": "Sets the time interval of the volume indication:\n â‰¤ 0: Disables the volume indication.\n > 0: The interval (ms) at which the volume indication is returned. We recommend setting it to greater than 100 ms. The minimum value is 10 ms. If the value is less than 10 ms, you may not receive the OnAudioVolumeIndication callback."
      },
      {
        "smooth": "The smoothing factor that sets the sensitivity of the volume indication. The value range is [0,10], and the recommended value is 3. The greater the value, the more sensitive the indication; the smaller the value, the smoother the indication."
      },
      {
        "reportVad": "true : Enables the local voice activity detection (VAD). After it is enabled, the vad parameter in the OnAudioVolumeIndication callback reports whether voice is detected locally. false : (Default) Disables the local VAD. Except for scenarios where the engine automatically performs local VAD, the vad parameter in the OnAudioVolumeIndication callback does not report whether voice is detected locally."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_enablecontentinspectex",
    "name": "EnableContentInspectEx",
    "description": "Enables/disables local snapshot upload.\n\nThis method allows you to capture and upload snapshots from multiple video streams. After enabling local snapshot upload, the SDK captures and uploads snapshots of the local user's video based on the module type and frequency you set in ContentInspectConfig. Once the snapshots are captured, Agora's server sends a callback notification to your server via an HTTPS request and uploads all snapshots to your designated third-party cloud storage. Before calling this method, make sure you have [contacted technical support](https://ticket.shengwang.cn/) to enable the local snapshot upload service.",
    "parameters": [
      {
        "enabled": "Sets whether to enable local snapshot upload: true : Enable local snapshot upload. false : Disable local snapshot upload."
      },
      {
        "config": "Local snapshot upload configuration. See ContentInspectConfig."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_enabledualstreammodeex",
    "name": "EnableDualStreamModeEx",
    "description": "Enables or disables dual-stream mode on the sender.\n\nDeprecated Deprecated: Deprecated since v4.2.0. Use SetDualStreamModeEx instead. You can call this method on the sender to enable or disable dual-stream mode. Dual-stream refers to high-quality and low-quality video streams:\n High-quality stream: High resolution and high frame rate video stream.\n Low-quality stream: Low resolution and low frame rate video stream. After enabling dual-stream mode, you can call SetRemoteVideoStreamType on the receiver to choose to receive the high-quality or low-quality video stream. This method applies to all types of streams sent by the sender, including but not limited to camera-captured video streams, screen sharing streams, and custom captured video streams.",
    "parameters": [
      {
        "enabled": "Whether to enable dual-stream mode: true : Enable dual-stream mode. false : (Default) Disable dual-stream mode."
      },
      {
        "streamConfig": "Configuration of the low-quality video stream. See SimulcastStreamConfig. When mode is set to DISABLE_SIMULCAST_STREAM, setting streamConfig has no effect."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_enableencryptionex",
    "name": "EnableEncryptionEx",
    "description": "Enables or disables built-in encryption.\n\nAfter a user leaves the channel, the SDK automatically disables encryption. To re-enable encryption, you need to call this method before the user rejoins the channel.\n All users in the same channel must use the same encryption mode and key when calling this method.\n When built-in encryption is enabled, the RTMP streaming feature cannot be used.",
    "parameters": [
      {
        "enabled": "Whether to enable built-in encryption: true : Enable built-in encryption. false : (default) Disable built-in encryption."
      },
      {
        "config": "Configure the built-in encryption mode and key. See EncryptionConfig."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_enableloopbackrecordingex",
    "name": "EnableLoopbackRecordingEx",
    "description": "Enables loopback recording.\n\nAfter enabling loopback recording, the sound played by the sound card will be mixed into the local audio stream and can be sent to the remote end.\n This method is only applicable to macOS and Windows platforms.\n The default sound card on macOS does not support recording. If you need this feature, please enable a virtual sound card and set deviceName to the device name of the virtual sound card. Agora recommends using the self-developed virtual sound card AgoraALD for recording.\n Currently, only one loopback recording is supported.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "enabled": "Whether to enable loopback recording: true : Enable loopback recording. false : (Default) Do not enable loopback recording."
      },
      {
        "deviceName": "macOS: The device name of the virtual sound card. Default is empty, which means using the AgoraALD virtual sound card for recording.\n Windows: The device name of the sound card. Default is empty, which means using the built-in sound card of the device for recording."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_getcallidex",
    "name": "GetCallIdEx",
    "description": "Gets the call ID using the connection ID.\n\nEach time the client joins a channel, it generates a corresponding callId to identify the current call. You can call this method to get the callId parameter, and then pass it in when calling methods such as Rate and Complain.",
    "parameters": [
      {
        "callId": "An output parameter. The current call ID."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_getconnectionstateex",
    "name": "GetConnectionStateEx",
    "description": "Gets the current network connection state.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "The current network connection state. See CONNECTION_STATE_TYPE.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_joinchannelex",
    "name": "JoinChannelEx",
    "description": "Joins a channel.\n\nCall this method to join multiple channels simultaneously. If you want to join the same channel on different devices, make sure each device uses a different user ID. If you are already in a channel, you cannot join the same channel again with the same user ID.\nBefore joining a channel, make sure the App ID used to generate the Token is the same as the one used to initialize the engine with the Initialize method; otherwise, joining the channel with the Token will fail.",
    "parameters": [
      {
        "token": "A dynamic key generated on your server for authentication. See [Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\n (Recommended) If your project has enabled secure mode (i.e., using APP ID + Token for authentication), this parameter is required.\n If your project is in debug mode only (i.e., using APP ID for authentication), you can join the channel without providing a Token. The user will automatically leave the channel after 24 hours.\n If you need to join multiple channels simultaneously or switch channels frequently, Agora recommends using a wildcard Token to avoid requesting a new Token from your server each time you join a new channel. See [Using Wildcard Token](https://doc.shengwang.cn/doc/rtc/unity/best-practice/wildcard-token)."
      },
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "options": "Channel media configuration options. See ChannelMediaOptions."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting advice.\n -2: Invalid parameters. For example, using an invalid Token, uid not set as an integer, or invalid values in ChannelMediaOptions. You need to provide valid parameters and rejoin the channel.\n -3: IRtcEngine initialization failed. You need to reinitialize the IRtcEngine object.\n -7: IRtcEngine is not initialized. You must successfully initialize IRtcEngine before calling this method.\n -8: Internal state error in IRtcEngine. Possible cause: calling this method to join a channel after StartEchoTest without calling StopEchoTest. You need to call StopEchoTest before this method.\n -17: This method call was rejected. Possible cause: the user is already in the channel. Use the OnConnectionStateChanged callback to check the connection state. Do not call this method again unless you receive CONNECTION_STATE_DISCONNECTED (1).\n -102: Invalid channel name. You need to provide a valid channelId and rejoin the channel.\n -121: Invalid user ID. You need to provide a valid uid and rejoin the channel.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_leavechannelex",
    "name": "LeaveChannelEx [1/2]",
    "description": "Leaves the channel.\n\nAfter calling this method, the SDK stops audio and video interactions, leaves the current channel, and releases all session-related resources.\nAfter successfully joining a channel using JoinChannelEx, you must call this method or LeaveChannelEx [2/2] to end the call, otherwise you cannot start a new one.\n This method is asynchronous. The return does not mean you have actually left the channel.\n If you call LeaveChannel [1/2] or LeaveChannel [2/2], you will leave both the channels joined by JoinChannel [1/2] or JoinChannel [2/2] and JoinChannelEx. If you call Dispose immediately after this method, the SDK will not trigger the OnLeaveChannel callback.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_leavechannelex2",
    "name": "LeaveChannelEx [2/2]",
    "description": "Sets channel options and leaves the channel.\n\nAfter calling this method, the SDK stops audio and video interactions, leaves the current channel, and releases all session-related resources.\nAfter successfully joining a channel using JoinChannelEx, you must call this method or LeaveChannelEx [1/2] to end the call, otherwise you cannot start a new one.\n This method is asynchronous. The return does not mean you have actually left the channel.\n If you call LeaveChannel [1/2] or LeaveChannel [2/2], you will leave both the channels joined by JoinChannel [1/2] or JoinChannel [2/2] and JoinChannelEx. If you call Dispose immediately after this method, the SDK will not trigger the OnLeaveChannel callback.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "options": "Options for leaving the channel. See LeaveChannelOptions. This parameter only supports setting the stopMicrophoneRecording member in LeaveChannelOptions. Other members are not effective."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_muteallremoteaudiostreamsex",
    "name": "MuteAllRemoteAudioStreamsEx",
    "description": "Stops or resumes subscribing to all remote users' audio streams.\n\nAfter successfully calling this method, the local user stops or resumes subscribing to remote users' audio streams, including those who join the channel after this method is called.\n This method must be called after joining a channel.\n To set the default behavior to not subscribe to remote users' audio streams before joining a channel, set autoSubscribeAudio to false when calling JoinChannel [2/2].",
    "parameters": [
      {
        "mute": "Whether to stop subscribing to all remote users' audio streams: true : Stop subscribing to all remote users' audio streams. false : (Default) Subscribe to all remote users' audio streams."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_muteallremotevideostreamsex",
    "name": "MuteAllRemoteVideoStreamsEx",
    "description": "Stops or resumes subscribing to all remote users' video streams.\n\nAfter this method is successfully called, the local user stops or resumes subscribing to all remote users' video streams, including those who join the channel after this method is called.",
    "parameters": [
      {
        "mute": "Whether to stop subscribing to all remote users' video streams. true : Stop subscribing to all users' video streams. false : (Default) Subscribe to all users' video streams."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_mutelocalaudiostreamex",
    "name": "MuteLocalAudioStreamEx",
    "description": "Stops or resumes publishing the local audio stream.\n\nAfter this method is successfully called, remote users trigger the OnUserMuteAudio and OnRemoteAudioStateChanged callbacks. This method does not affect the audio capture status, as it does not disable the audio capture device.",
    "parameters": [
      {
        "mute": "Whether to stop publishing the local audio stream. true : Stop publishing. false : (Default) Publish."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_mutelocalvideostreamex",
    "name": "MuteLocalVideoStreamEx",
    "description": "Stops or resumes publishing the local video stream.\n\nAfter this method is successfully called, remote users trigger the OnUserMuteVideo callback.\n This method does not affect the video capture status and does not disable the camera.",
    "parameters": [
      {
        "mute": "Whether to stop sending the local video stream. true : Stop sending the local video stream. false : (Default) Send the local video stream."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_muteremoteaudiostreamex",
    "name": "MuteRemoteAudioStreamEx",
    "description": "Stops or resumes receiving the specified audio stream.\n\nThis method stops or resumes receiving the audio stream of a specified remote user. It can be called before or after joining the channel. The setting becomes invalid after leaving the channel.",
    "parameters": [
      {
        "uid": "The ID of the specified user."
      },
      {
        "mute": "Whether to stop receiving the specified audio stream: true : Stop receiving the specified audio stream. false : (Default) Continue receiving the specified audio stream."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_muteremotevideostreamex",
    "name": "MuteRemoteVideoStreamEx",
    "description": "Stops or resumes receiving a specified video stream.\n\nThis method stops or resumes receiving the video stream of a specified remote user. You can call this method before or after joining a channel. The setting becomes invalid after leaving the channel.",
    "parameters": [
      {
        "uid": "The ID of the remote user."
      },
      {
        "mute": "Whether to stop receiving the video stream of a remote user: true : Stop receiving. false : (Default) Resume receiving."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_pauseallchannelmediarelayex",
    "name": "PauseAllChannelMediaRelayEx",
    "description": "Pauses media stream forwarding to all destination channels.\n\nAfter starting to forward media streams across channels, if you need to pause forwarding to all channels, you can call this method. To resume forwarding, call the ResumeAllChannelMediaRelay method. You must call this method after calling StartOrUpdateChannelMediaRelayEx to start cross-channel media stream forwarding.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -5: This method call was rejected. No cross-channel media stream forwarding is currently in progress.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_playeffectex",
    "name": "PlayEffectEx",
    "description": "Plays the specified sound effect in the channel.\n\nSince Available since v4.6.2. You can call this method to play the specified sound effect to all users in the channel. Each call to this method can only play one sound effect. To play multiple sound effects simultaneously, use different soundId and filePath and call this method multiple times. You can also set whether to publish the sound effect in the channel.\n Agora recommends not playing more than three sound effects at the same time.\n The sound effect ID and file path in this method must be the same as those in the preloadEffectEx method.\n If you call preloadEffectEx before calling playEffectEx, then playEffectEx will not release the file resource after execution. The next time you call playEffectEx, it will start playing from the beginning.\n If you do not call preloadEffectEx before calling playEffectEx, then playEffectEx will destroy the resource after execution. The next time you call playEffectEx, it will attempt to reopen the file and start playing from the beginning.",
    "parameters": [
      {
        "connection": "RtcConnection object. See RtcConnection."
      },
      {
        "soundId": "Sound effect ID."
      },
      {
        "filePath": "The absolute path of the local file or the URL of the online file. Supported audio formats include mp3, mp4, m4a, aac, 3gp, mkv, and wav."
      },
      {
        "loopCount": "Number of times the sound effect loops: -1 : Infinite loop until stopEffect or stopAllEffects is called. 0 : Play once. 1 : Play twice."
      },
      {
        "pitch": "Pitch of the sound effect. The range is from 0.5 to 2.0. The default value is 1.0 (original pitch). The smaller the value, the lower the pitch."
      },
      {
        "pan": "Spatial position of the sound effect. The range is from -1.0 to 1.0: -1.0 : The sound effect comes from the left of the user. 0.0 : The sound effect comes from the front of the user. 1.0 : The sound effect comes from the right of the user."
      },
      {
        "gain": "Volume of the sound effect. The range is from 0 to 100. The default value is 100 (original volume). The smaller the value, the lower the volume."
      },
      {
        "publish": "Whether to publish the sound effect in the channel: true : Publish the sound effect in the channel. false : (Default) Do not publish the sound effect in the channel."
      },
      {
        "startPos": "The start position for playing the sound effect file, in milliseconds."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_preloadeffectex",
    "name": "PreloadEffectEx",
    "description": "Preloads the specified sound effect into the channel.\n\nSince Available since v4.6.2. Each time you call this method, only one sound effect file can be preloaded into memory. To preload multiple sound effect files, call this method multiple times. After preloading, you can call playEffect to play the preloaded sound effect, or call playAllEffects to play all preloaded sound effects.\n To ensure a smooth experience, the size of the sound effect file should not exceed the limit.\n Agora recommends calling this method before joining a channel.\n If you call preloadEffectEx before calling playEffectEx, then playEffectEx will not release the file resource after execution. The next time you call playEffectEx, it will start playing from the beginning.\n If you do not call preloadEffectEx before calling playEffectEx, then playEffectEx will destroy the resource after execution. The next time you call playEffectEx, it will attempt to reopen the file and start playing from the beginning.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "soundId": "Sound effect ID."
      },
      {
        "filePath": "The absolute path of the local file or the URL of the online file. Supported audio formats include: mp3, mp4, m4a, aac, 3gp, mkv, and wav."
      },
      {
        "startPos": "The start position for playing the sound effect file, in milliseconds."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_removevideowatermarkex",
    "name": "RemoveVideoWatermarkEx",
    "description": "Removes the specified watermark image from the local or remote video stream.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "id": "Watermark ID."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_resumeallchannelmediarelayex",
    "name": "ResumeAllChannelMediaRelayEx",
    "description": "Resumes media stream forwarding to all destination channels.\n\nAfter calling the PauseAllChannelMediaRelayEx method, if you need to resume forwarding to all destination channels, you can call this method. You must call this method after PauseAllChannelMediaRelayEx.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -5: This method call was rejected. No cross-channel media stream forwarding is currently paused.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_sendcustomreportmessageex",
    "name": "SendCustomReportMessageEx",
    "description": "Custom data reporting and analytics service.\n\nAgora provides custom data reporting and analytics services. This service is currently in a free beta period. During the beta, you can report up to 10 data entries within 6 seconds. Each custom data entry must not exceed 256 bytes, and each string must not exceed 100 bytes. To try this service, please [contact sales](https://www.shengwang.cn/contact-sales/) to enable it and agree on the custom data format.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_sendstreammessageex",
    "name": "SendStreamMessageEx",
    "description": "Sends a data stream.\n\nAfter calling CreateDataStreamEx [2/2], you can call this method to send data stream messages to all users in the channel.\nThe SDK imposes the following restrictions on this method:\n Each client in the channel can have up to 5 data channels simultaneously, and the total sending bitrate shared by all data channels is limited to 30 KB/s.\n Each data channel can send up to 60 packets per second, with each packet up to 1 KB in size. After this method is successfully called, the remote side triggers the OnStreamMessage callback, where remote users can retrieve the received stream message; if the call fails, the remote side triggers the OnStreamMessageError callback.\n If you need a more comprehensive, low-latency, high-concurrency, and scalable real-time messaging and state synchronization solution, we recommend using [Real-time Messaging](https://doc.shengwang.cn/doc/rtm2/unity/landing-page).\n You must call this method after JoinChannelEx.\n Make sure you have called CreateDataStreamEx [2/2] to create a data channel before calling this method.",
    "parameters": [
      {
        "streamId": "The data stream ID. You can get it through CreateDataStreamEx [2/2]."
      },
      {
        "data": "The data to be sent."
      },
      {
        "length": "The length of the data."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setdualstreammodeex",
    "name": "SetDualStreamModeEx",
    "description": "Sets the dual-stream mode on the sender.\n\nBy default, the SDK enables adaptive low-quality stream mode (AUTO_SIMULCAST_STREAM) on the sender, meaning the sender does not actively send low-quality streams. Receivers with host identity can call SetRemoteVideoStreamTypeEx to request a low-quality stream, and the sender starts sending it upon receiving the request.\n If you want to change this behavior, call this method and set mode to DISABLE_SIMULCAST_STREAM (never send low-quality stream) or ENABLE_SIMULCAST_STREAM (always send low-quality stream).\n If you want to revert to the default behavior after changing it, call this method again and set mode to AUTO_SIMULCAST_STREAM. The differences and relationships between this method and EnableDualStreamModeEx are as follows:\n Calling this method and setting mode to DISABLE_SIMULCAST_STREAM has the same effect as EnableDualStreamModeEx(false).\n Calling this method and setting mode to ENABLE_SIMULCAST_STREAM has the same effect as EnableDualStreamModeEx(true).\n Both methods can be called before or after joining a channel. If both are used, the settings from the later call take effect.",
    "parameters": [
      {
        "mode": "The mode for sending video streams. See SIMULCAST_STREAM_MODE."
      },
      {
        "streamConfig": "Configuration of the low-quality video stream. See SimulcastStreamConfig. When mode is set to DISABLE_SIMULCAST_STREAM, setting streamConfig has no effect."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setremoterendermodeex",
    "name": "SetRemoteRenderModeEx",
    "description": "Sets the display mode of the remote view.\n\nAfter initializing the remote user view, you can call this method to update the rendering and mirror mode of the remote user view when displayed locally. This method only affects the video image seen by the local user.",
    "parameters": [
      {
        "uid": "Remote user ID."
      },
      {
        "renderMode": "Display mode of the remote view. See RENDER_MODE_TYPE."
      },
      {
        "mirrorMode": "Mirror mode of the remote user view. See VIDEO_MIRROR_MODE_TYPE."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setremotevideostreamtypeex",
    "name": "SetRemoteVideoStreamTypeEx",
    "description": "Sets the video stream type to subscribe to.\n\nDepending on the sender's default behavior and the specific configuration of SetDualStreamMode [2/2], the receiver's behavior when calling this method is as follows:\n By default, the SDK enables small stream adaptive mode (AUTO_SIMULCAST_STREAM) on the sender side, meaning the sender only sends the high-quality stream. Only receivers with host roles can call this method to request the low-quality stream. Once the sender receives the request, it starts sending the low-quality stream automatically. At this point, all users in the channel can call this method to switch to the low-quality stream subscription mode.\n If the sender calls SetDualStreamMode [2/2] and sets mode to DISABLE_SIMULCAST_STREAM (never send low-quality stream), this method has no effect.\n If the sender calls SetDualStreamMode [2/2] and sets mode to ENABLE_SIMULCAST_STREAM (always send low-quality stream), both host and audience roles on the receiver side can call this method to switch to low-quality stream subscription mode. When receiving a low-quality video stream, the SDK dynamically adjusts the video stream size based on the size of the video window to save bandwidth and computing resources. The aspect ratio of the low-quality stream is the same as that of the high-quality stream. Based on the current high-quality stream's aspect ratio, the system automatically assigns resolution, frame rate, and bitrate for the low-quality stream. If the sender has already called SetDualStreamModeEx and set mode to DISABLE_SIMULCAST_STREAM (never send low-quality stream), this method has no effect. You need to call SetDualStreamModeEx again on the sender side to change the configuration.",
    "parameters": [
      {
        "uid": "User ID."
      },
      {
        "streamType": "Video stream type: VIDEO_STREAM_TYPE."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setremotevideosubscriptionoptionsex",
    "name": "SetRemoteVideoSubscriptionOptionsEx",
    "description": "Sets the subscription options for the remote video stream.\n\nWhen the remote user sends dual streams, you can call this method to set the subscription options for the remote video stream.",
    "parameters": [
      {
        "uid": "The remote user ID."
      },
      {
        "options": "Subscription settings for the video stream. See VideoSubscriptionOptions."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setremotevoicepositionex",
    "name": "SetRemoteVoicePositionEx",
    "description": "Sets the 2D position of a remote user's voice, i.e., horizontal plane position.\n\nSets the spatial position and volume of a remote user's voice to help the local user perceive directionality.\nBy calling this API to set the position of a remote user's voice, the difference between the left and right audio channels creates a sense of direction, allowing the user to determine the real-time position of the remote user. In multiplayer online games, such as battle royale games, this method can effectively enhance the spatial awareness of game characters and simulate real scenarios.\n For the best listening experience, it is recommended that users wear wired headphones.\n This method must be called after joining a channel.",
    "parameters": [
      {
        "uid": "The ID of the remote user."
      },
      {
        "pan": "Sets the spatial position of the remote user's voice. Range: [-1.0, 1.0]:\n -1.0: Voice appears on the left.\n (Default) 0.0: Voice appears in front.\n 1.0: Voice appears on the right."
      },
      {
        "gain": "Sets the volume of the remote user's voice. Range: [0.0, 100.0], default is 100.0, indicating the user's original volume. The smaller the value, the lower the volume."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setsubscribeaudioallowlistex",
    "name": "SetSubscribeAudioAllowlistEx",
    "description": "Sets the audio subscription allowlist.\n\nYou can call this method to specify the audio streams you want to subscribe to.\n You can call this method either before or after joining a channel.\n The audio subscription allowlist is not affected by MuteRemoteAudioStream, MuteAllRemoteAudioStreams, or the autoSubscribeAudio setting in ChannelMediaOptions.\n After setting the allowlist, it remains effective even if you leave and rejoin the channel.\n If a user is in both the audio subscription allowlist and blocklist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the audio subscription allowlist.\nIf you want to subscribe to the audio stream of a specific user, add the user's ID to this list. To remove a user from the allowlist, you need to call SetSubscribeAudioAllowlist again with an updated list that does not include the uid of the user you want to remove."
      },
      {
        "uidNumber": "The number of users in the allowlist."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setsubscribeaudioblocklistex",
    "name": "SetSubscribeAudioBlocklistEx",
    "description": "Sets the audio subscription blocklist.\n\nYou can call this method to specify the audio streams you do not want to subscribe to.\n You can call this method before or after joining a channel.\n The audio subscription blocklist is not affected by MuteRemoteAudioStream, MuteAllRemoteAudioStreams, or autoSubscribeAudio in ChannelMediaOptions.\n After setting the blocklist, it remains effective even if you leave and rejoin the channel.\n If a user appears in both the audio subscription blocklist and allowlist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the audio subscription blocklist.\nIf you want to block the audio stream from a specific user, add the user's ID to this list. To remove a user from the blocklist, you need to call SetSubscribeAudioBlocklist again to update the list so that it no longer includes the user's uid."
      },
      {
        "uidNumber": "The number of users in the audio subscription blocklist."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setsubscribevideoallowlistex",
    "name": "SetSubscribeVideoAllowlistEx",
    "description": "Sets the video subscription allowlist.\n\nYou can call this method to specify the video streams you want to subscribe to.\n You can call this method before or after joining a channel.\n The video subscription allowlist is not affected by MuteRemoteVideoStream, MuteAllRemoteVideoStreams, or autoSubscribeVideo in ChannelMediaOptions.\n After setting the allowlist, it remains effective even if you leave and rejoin the channel.\n If a user appears in both the audio subscription blocklist and allowlist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the video subscription allowlist.\nIf you want to subscribe only to the video stream from a specific user, add the user's ID to this list. To remove a user from the allowlist, you need to call SetSubscribeVideoAllowlist again to update the video subscription allowlist so that it no longer includes the user's uid."
      },
      {
        "uidNumber": "The number of users in the video subscription allowlist."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setsubscribevideoblocklistex",
    "name": "SetSubscribeVideoBlocklistEx",
    "description": "Sets the video subscription blocklist.\n\nYou can call this method to specify the video streams you do not want to subscribe to.\n You can call this method before or after joining a channel.\n The video subscription blocklist is not affected by MuteRemoteVideoStream, MuteAllRemoteVideoStreams, or autoSubscribeVideo in ChannelMediaOptions.\n After setting the blocklist, it remains effective even if you leave and rejoin the channel.\n If a user appears in both the audio subscription blocklist and allowlist, only the blocklist takes effect.",
    "parameters": [
      {
        "uidList": "The list of user IDs in the video subscription blocklist.\nIf you want to block the video stream from a specific user, add the user's ID to this list. To remove a user from the blocklist, you need to call SetSubscribeVideoBlocklist again to update the list so that it no longer includes the user's uid."
      },
      {
        "uidNumber": "The number of users in the video subscription blocklist."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setupremotevideoex",
    "name": "SetupRemoteVideoEx",
    "description": "Initializes the remote user view.\n\nThis method binds the remote user and the display view, and sets the rendering and mirror mode of the remote user view when displayed locally. It only affects the video image seen by the local user.\nWhen calling this method, you need to specify the user ID of the remote video in VideoCanvas. It is generally recommended to set it before joining the channel.\nIf you cannot obtain the remote user's uid before joining the channel, you can call this method upon receiving the OnUserJoined callback. If video recording is enabled, the recording service will join the channel as a dummy client, and other clients will also receive its onUserJoined event. The app should not bind a view for it (because it does not send video streams).\nTo unbind a remote user's view, call this method and set view to null.\nAfter leaving the channel, the SDK will clear the binding of the remote user view.\n This method must be called after JoinChannelEx.\n In Flutter, you do not need to call this method manually. Use AgoraVideoView to render local and remote views.\n If you want to update the rendering or mirror mode of the remote user view during a call, use the SetRemoteRenderModeEx method.",
    "parameters": [
      {
        "canvas": "Video canvas information. See VideoCanvas."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_setvideoencoderconfigurationex",
    "name": "SetVideoEncoderConfigurationEx",
    "description": "Sets the video encoding properties.\n\nSets the encoding properties for the local video. Each video encoding configuration corresponds to a set of video-related parameters, including resolution, frame rate, and bitrate. The config parameter of this method specifies the maximum values achievable under ideal network conditions. If the network condition is poor, the video engine may not use this config to render the local video and will automatically downgrade to a suitable video parameter setting.",
    "parameters": [
      {
        "config": "Video encoding parameter configuration. See VideoEncoderConfiguration."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Method call succeeded.\n < 0: Method call failed. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_startmediarenderingtracingex",
    "name": "StartMediaRenderingTracingEx",
    "description": "Starts video frame rendering tracing.\n\nAfter this method is successfully called, the SDK uses the time of this call as the starting point and reports video frame rendering information through the OnVideoRenderingTracingResult callback.\n If you do not call this method, the SDK uses the time of calling JoinChannel [2/2] to join the channel as the default starting point and automatically begins tracing video rendering events. You can call this method at an appropriate time based on your business scenario to customize the tracing point.\n After leaving the current channel, the SDK automatically resets the tracing point to the time of the next channel join.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_startorupdatechannelmediarelayex",
    "name": "StartOrUpdateChannelMediaRelayEx",
    "description": "Starts or updates cross-channel media stream forwarding.\n\nThe first successful call to this method starts forwarding media streams across channels. To forward streams to multiple destination channels or leave a current forwarding channel, you can call this method again to add or remove destination channels. This feature supports forwarding to up to 6 destination channels.\nAfter a successful call, the SDK triggers the OnChannelMediaRelayStateChanged callback to report the current state of cross-channel media stream forwarding. Common states include:\n If the OnChannelMediaRelayStateChanged callback reports RELAY_STATE_RUNNING (2) and RELAY_OK (0), it means the SDK has started forwarding media streams between the source and destination channels.\n If the callback reports RELAY_STATE_FAILURE (3), it means an error occurred during cross-channel media stream forwarding.\n Call this method after successfully joining a channel.\n In a live streaming scenario, only users with the host role can call this method.\n Cross-channel media stream forwarding requires [contacting technical support](https://ticket.shengwang.cn/) to enable.\n This feature does not support String-type UIDs.",
    "parameters": [
      {
        "configuration": "Configuration for cross-channel media stream forwarding. See ChannelMediaRelayConfiguration."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -1: General error (not specifically classified).\n -2: Invalid parameter.\n -8: Internal state error. Possibly because the user role is not host.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_startrtmpstreamwithouttranscodingex",
    "name": "StartRtmpStreamWithoutTranscodingEx",
    "description": "Starts RTMP streaming without transcoding.\n\nAgora recommends using a more comprehensive server-side streaming feature. See [Implement server-side streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nBy calling this method, you can push live audio and video streams to the specified RTMP address. This method can only push to one address at a time. If you need to push to multiple addresses, call this method multiple times.\nAfter calling this method, the SDK triggers the OnRtmpStreamingStateChanged callback locally to report the streaming state.\n Call this method after joining a channel.\n Only hosts in a live broadcast scenario can call this method.\n If the streaming fails and you want to restart it, make sure to call StopRtmpStream before calling this method again, otherwise the SDK returns the same error code as the last failure.",
    "parameters": [
      {
        "url": "The RTMP or RTMPS streaming URL. The character length must not exceed 1024 bytes. Chinese characters and other special characters are not supported."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid URL or transcoding parameters. Please check your URL or parameter settings.\n -7: The SDK was not initialized before calling this method.\n -19: The RTMP URL is already in use. Please use another RTMP URL.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_startrtmpstreamwithtranscodingex",
    "name": "StartRtmpStreamWithTranscodingEx",
    "description": "Starts RTMP streaming with transcoding settings.\n\nAgora recommends using a more comprehensive server-side streaming feature. See [Implement server-side streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nBy calling this method, you can push live audio and video streams to the specified RTMP address and set transcoding parameters. This method can only push to one address at a time. If you need to push to multiple addresses, call this method multiple times.\nAfter calling this method, the SDK triggers the OnRtmpStreamingStateChanged callback locally to report the streaming state.\n Make sure the RTMP streaming service is enabled.\n Call this method after joining a channel.\n Only hosts in a live broadcast scenario can call this method.\n If the streaming fails and you want to restart it, make sure to call StopRtmpStreamEx before calling this method again, otherwise the SDK returns the same error code as the last failure.",
    "parameters": [
      {
        "url": "The RTMP or RTMPS streaming URL. The character length must not exceed 1024 bytes. Chinese characters and other special characters are not supported."
      },
      {
        "transcoding": "The transcoding settings for RTMP streaming. See LiveTranscoding."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid URL or transcoding parameters. Please check your URL or parameter settings.\n -7: The SDK was not initialized before calling this method.\n -19: The RTMP URL is already in use. Please use another RTMP URL.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_stopchannelmediarelayex",
    "name": "StopChannelMediaRelayEx",
    "description": "Stops channel media stream relay. Once stopped, the host leaves all destination channels.\n\nAfter this method is successfully called, the SDK triggers the OnChannelMediaRelayStateChanged callback. If it reports RELAY_STATE_IDLE (0) and RELAY_OK (0), it indicates that media stream relay has stopped. If the method call fails, the SDK triggers the OnChannelMediaRelayStateChanged callback and reports the error code RELAY_ERROR_SERVER_NO_RESPONSE (2) or RELAY_ERROR_SERVER_CONNECTION_LOST (8). You can call the LeaveChannel [2/2] method to leave the channel, and the media stream relay will stop automatically.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -5: This method call was rejected. There is no ongoing channel media stream relay.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_stoprtmpstreamex",
    "name": "StopRtmpStreamEx",
    "description": "Stops the RTMP stream.\n\nAgora recommends using a more complete server-side streaming service. See [Implement Server-Side RTMP Streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nCall this method to stop the live stream at the specified RTMP streaming URL. This method can only stop one stream at a time. To stop multiple streams, call this method multiple times.\nAfter calling this method, the SDK triggers the OnRtmpStreamingStateChanged callback locally to report the streaming status.",
    "parameters": [
      {
        "url": "The RTMP streaming URL. Must be in RTMP or RTMPS format. The character length cannot exceed 1024 bytes. Special characters such as Chinese characters are not supported."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_takesnapshotex",
    "name": "TakeSnapshotEx [1/2]",
    "description": "Captures a video snapshot using a connection ID.\n\nThis method captures a snapshot of the specified user's video stream, generates a JPG image, and saves it to the specified path.\n This method is asynchronous. When the call returns, the SDK has not yet completed the snapshot.\n When used for local video snapshots, it captures the video stream specified in ChannelMediaOptions.\n If the video has been post-processed (e.g., with watermark or beautification), the snapshot will include the effects.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "uid": "User ID. Set to 0 to capture a snapshot of the local user's video."
      },
      {
        "filePath": "Make sure the directory exists and is writable. Local path to save the snapshot, including file name and format. For example:\n Windows: C:\\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\example.jpg\n iOS: /App Sandbox/Library/Caches/example.jpg\n macOS: ï½ž/Library/Logs/example.jpg\n Android: /storage/emulated/0/Android/data/<package name>/files/example.jpg"
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_takesnapshotex2",
    "name": "TakeSnapshotEx [2/2]",
    "description": "Captures a video snapshot at a specified observation point using a connection ID.\n\nThis method captures a snapshot of the specified user's video stream, generates a JPG image, and saves it to the specified path.\n This method is asynchronous. When the call returns, the SDK has not yet completed the snapshot.\n When used for local video snapshots, it captures the video stream specified in ChannelMediaOptions.\n If the video has been post-processed (e.g., with watermark or beautification), the snapshot will include the effects.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "uid": "User ID. Set to 0 to capture a snapshot of the local user's video."
      },
      {
        "config": "Snapshot configuration. See SnapshotConfig."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_updatechannelmediaoptionsex",
    "name": "UpdateChannelMediaOptionsEx",
    "description": "Updates channel media options after joining the channel.",
    "parameters": [
      {
        "options": "Channel media options. See ChannelMediaOptions."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: The method call succeeds.\n < 0: The method call fails. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.\n -2: Invalid ChannelMediaOptions member values. For example, using an invalid token or setting an invalid user role. You need to provide valid parameters.\n -7: The IRtcEngine object is not initialized. You must successfully initialize the IRtcEngine object before calling this method.\n -8: Internal state error of the IRtcEngine object. This may be because the user is not in the channel. It is recommended to use the OnConnectionStateChanged callback to determine whether the user is in the channel. If you receive CONNECTION_STATE_DISCONNECTED (1) or CONNECTION_STATE_FAILED (5), it means the user is not in the channel. You need to call JoinChannel [2/2] before calling this method.",
    "is_hide": false
  },
  {
    "id": "api_irtcengineex_updatertmptranscodingex",
    "name": "UpdateRtmpTranscodingEx",
    "description": "Updates the RTMP transcoding configuration.\n\nAgora recommends using a more complete server-side streaming service. See [Implement Server-Side RTMP Streaming](https://doc.shengwang.cn/doc/media-push/restful/landing-page).\nAfter enabling transcoding streaming, you can dynamically update the transcoding configuration based on your scenario. After the transcoding configuration is updated, the SDK triggers the OnTranscodingUpdated callback.",
    "parameters": [
      {
        "transcoding": "The RTMP transcoding configuration. See LiveTranscoding."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ivideodevicemanager_enumeratevideodevices",
    "name": "EnumerateVideoDevices",
    "description": "Gets a list of all video devices on the system.\n\nThis method is applicable to Windows and macOS only.",
    "parameters": [],
    "returns": "On success: Returns a DeviceInfo array that contains all video devices on the system.\n On failure: Returns an empty list.",
    "is_hide": false
  },
  {
    "id": "api_ivideodevicemanager_getcapability",
    "name": "GetCapability",
    "description": "Gets detailed video frame information for the specified video format of the video capture device.\n\nAfter calling NumberOfCapabilities to get the number of video formats supported by the video capture device, you can call this method to get the specific video frame information for the specified index. This method is applicable to Windows and macOS only.",
    "parameters": [
      {
        "deviceIdUTF8": "The ID of the video capture device."
      },
      {
        "deviceCapabilityNumber": "The index of the video format. If the return value of NumberOfCapabilities is i, then the value range of this parameter is [0, i)."
      },
      {
        "capability": "Output parameter. Indicates the specific information of the specified video format, including width (px), height (px), and frame rate (fps). See VideoFormat."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ivideodevicemanager_getdevice",
    "name": "GetDevice",
    "description": "Gets the currently used video capture device.\n\n(Windows and macOS only)",
    "parameters": [
      {
        "deviceIdUTF8": "Output parameter. Device ID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ivideodevicemanager_numberofcapabilities",
    "name": "NumberOfCapabilities",
    "description": "Gets the number of video formats supported by the specified video capture device.\n\nA video capture device may support multiple video formats, each with different combinations of frame width, frame height, and frame rate.\nYou can call this method to get how many video formats are supported by the specified video capture device, and then call GetCapability to get detailed video frame information for each format. (Windows and macOS only)",
    "parameters": [
      {
        "deviceIdUTF8": "ID of the video capture device."
      }
    ],
    "returns": "> 0: Success. Returns the number of video formats supported by the device. For example, if the specified camera supports 10 different formats, the return value is 10.\n â‰¤ 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ivideodevicemanager_setdevice",
    "name": "SetDevice",
    "description": "Specifies the video capture device by device ID.\n\nPlugging or unplugging a device does not change its device ID.\n (Windows and macOS only)",
    "parameters": [
      {
        "deviceIdUTF8": "Device ID. You can get it by calling the EnumerateVideoDevices method."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and resolution suggestions.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_addorupdatevideoeffect",
    "name": "AddOrUpdateVideoEffect",
    "description": "Adds or updates the effect for the specified video effect node and template.\n\nSince Available since v4.6.2. Priority rules:\n Style makeup nodes take precedence over filter effect nodes.\n To apply filter effects, you must first remove the style makeup effect node.",
    "parameters": [
      {
        "nodeId": "Unique identifier or combination of identifiers for the video effect node. See VIDEO_EFFECT_NODE_ID."
      },
      {
        "templateName": "Name of the effect template. If set to NULL or an empty string, the SDK loads the default configuration from the resource package."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_getvideoeffectboolparam",
    "name": "GetVideoEffectBoolParam",
    "description": "Gets the boolean parameter in the video effect.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "option": "The category of the option to which the parameter belongs."
      },
      {
        "key": "The key name of the parameter."
      }
    ],
    "returns": "true : The parameter is enabled. false : The parameter is not enabled or does not exist.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_getvideoeffectfloatparam",
    "name": "GetVideoEffectFloatParam",
    "description": "Gets the value of the specified float parameter in the video effect.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "option": "The category of the option to which the parameter belongs."
      },
      {
        "key": "The key name of the parameter."
      }
    ],
    "returns": "If the parameter exists, returns the corresponding float value.\n If the parameter does not exist or an error occurs, returns 0.0f.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_getvideoeffectintparam",
    "name": "GetVideoEffectIntParam",
    "description": "Gets the integer parameter in the video effect.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "option": "The category of the option."
      },
      {
        "key": "The key name of the parameter."
      }
    ],
    "returns": "If the parameter exists, returns the corresponding integer value.\n If the parameter does not exist or an error occurs, returns 0.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_performvideoeffectaction",
    "name": "PerformVideoEffectAction",
    "description": "Performs an action on the specified video effect node.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "nodeId": "Unique identifier of the video effect node."
      },
      {
        "actionId": "Action to perform. See VIDEO_EFFECT_ACTION."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_removevideoeffect",
    "name": "RemoveVideoEffect",
    "description": "Removes the video effect for the specified node ID.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "nodeId": "Unique identifier of the video effect node to remove. See VIDEO_EFFECT_NODE_ID."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_setvideoeffectboolparam",
    "name": "SetVideoEffectBoolParam",
    "description": "Sets a boolean parameter for the video effect.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "option": "The category of the option."
      },
      {
        "key": "The key name of the parameter."
      },
      {
        "param": "The boolean value to set: true : Enable the option. false : Disable the option."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_setvideoeffectfloatparam",
    "name": "SetVideoEffectFloatParam",
    "description": "Sets a float parameter for the video effect.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "option": "Category of the parameter option."
      },
      {
        "key": "Key name of the parameter."
      },
      {
        "param": "Float value to set."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_ivideoeffectobject_setvideoeffectintparam",
    "name": "SetVideoEffectIntParam",
    "description": "setVideoEffectIntParam : Sets an integer parameter for the video effect.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "option": "The category of the option to which the parameter belongs."
      },
      {
        "key": "The key name of the parameter."
      },
      {
        "param": "The integer value to set."
      }
    ],
    "returns": "0: Success.\n < 0: Failure.",
    "is_hide": false
  },
  {
    "id": "api_videosurface_setenable",
    "name": "SetEnable",
    "description": "Starts/stops video rendering.",
    "parameters": [
      {
        "enable": "Whether to start video rendering. true : (default) enable false : disable"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "api_videosurface_setforuser",
    "name": "SetForUser",
    "description": "Sets local/remote video display.\n\nMake sure to call this method on the main thread.\n Make sure to call this method before binding VideoSurface.cs.",
    "parameters": [
      {
        "uid": "The remote user ID, obtained via OnUserJoined. The default value is 0, which means the local video is visible."
      },
      {
        "channelId": "Channel ID."
      },
      {
        "source_type": "Video stream type. See VIDEO_SOURCE_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_iaudioencodedframeobserver_onmixedaudioencodedframe",
    "name": "OnMixedAudioEncodedFrame",
    "description": "Retrieves the encoded audio data after mixing local and all remote users' audio.\n\nAfter calling RegisterAudioEncodedFrameObserver and setting the audio encoded content to AUDIO_ENCODED_FRAME_OBSERVER_POSITION_MIXED, you can use this callback to get the encoded audio data after mixing local and all remote users' audio.",
    "parameters": [
      {
        "frameBufferPtr": "Audio buffer."
      },
      {
        "length": "Length of the audio data in bytes."
      },
      {
        "audioEncodedFrameInfo": "Information about the encoded audio. See EncodedAudioFrameInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_iaudioencodedframeobserver_onplaybackaudioencodedframe",
    "name": "OnPlaybackAudioEncodedFrame",
    "description": "Retrieves the encoded audio data of all remote users.\n\nAfter calling RegisterAudioEncodedFrameObserver and setting the audio encoded content to AUDIO_ENCODED_FRAME_OBSERVER_POSITION_PLAYBACK, you can use this callback to get the encoded audio data of all remote users.",
    "parameters": [
      {
        "frameBufferPtr": "Audio buffer."
      },
      {
        "length": "Length of the audio data in bytes."
      },
      {
        "audioEncodedFrameInfo": "Information about the encoded audio. See EncodedAudioFrameInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_iaudioencodedframeobserver_onrecordaudioencodedframe",
    "name": "OnRecordAudioEncodedFrame",
    "description": "Retrieves the encoded audio data of the local user.\n\nAfter calling RegisterAudioEncodedFrameObserver and setting the audio encoded content to AUDIO_ENCODED_FRAME_OBSERVER_POSITION_RECORD, you can use this callback to get the encoded audio data of the local user.",
    "parameters": [
      {
        "frameBufferPtr": "Audio buffer."
      },
      {
        "length": "Length of the audio data in bytes."
      },
      {
        "audioEncodedFrameInfo": "Information about the encoded audio. See EncodedAudioFrameInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_iaudioframeobserver_onplaybackaudioframebeforemixing",
    "name": "OnPlaybackAudioFrameBeforeMixing",
    "description": "Gets the audio of the subscribed remote user before mixing.",
    "parameters": [
      {
        "channel_id": "Channel ID."
      },
      {
        "uid": "The ID of the subscribed remote user."
      },
      {
        "audio_frame": "The raw audio data. See AudioFrame."
      }
    ],
    "returns": "No practical meaning.",
    "is_hide": false
  },
  {
    "id": "callback_iaudioframeobserverbase_onearmonitoringaudioframe",
    "name": "OnEarMonitoringAudioFrame",
    "description": "Gets the raw audio data for ear monitoring.\n\nTo ensure the ear monitoring audio data format meets expectations, you can call SetEarMonitoringAudioFrameParameters to set the audio format, then call RegisterAudioFrameObserver to register the audio frame observer. The SDK calculates the sampling interval using the parameters in this method and triggers the OnEarMonitoringAudioFrame callback accordingly.",
    "parameters": [
      {
        "audioFrame": "The raw audio data. See AudioFrame."
      }
    ],
    "returns": "No practical meaning.",
    "is_hide": false
  },
  {
    "id": "callback_iaudioframeobserverbase_onmixedaudioframe",
    "name": "OnMixedAudioFrame",
    "description": "Retrieves the audio data after mixing captured and playback audio.\n\nTo ensure the format of the audio data after mixing capture and playback meets expectations, you can call SetMixedAudioFrameParameters to set the audio data format, and then call RegisterAudioFrameObserver to register the audio frame observer. The SDK calculates the sampling interval based on the parameters of this method and triggers the OnMixedAudioFrame callback accordingly.",
    "parameters": [
      {
        "audio_frame": "Raw audio data. See AudioFrame."
      },
      {
        "channelId": "Channel ID."
      }
    ],
    "returns": "No actual meaning.",
    "is_hide": false
  },
  {
    "id": "callback_iaudioframeobserverbase_onplaybackaudioframe",
    "name": "OnPlaybackAudioFrame",
    "description": "Gets the raw audio data for playback.\n\nTo ensure the playback audio data format meets expectations, you can call SetPlaybackAudioFrameParameters to set the audio format, then call RegisterAudioFrameObserver to register the audio frame observer. The SDK calculates the sampling interval using the parameters in this method and triggers the OnPlaybackAudioFrame callback accordingly.",
    "parameters": [
      {
        "audio_frame": "The raw audio data. See AudioFrame."
      },
      {
        "channelId": "Channel ID."
      }
    ],
    "returns": "No practical meaning.",
    "is_hide": false
  },
  {
    "id": "callback_iaudioframeobserverbase_onrecordaudioframe",
    "name": "OnRecordAudioFrame",
    "description": "Gets the raw audio data for recording.\n\nTo ensure the recorded audio data format meets expectations, you can call SetRecordingAudioFrameParameters to set the audio format, then call RegisterAudioFrameObserver to register the audio frame observer. The SDK calculates the sampling interval using the parameters in this method and triggers the OnRecordAudioFrame callback accordingly.",
    "parameters": [
      {
        "audioFrame": "The raw audio data. See AudioFrame."
      },
      {
        "channelId": "Channel ID."
      }
    ],
    "returns": "No practical meaning.",
    "is_hide": false
  },
  {
    "id": "callback_iaudiopcmframesink_onframe",
    "name": "OnFrame",
    "description": "Callback for received audio frame.\n\nAfter registering the audio data observer, this callback is triggered each time an audio frame is received to report audio frame information.",
    "parameters": [
      {
        "frame": "Audio frame information. See AudioPcmFrame."
      }
    ],
    "returns": "No actual meaning.",
    "is_hide": false
  },
  {
    "id": "callback_iaudiospectrumobserver_onlocalaudiospectrum",
    "name": "OnLocalAudioSpectrum",
    "description": "Receives local audio spectrum.\n\nAfter successfully calling RegisterAudioSpectrumObserver, implementing the OnLocalAudioSpectrum callback in IAudioSpectrumObserver, and calling EnableAudioSpectrumMonitor to enable audio spectrum monitoring, the SDK triggers this callback at the interval you set to report the spectrum of local audio data before encoding.",
    "parameters": [
      {
        "data": "Audio spectrum data of the local user. See AudioSpectrumData."
      }
    ],
    "returns": "Whether to receive spectrum data: true : Receive. false : Do not receive.",
    "is_hide": false
  },
  {
    "id": "callback_iaudiospectrumobserver_onremoteaudiospectrum",
    "name": "OnRemoteAudioSpectrum",
    "description": "Receives remote audio spectrum.\n\nAfter successfully calling RegisterAudioSpectrumObserver, implementing the OnRemoteAudioSpectrum callback in IAudioSpectrumObserver, and calling EnableAudioSpectrumMonitor to enable audio spectrum monitoring, the SDK triggers this callback at the interval you set to report the spectrum of received remote audio data.",
    "parameters": [
      {
        "spectrums": "Audio spectrum information of remote users. See UserAudioSpectrumInfo. The array size equals the number of remote users detected by the SDK. An empty array indicates no remote user audio spectrum was detected."
      },
      {
        "spectrumNumber": "Number of remote users."
      }
    ],
    "returns": "Whether to receive spectrum data: true : Receive. false : Do not receive.",
    "is_hide": false
  },
  {
    "id": "callback_idirectcdnstreamingeventhandler_ondirectcdnstreamingstatechanged",
    "name": "OnDirectCdnStreamingStateChanged",
    "description": "Callback for CDN streaming state changes.\n\nAfter the host starts pushing the stream directly to the CDN, when the streaming state changes, the SDK triggers this callback to report the new state, error code, and message. You can use this information to troubleshoot issues.",
    "parameters": [
      {
        "state": "Current streaming state. See DIRECT_CDN_STREAMING_STATE."
      },
      {
        "reason": "Reason for the streaming state change. See DIRECT_CDN_STREAMING_REASON."
      },
      {
        "message": "Message corresponding to the state change."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_idirectcdnstreamingeventhandler_ondirectcdnstreamingstats",
    "name": "OnDirectCdnStreamingStats",
    "description": "Callback for CDN streaming statistics.\n\nDuring the process of pushing the stream directly to the CDN from the host, the SDK triggers this callback every 1 second.",
    "parameters": [
      {
        "stats": "Current streaming statistics. See DirectCdnStreamingStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_ifaceinfoobserver_onfaceinfo",
    "name": "OnFaceInfo",
    "description": "Reports the face information processed by the voice driver extension.",
    "parameters": [
      {
        "outFaceInfo": "Output parameter. A JSON string of face information processed by the voice driver extension, containing the following fields:\n faces: Array of objects. Contains detected face information, each face corresponds to one object.\n blendshapes: Object. A set of blend shape coefficients named according to the ARKit standard. The internal key-value pairs represent each blend shape coefficient. The coefficient is a float in the range [0.0, 1.0].\n rotation: Array of objects. Head rotation values, including the following key-value pairs with float values in the range [-180.0, 180.0]:\n pitch: Head pitch angle. Positive when looking down, negative when looking up.\n yaw: Head yaw angle. Positive when turning left, negative when turning right.\n roll: Head roll angle. Positive when tilting right, negative when tilting left.\n timestamp: String. Timestamp of the output result in milliseconds. Example JSON: { \"faces\":[{ \"blendshapes\":{ \"eyeBlinkLeft\":0.9, \"eyeLookDownLeft\":0.0, \"eyeLookInLeft\":0.0, \"eyeLookOutLeft\":0.0, \"eyeLookUpLeft\":0.0, \"eyeSquintLeft\":0.0, \"eyeWideLeft\":0.0, \"eyeBlinkRight\":0.0, \"eyeLookDownRight\":0.0, \"eyeLookInRight\":0.0, \"eyeLookOutRight\":0.0, \"eyeLookUpRight\":0.0, \"eyeSquintRight\":0.0, \"eyeWideRight\":0.0, \"jawForward\":0.0, \"jawLeft\":0.0, \"jawRight\":0.0, \"jawOpen\":0.0, \"mouthClose\":0.0, \"mouthFunnel\":0.0, \"mouthPucker\":0.0, \"mouthLeft\":0.0, \"mouthRight\":0.0, \"mouthSmileLeft\":0.0, \"mouthSmileRight\":0.0, \"mouthFrownLeft\":0.0, \"mouthFrownRight\":0.0, \"mouthDimpleLeft\":0.0, \"mouthDimpleRight\":0.0, \"mouthStretchLeft\":0.0, \"mouthStretchRight\":0.0, \"mouthRollLower\":0.0, \"mouthRollUpper\":0.0, \"mouthShrugLower\":0.0, \"mouthShrugUpper\":0.0, \"mouthPressLeft\":0.0, \"mouthPressRight\":0.0, \"mouthLowerDownLeft\":0.0, \"mouthLowerDownRight\":0.0, \"mouthUpperUpLeft\":0.0, \"mouthUpperUpRight\":0.0, \"browDownLeft\":0.0, \"browDownRight\":0.0, \"browInnerUp\":0.0, \"browOuterUpLeft\":0.0, \"browOuterUpRight\":0.0, \"cheekPuff\":0.0, \"cheekSquintLeft\":0.0, \"cheekSquintRight\":0.0, \"noseSneerLeft\":0.0, \"noseSneerRight\":0.0, \"tongueOut\":0.0 }, \"rotation\":{\"pitch\":30.0, \"yaw\":25.5, \"roll\":-15.5}, }], \"timestamp\":\"654879876546\" }"
      }
    ],
    "returns": "true : Successfully parsed the face info JSON. false : Failed to parse the face info JSON.",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayercustomdataprovider_onreaddata",
    "name": "OnReadData",
    "description": "Callback to read media resource data.\n\nWhen using OpenWithMediaSource to open a media resource, the SDK triggers this callback to request a buffer containing media resource data from you.",
    "parameters": [
      {
        "bufferPtr": "Input parameter. Data buffer in bytes. Write the data of size bufferSize reported by the SDK into this parameter."
      },
      {
        "bufferSize": "Length of the data buffer in bytes."
      }
    ],
    "returns": "If data is read successfully, return the actual number of bytes read.\n If data reading fails, return 0.",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayercustomdataprovider_onseek",
    "name": "OnSeek",
    "description": "Callback for seeking media resource data.\n\nWhen opening a media resource using OpenWithMediaSource or Open, the SDK triggers this callback to request seeking to a specified position in the media resource.",
    "parameters": [
      {
        "offset": "Input parameter. The offset from the origin to seek to, in bytes. Can be positive or negative."
      },
      {
        "whence": "Input parameter. Indicates the origin position for seeking. Possible values:\n 0: Origin is the beginning of the data. Actual offset is offset.\n 1: Origin is the current position. Actual offset is current position plus offset.\n 2: Origin is the end of the data. Actual offset is file length plus offset.\n 65536: Do not perform seek operation; return file size. Recommended for playing pure audio files such as MP3 or WAV."
      }
    ],
    "returns": "When whence is 65536, returns the media file size.\n When whence is 0 / 1 / 2, returns the actual offset after seeking.\n -1: Seek failed.",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onaudiovolumeindication",
    "name": "onAudioVolumeIndication",
    "description": "Callback for media player volume indication.\n\nThe SDK triggers this callback every 200 milliseconds to report the current volume of the media player.",
    "parameters": [
      {
        "volume": "Current volume of the player, range: [0,255]."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onmetadata",
    "name": "OnMetaData",
    "description": "Reports acquired media metadata.\n\nAfter parsing the media metadata, the SDK triggers this callback to report the data type and actual data of the metadata.",
    "parameters": [
      {
        "data": "Actual data in a user-defined format."
      },
      {
        "length": "Length of the data in bytes."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onplaybufferupdated",
    "name": "OnPlayBufferUpdated",
    "description": "Reports the duration the current buffered data can support playback.\n\nDuring online media playback, the SDK triggers this callback every second to report the playback duration supported by the current buffered data.\n When the buffered playback duration is less than the threshold (default is 0), PLAYER_EVENT_BUFFER_LOW (6) is returned.\n When the buffered playback duration exceeds the threshold (default is 0), PLAYER_EVENT_BUFFER_RECOVER (7) is returned.",
    "parameters": [
      {
        "playCachedBuffer": "Playback duration supported by the current buffered data (milliseconds)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onplayercachestats",
    "name": "OnPlayerCacheStats",
    "description": "Reports information about the media resources currently in cache.\n\nAfter calling the OpenWithMediaSource method and setting the enableCache member to true, the SDK triggers this callback once per second after the media file is opened to report statistics about the currently cached media files.",
    "parameters": [
      {
        "stats": "Information about the media resources in the cache. See CacheStatistics."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onplayerevent",
    "name": "OnPlayerEvent",
    "description": "Reports player events.\n\nAfter calling Seek to seek playback, the SDK triggers this callback to report the result of the seek operation.",
    "parameters": [
      {
        "eventCode": "Player event. See MEDIA_PLAYER_EVENT."
      },
      {
        "elapsedTime": "Time when the event occurred (milliseconds)."
      },
      {
        "message": "Information about the event."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onplayerinfoupdated",
    "name": "OnPlayerInfoUpdated",
    "description": "Callback when media player related information changes.\n\nThis callback is triggered by the SDK when media player related information changes. You can use it for troubleshooting and diagnostics.",
    "parameters": [
      {
        "info": "Media player related information. See PlayerUpdatedInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onplayerplaybackstats",
    "name": "OnPlayerPlaybackStats",
    "description": "Reports information about the currently playing media resource.\n\nAfter the media resource starts playing, the SDK triggers this callback every second to report related information about the media resource.",
    "parameters": [
      {
        "stats": "Information about the media resource. See PlayerPlaybackStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onplayersourcestatechanged",
    "name": "OnPlayerSourceStateChanged",
    "description": "Reports changes in player state.\n\nThis callback is triggered by the SDK when the player state changes, reporting the new playback state.",
    "parameters": [
      {
        "state": "The new playback state. See MEDIA_PLAYER_STATE."
      },
      {
        "reason": "The reason for the player state change. See MEDIA_PLAYER_REASON."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onplayersrcinfochanged",
    "name": "OnPlayerSrcInfoChanged",
    "description": "Callback for video bitrate changes in media resource.",
    "parameters": [
      {
        "from": "Information about the video bitrate before the change during media playback. See SrcInfo."
      },
      {
        "to": "Information about the video bitrate after the change during media playback. See SrcInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onpositionchanged",
    "name": "OnPositionChanged",
    "description": "Reports the current playback progress of the media resource.\n\nWhile playing a media file, the SDK automatically triggers this callback every second to report the current playback progress.",
    "parameters": [
      {
        "position_ms": "Current playback progress in milliseconds."
      },
      {
        "timestampMs": "NTP timestamp of the current playback progress in milliseconds."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imediaplayersourceobserver_onpreloadevent",
    "name": "OnPreloadEvent",
    "description": "Reports events related to preloading media resources.",
    "parameters": [
      {
        "src": "Path to the media resource."
      },
      {
        "@event": "Event that occurred during media resource preloading. See PLAYER_PRELOAD_EVENT."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imetadataobserver_onmetadatareceived",
    "name": "OnMetadataReceived",
    "description": "Occurs when metadata is received on the receiving end.",
    "parameters": [
      {
        "metadata": "The received metadata. See Metadata."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_imetadataobserver_onreadytosendmetadata",
    "name": "OnReadyToSendMetadata",
    "description": "Occurs when the sender is ready to send metadata.\n\nThis callback is triggered when the SDK is ready to send metadata.",
    "parameters": [
      {
        "source_Type": "The type of video data. See VIDEO_SOURCE_TYPE."
      },
      {
        "metadata": "The metadata the user wants to send. See Metadata."
      }
    ],
    "returns": "true : Send false : Do not send",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onactivespeaker",
    "name": "OnActiveSpeaker",
    "description": "Occurs when the most active remote speaker is detected.\n\nAfter successfully calling EnableAudioVolumeIndication, the SDK continuously monitors the remote user with the highest volume and counts the number of times the user is identified as the loudest. The remote user with the highest count during a given period is considered the most active speaker.\nWhen there are two or more users in the channel and there is an active remote speaker, the SDK triggers this callback and reports the uid of the most active remote speaker.\n If the most active remote speaker remains the same, the SDK does not trigger the OnActiveSpeaker callback again.\n If the most active remote speaker changes, the SDK triggers this callback again and reports the uid of the new most active remote speaker.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "uid": "The ID of the most active remote speaker."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiodevicestatechanged",
    "name": "OnAudioDeviceStateChanged",
    "description": "Callback for audio device state changes.\n\nIndicates that the system audio device state has changed, such as when a headset is unplugged. This method is only available on Windows and macOS.",
    "parameters": [
      {
        "deviceId": "Device ID."
      },
      {
        "deviceType": "Device type definition. See MEDIA_DEVICE_TYPE."
      },
      {
        "deviceState": "Device state. See MEDIA_DEVICE_STATE_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiodevicevolumechanged",
    "name": "OnAudioDeviceVolumeChanged",
    "description": "Callback when the volume of an audio device or the app changes.\n\nThis callback is triggered when the volume of the audio playback device, capture device, or app changes. This callback applies to Windows and macOS only.",
    "parameters": [
      {
        "deviceType": "Device type definition. See MEDIA_DEVICE_TYPE."
      },
      {
        "volume": "Volume. Range: [0,255]."
      },
      {
        "muted": "Whether the audio device is muted: true : The audio device is muted. false : The audio device is not muted."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudioeffectfinished",
    "name": "OnAudioEffectFinished",
    "description": "Callback when the local audio effect file finishes playing.\n\nThis callback is triggered when the audio effect finishes playing.",
    "parameters": [
      {
        "soundId": "The ID of the specified audio effect. Each audio effect has a unique ID."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiomixingfinished",
    "name": "OnAudioMixingFinished",
    "description": "Callback when local music file playback finishes.\n\nDeprecated Deprecated: Use OnAudioMixingStateChanged instead. This callback is triggered when playback of a local music file started with StartAudioMixing [2/2] ends. If StartAudioMixing [2/2] fails, it returns the error code WARN_AUDIO_MIXING_OPEN_ERROR.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiomixingpositionchanged",
    "name": "OnAudioMixingPositionChanged",
    "description": "Callback for music file playback progress.\n\nAfter calling the StartAudioMixing [2/2] method to play a music file, the SDK triggers this callback every second to report the current playback progress.",
    "parameters": [
      {
        "position": "The current playback progress of the music file, in ms."
      }
    ],
    "returns": "0: Success.\n < 0: Failure. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes) for details and troubleshooting.",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiomixingstatechanged",
    "name": "OnAudioMixingStateChanged",
    "description": "Callback when the playback state of the music file changes.\n\nThis callback is triggered when the playback state of the music file changes and reports the current playback state and error code.",
    "parameters": [
      {
        "state": "The playback state of the music file. See AUDIO_MIXING_STATE_TYPE."
      },
      {
        "reason": "Error code. See AUDIO_MIXING_REASON_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiopublishstatechanged",
    "name": "OnAudioPublishStateChanged",
    "description": "Callback for audio publish state change.",
    "parameters": [
      {
        "channel": "Channel name."
      },
      {
        "oldState": "Previous publish state. See STREAM_PUBLISH_STATE."
      },
      {
        "newState": "Current publish state. See STREAM_PUBLISH_STATE."
      },
      {
        "elapseSinceLastState": "Time interval between the two state changes (ms)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudioquality",
    "name": "OnAudioQuality",
    "description": "Reports the audio quality of a remote user.\n\nDeprecated Deprecated: Use OnRemoteAudioStats instead. This callback reports the audio quality of a remote user during a call. It is triggered every 2 seconds for each remote user/host. If there are multiple remote users/hosts, this callback is triggered multiple times every 2 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "The user ID of the sender of the audio stream."
      },
      {
        "quality": "Audio quality. See QUALITY_TYPE."
      },
      {
        "delay": "The delay (ms) from the sender to the receiver, including preprocessing, network transmission, and jitter buffer delay."
      },
      {
        "lost": "The packet loss rate (%) from the sender to the receiver."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudioroutingchanged",
    "name": "OnAudioRoutingChanged",
    "description": "Callback when the audio routing changes.\n\nThis callback is for Android, iOS, and macOS only.",
    "parameters": [
      {
        "routing": "The current audio route. See AudioRoute."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiosubscribestatechanged",
    "name": "OnAudioSubscribeStateChanged",
    "description": "Callback for audio subscribe state change.",
    "parameters": [
      {
        "channel": "Channel name."
      },
      {
        "uid": "ID of the remote user."
      },
      {
        "oldState": "Previous subscribe state. See STREAM_SUBSCRIBE_STATE."
      },
      {
        "newState": "Current subscribe state. See STREAM_SUBSCRIBE_STATE."
      },
      {
        "elapseSinceLastState": "Time interval between the two state changes (ms)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onaudiovolumeindication",
    "name": "OnAudioVolumeIndication",
    "description": "Reports the audio volume indication of users.\n\nThis callback is disabled by default. You can enable it by calling EnableAudioVolumeIndication. Once enabled, as long as there are users publishing streams in the channel, the SDK triggers the OnAudioVolumeIndication callback at the time interval set in EnableAudioVolumeIndication after joining the channel. Each time, two OnAudioVolumeIndication callbacks are triggered: one reports the volume information of the local user who is publishing, and the other reports the volume information of up to three remote users with the highest instantaneous volume. After enabling this feature, if a user mutes themselves (by calling MuteLocalAudioStream), the SDK continues to report the local user's volume indication callback.\nIf a remote user with the highest instantaneous volume mutes themselves for 20 seconds, they will no longer be included in the remote volume indication callback. If all remote users mute themselves, the SDK stops reporting the remote volume indication callback after 20 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "speakers": "User volume information. See the AudioVolumeInfo array. If speakers is empty, it indicates that no remote user is publishing or there are no remote users."
      },
      {
        "speakerNumber": "Number of users.\n In the local user's callback, as long as the local user is publishing, speakerNumber is always 1.\n In the remote users' callback, speakerNumber ranges from [0,3]. If there are more than 3 remote users publishing, speakerNumber is 3 in this callback."
      },
      {
        "totalVolume": "Total mixed volume, ranging from [0,255].\n In the local user's callback, totalVolume is the volume of the local user.\n In the remote users' callback, totalVolume is the total mixed volume of up to three remote users with the highest instantaneous volume."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_oncameraexposureareachanged",
    "name": "OnCameraExposureAreaChanged",
    "description": "Callback when the camera exposure area changes.",
    "parameters": [
      {
        "x": "The x-coordinate of the changed exposure area."
      },
      {
        "y": "The y-coordinate of the changed exposure area."
      },
      {
        "width": "The width of the changed exposure area."
      },
      {
        "height": "The height of the changed exposure area."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_oncamerafocusareachanged",
    "name": "OnCameraFocusAreaChanged",
    "description": "Callback when the camera focus area changes.\n\nThis callback is triggered when the local user calls the SetCameraFocusPositionInPreview method to change the focus position. This callback is applicable to Android and iOS only.",
    "parameters": [
      {
        "x": "The x-coordinate of the changed focus area."
      },
      {
        "y": "The y-coordinate of the changed focus area."
      },
      {
        "width": "The width of the changed focus area."
      },
      {
        "height": "The height of the changed focus area."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_oncameraready",
    "name": "OnCameraReady",
    "description": "Callback when the camera is ready.\n\nDeprecated Deprecated: Use OnLocalVideoStateChanged with LOCAL_VIDEO_STREAM_STATE_CAPTURING(1) instead. This callback indicates that the camera has been successfully opened and video capture can begin.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onchannelmediarelaystatechanged",
    "name": "OnChannelMediaRelayStateChanged",
    "description": "Callback when the state of channel media stream relay changes.\n\nWhen the state of channel media stream relay changes, the SDK triggers this callback and reports the current relay state and related error information.",
    "parameters": [
      {
        "state": "The state of channel media stream relay. See CHANNEL_MEDIA_RELAY_STATE."
      },
      {
        "code": "The error code of channel media stream relay. See CHANNEL_MEDIA_RELAY_ERROR."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onclientrolechanged",
    "name": "OnClientRoleChanged",
    "description": "Callback when the user role or audience latency level is switched.\n\nThis callback is not triggered if you call SetClientRole [1/2] or SetClientRole [2/2] to set the user role to BROADCASTER before joining a channel.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "oldRole": "The role before the switch: CLIENT_ROLE_TYPE."
      },
      {
        "newRole": "The role after the switch: CLIENT_ROLE_TYPE."
      },
      {
        "newRoleOptions": "The options of the new role. See ClientRoleOptions."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onclientrolechangefailed",
    "name": "OnClientRoleChangeFailed",
    "description": "Callback when the user role switch fails.\n\nThis callback informs you of the reason for the failure and the current user role when the user role switch fails.",
    "parameters": [
      {
        "reason": "The reason for the user role switch failure. See CLIENT_ROLE_CHANGE_FAILED_REASON."
      },
      {
        "currentRole": "The current user role. See CLIENT_ROLE_TYPE."
      },
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onconnectionbanned",
    "name": "OnConnectionBanned",
    "description": "Callback when the network connection is banned by the server.\n\nDeprecated Deprecated: Use OnConnectionStateChanged instead.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onconnectioninterrupted",
    "name": "OnConnectionInterrupted",
    "description": "Callback when the network connection is interrupted.\n\nDeprecated Deprecated: Use the OnConnectionStateChanged callback instead. The SDK triggers this callback when it loses network connection for more than 4 seconds after establishing a connection with the server. After this event is triggered, the SDK attempts to reconnect to the server, so this event can be used for UI prompts. The difference between this callback and OnConnectionLost is: OnConnectionInterrupted is triggered only after successfully joining a channel and when the SDK loses connection with the server for more than 4 seconds. OnConnectionLost is triggered regardless of whether the channel is joined, as long as the SDK fails to connect to the server within 10 seconds. If the SDK fails to rejoin the channel within 20 minutes after disconnection, it stops trying to reconnect.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onconnectionlost",
    "name": "OnConnectionLost",
    "description": "Callback when the network connection is lost and the SDK fails to reconnect to the server within 10 seconds.\n\nAfter calling JoinChannel [2/2], this callback is triggered if the SDK fails to connect to the server within 10 seconds, regardless of whether the channel was successfully joined. If the SDK fails to rejoin the channel within 20 minutes after disconnection, it stops trying to reconnect.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onconnectionstatechanged",
    "name": "OnConnectionStateChanged",
    "description": "Callback when the network connection state changes.\n\nThis callback is triggered when the network connection state changes and informs you of the current state and the reason for the change.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "state": "Current network connection state. See CONNECTION_STATE_TYPE."
      },
      {
        "reason": "Reason for the change in network connection state. See CONNECTION_CHANGED_REASON_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onencryptionerror",
    "name": "OnEncryptionError",
    "description": "Callback when built-in encryption fails.\n\nAfter calling EnableEncryption to enable encryption, if encryption or decryption fails on the sender or receiver side, the SDK triggers this callback.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "errorType": "Error type. See ENCRYPTION_ERROR_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onerror",
    "name": "OnError",
    "description": "Callback when an error occurs.\n\nThis callback indicates that a network or media-related error occurred during SDK runtime. In most cases, errors reported by the SDK mean that the SDK cannot recover automatically and requires app intervention or user notification.",
    "parameters": [
      {
        "err": "Error code. See ERROR_CODE_TYPE."
      },
      {
        "msg": "Error description."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onextensionerrorwithcontext",
    "name": "OnExtensionErrorWithContext",
    "description": "Callback for extension errors.\n\nThis callback is triggered when enabling the extension fails or the extension encounters a runtime error, reporting the error code and reason.",
    "parameters": [
      {
        "context": "Extension context information. See ExtensionContext."
      },
      {
        "error": "Error code. See the plugin documentation provided by the extension provider."
      },
      {
        "message": "Error reason. See the plugin documentation provided by the extension provider."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onextensioneventwithcontext",
    "name": "OnExtensionEventWithContext",
    "description": "Callback for extension events.\n\nTo listen for extension events, you need to register this callback.",
    "parameters": [
      {
        "context": "Extension context information. See ExtensionContext."
      },
      {
        "key": "The key of the extension property."
      },
      {
        "value": "The value corresponding to the extension property key."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onextensionstartedwithcontext",
    "name": "OnExtensionStartedWithContext",
    "description": "Callback when the extension is successfully enabled.\n\nThis callback is triggered after the extension is successfully enabled.",
    "parameters": [
      {
        "context": "Extension context information. See ExtensionContext."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onextensionstoppedwithcontext",
    "name": "OnExtensionStoppedWithContext",
    "description": "Callback when the extension is disabled.\n\nThis callback is triggered after the extension is successfully disabled.",
    "parameters": [
      {
        "context": "Extension context information. See ExtensionContext."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfacepositionchanged",
    "name": "OnFacePositionChanged",
    "description": "Reports the result of local face detection.\n\nAfter calling EnableFaceDetection(true) to enable local face detection, you can use this callback to get the following face detection information in real time:\n The size of the image captured by the camera\n The position of the face in the view\n The distance between the face and the device screen The distance between the face and the device screen is estimated by the SDK based on the size of the captured image and the position of the face in the view.\n This callback is only applicable to Android and iOS platforms.\n When the face in front of the camera disappears, this callback is triggered immediately; when no face is detected, the callback frequency is reduced to save device power.\n When the face is too close to the device screen, the SDK does not trigger this callback.",
    "parameters": [
      {
        "imageWidth": "Width (px) of the image captured by the camera."
      },
      {
        "imageHeight": "Height (px) of the image captured by the camera."
      },
      {
        "vecRectangle": "Detected face information. See Rectangle."
      },
      {
        "vecDistance": "Distance (cm) between the face and the device screen."
      },
      {
        "numFaces": "Number of faces detected. If 0, no face is detected."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfirstlocalaudioframepublished",
    "name": "OnFirstLocalAudioFramePublished",
    "description": "Occurs when the first local audio frame is published.\n\nThe SDK triggers this callback in the following situations:\n After successfully joining a channel by calling JoinChannel [2/2] with local audio enabled.\n After calling MuteLocalAudioStream(true) and then MuteLocalAudioStream(false).\n After calling DisableAudio and then EnableAudio.\n After successfully pushing an audio frame to the SDK using PushAudioFrame.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "elapsed": "The time elapsed (ms) from calling JoinChannel [2/2] to the triggering of this callback."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfirstlocalvideoframe",
    "name": "OnFirstLocalVideoFrame",
    "description": "Callback when the first local video frame is rendered.\n\nThe SDK triggers this callback when the first local video frame is rendered on the local view.",
    "parameters": [
      {
        "source": "The type of video source. See VIDEO_SOURCE_TYPE."
      },
      {
        "width": "The width (px) of the locally rendered video."
      },
      {
        "height": "The height (px) of the locally rendered video."
      },
      {
        "elapsed": "Time elapsed (ms) from calling JoinChannel [1/2] or JoinChannel [2/2] to when this event occurs. If StartPreview [1/2] / StartPreview [2/2] was called before joining the channel, this parameter indicates the time elapsed from calling StartPreview [1/2] or StartPreview [2/2] to when this event occurs."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfirstlocalvideoframepublished",
    "name": "OnFirstLocalVideoFramePublished",
    "description": "Callback when the first local video frame is published.\n\nThe SDK triggers this callback under the following conditions:\n After successfully joining a channel by calling JoinChannel [1/2] or JoinChannel [2/2] with the local video module enabled.\n After calling MuteLocalVideoStream(true) and then MuteLocalVideoStream(false).\n After calling DisableVideo and then EnableVideo.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "elapsed": "The time interval (ms) from calling JoinChannel [1/2] or JoinChannel [2/2] to when this callback is triggered."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfirstremoteaudiodecoded",
    "name": "OnFirstRemoteAudioDecoded",
    "description": "Occurs when the first remote audio frame is decoded.\n\nDeprecated Deprecated: Use OnRemoteAudioStateChanged instead. The SDK triggers this callback in the following situations:\n When a remote user sends audio after joining the channel for the first time.\n When a remote user goes offline and rejoins to send audio again. Offline means no audio packet is received within 15 seconds, which may be caused by:\n The remote user leaves the channel\n The remote user is disconnected\n The remote user calls MuteLocalAudioStream to stop sending audio\n The remote user calls DisableAudio to disable audio",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "uid": "The ID of the remote user."
      },
      {
        "elapsed": "The delay (ms) from the local user calling JoinChannel [2/2] to the triggering of this callback."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfirstremoteaudioframe",
    "name": "OnFirstRemoteAudioFrame",
    "description": "Occurs when the first remote audio frame is received.\n\nDeprecated Deprecated: Use OnRemoteAudioStateChanged instead.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "userId": "The user ID of the remote user who sends the audio frame."
      },
      {
        "elapsed": "The delay (ms) from the local user calling JoinChannel [2/2] to the triggering of this callback."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfirstremotevideodecoded",
    "name": "OnFirstRemoteVideoDecoded",
    "description": "Callback when the first remote video frame is received and decoded.\n\nThe SDK triggers this callback under the following conditions:\n A remote user sends video after joining the channel for the first time.\n A remote user sends video after going offline and coming back online. Possible reasons for the interruption include:\n The remote user leaves the channel.\n The remote user gets disconnected.\n The remote user calls DisableVideo to disable the video module.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "User ID indicating which user's video stream it is."
      },
      {
        "width": "Width (px) of the video stream."
      },
      {
        "height": "Height (px) of the video stream."
      },
      {
        "elapsed": "Delay (ms) from when JoinChannel [1/2] or JoinChannel [2/2] is called locally to when this callback is triggered."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onfirstremotevideoframe",
    "name": "OnFirstRemoteVideoFrame",
    "description": "Callback when the renderer receives the first frame of remote video.\n\nThis callback is triggered only when the SDK handles rendering. If you use custom video rendering, this callback is not triggered. You need to implement it yourself outside the SDK.",
    "parameters": [
      {
        "remoteUid": "User ID that specifies whose video stream it is."
      },
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "width": "Width of the video stream (px)."
      },
      {
        "height": "Height of the video stream (px)."
      },
      {
        "elapsed": "Time elapsed (ms) from the local call to JoinChannel [1/2] or JoinChannel [2/2] until this event occurs."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onjoinchannelsuccess",
    "name": "OnJoinChannelSuccess",
    "description": "Callback when successfully joined a channel.\n\nThis callback indicates that the client has successfully joined the specified channel.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "elapsed": "Time elapsed (ms) from the local call to JoinChannel [2/2] to the occurrence of this event."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlastmileproberesult",
    "name": "OnLastmileProbeResult",
    "description": "Callback for the last mile network probe result before a call.\n\nAfter calling StartLastmileProbeTest, the SDK returns this callback within approximately 30 seconds.",
    "parameters": [
      {
        "result": "Last mile probe result for uplink and downlink. See LastmileProbeResult."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlastmilequality",
    "name": "OnLastmileQuality",
    "description": "Callback for last mile network quality before joining a channel.\n\nThis callback reports the result of the last mile network probe before the local user joins a channel. The last mile refers to the network connection between the device and the Agora edge server.\nBefore joining a channel, after calling StartLastmileProbeTest, the SDK triggers this callback to report the last mile network probe result for the local user.",
    "parameters": [
      {
        "quality": "Last mile network quality. See QUALITY_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onleavechannel",
    "name": "OnLeaveChannel",
    "description": "Callback when leaving a channel.\n\nYou can use this callback to get information such as the total call duration and the amount of data sent and received by the SDK during the call.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "stats": "Call statistics. See RtcStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlocalaudiostatechanged",
    "name": "OnLocalAudioStateChanged",
    "description": "Callback when the local audio state changes.\n\nWhen the state of the local audio (including microphone capture and audio encoding) changes, the SDK triggers this callback to report the current local audio state. When a local audio issue occurs, this callback helps you understand the current audio state and the reason for the issue, making it easier to troubleshoot. When the state is LOCAL_AUDIO_STREAM_STATE_FAILED (3), you can check the returned error information in the error parameter.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "state": "Current local audio state. See LOCAL_AUDIO_STREAM_STATE."
      },
      {
        "reason": "Reason for the local audio state change. See LOCAL_AUDIO_STREAM_REASON."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlocalaudiostats",
    "name": "OnLocalAudioStats",
    "description": "Callback for statistics of the local audio stream during a call.\n\nThe SDK triggers this callback every 2 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "stats": "Local audio statistics. See LocalAudioStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlocaluserregistered",
    "name": "OnLocalUserRegistered",
    "description": "Callback when the local user successfully registers a User Account.\n\nThis callback is triggered after the local user successfully registers a User Account by calling RegisterLocalUserAccount, or joins a channel by calling JoinChannelWithUserAccount [2/2]. It informs you of the local user's UID and User Account.",
    "parameters": [
      {
        "uid": "The local user's ID."
      },
      {
        "userAccount": "The local user's User Account."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlocalvideoevent",
    "name": "OnLocalVideoEvent",
    "description": "Callback triggered when a local video event occurs.\n\nSince Available since v4.6.1. You can use this callback to get the reason for the local video event.",
    "parameters": [
      {
        "source": "The video source type. See VIDEO_SOURCE_TYPE."
      },
      {
        "event": "The local video event type. See LOCAL_VIDEO_EVENT_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlocalvideostatechanged",
    "name": "OnLocalVideoStateChanged",
    "description": "Callback when the local video state changes.\n\nThis callback is triggered when the local video state changes. The SDK reports the current local video state and the reason for the change.\n Frame duplication detection applies only to video frames with resolution greater than 200 Ã— 200, frame rate â‰¥ 10 fps, and bitrate less than 20 Kbps.\n If an exception occurs during video capture, normally you can troubleshoot via the reason parameter in this callback. However, on some devices, when capture issues occur (e.g., freeze), Android may not throw any error callback, so the SDK cannot report the reason for local video state changes. In this case, you can determine whether frames are being captured by checking if this callback reports state as LOCAL_VIDEO_STREAM_STATE_CAPTURING or LOCAL_VIDEO_STREAM_STATE_ENCODING, and the captureFrameRate in the OnLocalVideoStats callback is 0.",
    "parameters": [
      {
        "source": "Type of video source. See VIDEO_SOURCE_TYPE."
      },
      {
        "state": "Local video state. See LOCAL_VIDEO_STREAM_STATE."
      },
      {
        "reason": "Reason for the local video state change. See LOCAL_VIDEO_STREAM_REASON."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlocalvideostats",
    "name": "OnLocalVideoStats",
    "description": "Callback for local video stream statistics.\n\nThis callback reports statistics about the local device sending video streams. It is triggered every 2 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "stats": "Local video stream statistics. See LocalVideoStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onlocalvideotranscodererror",
    "name": "OnLocalVideoTranscoderError",
    "description": "Callback for local video transcoding error.\n\nWhen StartLocalVideoTranscoder or UpdateLocalTranscoderConfiguration fails, the SDK triggers this callback to report the reason for the failure.",
    "parameters": [
      {
        "stream": "The video stream that failed to transcode. See TranscodingVideoStream."
      },
      {
        "error": "Reason for the local video transcoding error. See VIDEO_TRANSCODER_ERROR."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onmultipathstats",
    "name": "OnMultipathStats",
    "description": "Callback for multipath transmission statistics.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "stats": "Multipath transmission statistics. See MultipathStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onnetworkquality",
    "name": "OnNetworkQuality",
    "description": "Callback for uplink and downlink last mile network quality of each user during a call.\n\nThis callback reports the last mile network status of each user during a call. The last mile refers to the network connection between the device and the Agora edge server.\nThis callback is triggered every 2 seconds. If there are multiple remote users, it is triggered multiple times every 2 seconds.\nThe callback reports network quality via broadcast packets within the channel. Excessive broadcast packets may cause a broadcast storm. To prevent this, the callback supports reporting network quality for up to 4 remote hosts simultaneously by default. When the user is not sending streams, txQuality is UNKNOWN; when not receiving streams, rxQuality is UNKNOWN.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "User ID. Indicates the network quality report is for the user with this ID. If uid is 0, the report is for the local user."
      },
      {
        "txQuality": "Uplink network quality of the user, calculated based on sending bitrate, uplink packet loss rate, average RTT, and network jitter. This value reflects the current uplink quality and helps determine if the current video encoding settings are supported. For example, with an uplink bitrate of 1000 Kbps, 640 Ã— 480 resolution at 15 fps is supported in live broadcast scenarios, but 1280 Ã— 720 resolution may not be. See QUALITY_TYPE."
      },
      {
        "rxQuality": "Downlink network quality of the user, calculated based on downlink packet loss rate, average RTT, and network jitter. See QUALITY_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onnetworktypechanged",
    "name": "OnNetworkTypeChanged",
    "description": "Callback when the local network type changes.\n\nWhen the local network connection type changes, the SDK triggers this callback and specifies the current network type. You can use this callback to get the current network type. When the connection is interrupted, this callback helps determine whether the cause is a network switch or poor network conditions.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "type": "Local network connection type. See NETWORK_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onpermissionerror",
    "name": "OnPermissionError",
    "description": "Callback when failing to obtain device permission.\n\nWhen the SDK fails to obtain device permission, it triggers this callback to report which device permission could not be obtained.",
    "parameters": [
      {
        "permissionType": "Device permission type. See PERMISSION_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onpermissiongranted",
    "name": "OnPermissionGranted",
    "description": "Callback when a permission is granted.",
    "parameters": [
      {
        "permissionType": "Permission type. See PERMISSION_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onproxyconnected",
    "name": "OnProxyConnected",
    "description": "Callback for proxy connection status.\n\nYou can use this callback to monitor the SDK's proxy connection status. For example, when a user calls SetCloudProxy to set a proxy and successfully joins a channel, the SDK triggers this callback to report the user ID, the type of proxy connected, and the time elapsed from calling JoinChannel [2/2] to this callback being triggered.",
    "parameters": [
      {
        "channel": "Channel name."
      },
      {
        "uid": "User ID"
      },
      {
        "proxyType": "Type of proxy connected. See PROXY_TYPE."
      },
      {
        "localProxyIp": "Reserved parameter, currently not supported."
      },
      {
        "elapsed": "Time elapsed (ms) from calling JoinChannel [2/2] to the SDK triggering this callback."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onrejoinchannelsuccess",
    "name": "OnRejoinChannelSuccess",
    "description": "Callback when successfully rejoined a channel.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "elapsed": "Time interval (ms) from the call to JoinChannel [2/2] to the triggering of this callback."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onremoteaudiostatechanged",
    "name": "OnRemoteAudioStateChanged",
    "description": "Callback when the remote audio stream state changes.\n\nWhen the audio state of a remote user (in a communication scenario) or host (in a live streaming scenario) changes, the SDK triggers this callback to report the current remote audio stream state to the local user. When there are more than 32 users (in a communication scenario) or hosts (in a live streaming scenario) in the channel, this callback may be inaccurate.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "ID of the remote user whose audio state changed."
      },
      {
        "state": "Remote audio stream state. See REMOTE_AUDIO_STATE."
      },
      {
        "reason": "Specific reason for the remote audio stream state change. See REMOTE_AUDIO_STATE_REASON."
      },
      {
        "elapsed": "Time elapsed (in ms) from the local user calling JoinChannel [2/2] to the occurrence of this event."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onremoteaudiostats",
    "name": "OnRemoteAudioStats",
    "description": "Callback for statistics of the remote audio stream during a call.\n\nThis callback is triggered every 2 seconds for each remote user/host sending an audio stream. If multiple remote users/hosts are sending audio streams, this callback is triggered multiple times every 2 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "stats": "Received remote audio statistics. See RemoteAudioStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onremoteaudiotransportstats",
    "name": "OnRemoteAudioTransportStats",
    "description": "Callback for transport statistics of the remote audio stream during a call.\n\nDeprecated:\nUse OnRemoteAudioStats instead.\nThis callback describes end-to-end network statistics for a remote user during a call, calculated based on audio packets. It uses objective data such as packet loss and network delay to reflect the current network status. During a call, when the user receives audio packets from a remote user/host, this callback is triggered every 2 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "User ID indicating which user/host the audio packet belongs to."
      },
      {
        "delay": "Delay (ms) from the sender to the receiver for audio packets."
      },
      {
        "lost": "Packet loss rate (%) from the sender to the receiver for audio packets."
      },
      {
        "rxKBitrate": "Received bitrate (Kbps) of the remote audio packets."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onremotesubscribefallbacktoaudioonly",
    "name": "OnRemoteSubscribeFallbackToAudioOnly",
    "description": "Callback when the subscribed stream falls back to audio-only or recovers to audio-video.\n\nAfter you call SetRemoteSubscribeFallbackOption and set option to STREAM_FALLBACK_OPTION_AUDIO_ONLY, this callback is triggered in the following cases:\n The downlink network condition is poor, and the subscribed audio-video stream falls back to audio-only.\n The downlink network condition improves, and the subscribed audio stream recovers to audio-video. When the subscribed stream falls back to a lower-quality video stream due to poor network conditions, you can monitor the switch between remote video streams via the OnRemoteVideoStats callback.",
    "parameters": [
      {
        "uid": "The user ID of the remote user."
      },
      {
        "isFallbackOrRecover": "true : The subscribed stream has fallen back to audio-only due to poor network conditions. false : The subscribed stream has recovered to audio-video due to improved network conditions."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onremotevideostatechanged",
    "name": "OnRemoteVideoStateChanged",
    "description": "Callback when the remote video state changes.\n\nWhen the number of users (in communication scenario) or hosts (in live streaming scenario) in the channel exceeds 32, this callback may be inaccurate.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "Remote user ID whose video state has changed."
      },
      {
        "state": "Remote video stream state. See REMOTE_VIDEO_STATE."
      },
      {
        "reason": "Specific reason for the remote video stream state change. See REMOTE_VIDEO_STATE_REASON."
      },
      {
        "elapsed": "Time elapsed (ms) from the local user calling JoinChannel [2/2] to when this event occurs."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onremotevideostats",
    "name": "OnRemoteVideoStats",
    "description": "Callback for remote video stream statistics during a call.\n\nThis callback reports end-to-end video stream statistics of remote users during a call. It is triggered every 2 seconds for each remote user/host. If there are multiple remote users/hosts, this callback is triggered multiple times every 2 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "stats": "Remote video statistics. See RemoteVideoStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onremotevideotransportstats",
    "name": "OnRemoteVideoTransportStats",
    "description": "Callback for transport statistics of remote video streams during a call.\n\nDeprecated Deprecated: This callback is deprecated. Use OnRemoteVideoStats instead. This callback reports end-to-end network statistics of remote users during a call, calculated based on video packets. It provides objective data such as packet loss and network delay to reflect the current network status.\nDuring a call, when a user receives video packets sent by a remote user/host, this callback is triggered every 2 seconds.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "User ID that specifies whose video packet it is (user/host)."
      },
      {
        "delay": "Delay (ms) from sender to receiver for the video packet."
      },
      {
        "lost": "Packet loss rate (%) from sender to receiver for the video packet."
      },
      {
        "rxKBitRate": "Receiving bitrate of the remote video packet (Kbps)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onrenewtokenresult",
    "name": "OnRenewTokenResult",
    "description": "Callback for the result of renewToken method call.\n\nSince Available since v4.6.2. This callback is triggered after you call the renewToken method to update the token, to notify the result of the update.",
    "parameters": [
      {
        "token": "The updated token."
      },
      {
        "code": "Error code. See RENEW_TOKEN_ERROR_CODE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onrequesttoken",
    "name": "OnRequestToken",
    "description": "Callback when the token has expired.\n\nDuring audio and video interaction, if the token becomes invalid, the SDK triggers this callback to report that the token has expired.\nWhen you receive this callback, you need to generate a new token on your server and update the token using one of the following methods:\n Single-channel scenario:\n Call RenewToken to pass in the new token.\n Call LeaveChannel [2/2] to leave the current channel, then call JoinChannel [2/2] with the new token to rejoin the channel.\n Multi-channel scenario: Call UpdateChannelMediaOptionsEx to pass in the new token.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onrhythmplayerstatechanged",
    "name": "OnRhythmPlayerStateChanged",
    "description": "Callback when the virtual metronome state changes.\n\nDeprecated Deprecated since v4.6.2. This callback is triggered when the virtual metronome state changes. If the virtual metronome encounters a failure, this callback helps you understand the current state and the reason for the failure, facilitating troubleshooting. (Android and iOS only)",
    "parameters": [
      {
        "state": "Current state of the virtual metronome. See RHYTHM_PLAYER_STATE_TYPE."
      },
      {
        "reason": "Error code and message when an error occurs in the virtual metronome. See RHYTHM_PLAYER_REASON."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onrtcstats",
    "name": "OnRtcStats",
    "description": "Callback for statistics related to the current call.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "stats": "RTC engine statistics. See RtcStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onrtmpstreamingevent",
    "name": "OnRtmpStreamingEvent",
    "description": "Callback for RTMP streaming events.",
    "parameters": [
      {
        "url": "The RTMP streaming URL."
      },
      {
        "eventCode": "The RTMP streaming event code. See RTMP_STREAMING_EVENT."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onrtmpstreamingstatechanged",
    "name": "OnRtmpStreamingStateChanged",
    "description": "Callback when the RTMP streaming state changes.\n\nThe SDK triggers this callback when the RTMP streaming state changes. The callback provides the URL whose state changed and the current streaming state. This helps users understand the current streaming status. If a streaming error occurs, you can use the returned error code to identify the cause and troubleshoot the issue.",
    "parameters": [
      {
        "url": "The URL whose streaming state has changed."
      },
      {
        "state": "The current streaming state. See RTMP_STREAM_PUBLISH_STATE."
      },
      {
        "reason": "The reason for the streaming state change. See RTMP_STREAM_PUBLISH_REASON."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onsnapshottaken",
    "name": "OnSnapshotTaken",
    "description": "Callback for snapshot result.\n\nAfter successfully calling TakeSnapshot [1/2], the SDK triggers this callback to report whether the snapshot succeeded and provide snapshot details.",
    "parameters": [
      {
        "uid": "User ID. If uid is 0, it refers to the local user."
      },
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "filePath": "Local path where the snapshot is saved."
      },
      {
        "width": "Image width (px)."
      },
      {
        "height": "Image height (px)."
      },
      {
        "errCode": "Indicates success or failure of the snapshot.\n 0: Snapshot succeeded.\n < 0: Snapshot failed.\n -1: Failed to write to file or JPEG encoding failed.\n -2: No video frame received from the specified user within 1 second after calling TakeSnapshot [1/2]. Possible reasons: local capture stopped, remote user stopped publishing, or video data processing is blocked.\n -3: TakeSnapshot [1/2] is called too frequently."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onstreammessage",
    "name": "OnStreamMessage",
    "description": "Occurs when a stream message is received from a remote user.\n\nThis callback indicates that the local user has received a stream message sent by a remote user using the SendStreamMessage method. If you need a more comprehensive, low-latency, high-concurrency, and scalable real-time messaging and state synchronization solution, we recommend using [Real-time Messaging](https://doc.shengwang.cn/doc/rtm2/unity/landing-page).",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "The user ID of the sender."
      },
      {
        "streamId": "The stream ID of the received message."
      },
      {
        "data": "The received data."
      },
      {
        "length": "The length of the data in bytes."
      },
      {
        "sentTs": "The timestamp when the data stream was sent."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onstreammessageerror",
    "name": "OnStreamMessageError",
    "description": "Occurs when a stream message from a remote user fails to be received.\n\nThis callback indicates that the local user failed to receive a stream message sent by a remote user using the SendStreamMessage method. If you need a more comprehensive, low-latency, high-concurrency, and scalable real-time messaging and state synchronization solution, we recommend using [Real-time Messaging](https://doc.shengwang.cn/doc/rtm2/unity/landing-page).",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "The user ID of the sender."
      },
      {
        "streamId": "The stream ID of the received message."
      },
      {
        "code": "The error code. See [Error Codes](https://docs.agora.io/en/video-calling/troubleshooting/error-codes)."
      },
      {
        "missed": "The number of lost messages."
      },
      {
        "cached": "The number of messages cached after the data stream was interrupted."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_ontokenprivilegewillexpire",
    "name": "OnTokenPrivilegeWillExpire",
    "description": "Callback when the token will expire in 30 seconds.\n\nWhen you receive this callback, you need to generate a new token on your server and update the token using one of the following methods:\n Single-channel scenario:\n Call RenewToken to pass in the new token.\n Call LeaveChannel [2/2] to leave the current channel, then call JoinChannel [2/2] with the new token to rejoin the channel.\n Multi-channel scenario: Call UpdateChannelMediaOptionsEx to pass in the new token.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "token": "The token that is about to expire."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_ontranscodedstreamlayoutinfo",
    "name": "OnTranscodedStreamLayoutInfo",
    "description": "Occurs when a mixed video stream with layout information is received.\n\nThis callback is triggered when the local client receives a mixed video stream from the mixing server for the first time, or when the layout information of the mixed stream changes. The SDK reports the layout information of each sub-stream in the mixed video stream. This callback is only applicable to Android and iOS.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "uid": "User ID of the publisher of the mixed video stream."
      },
      {
        "width": "Width (px) of the mixed video stream."
      },
      {
        "height": "Height (px) of the mixed video stream."
      },
      {
        "layoutCount": "Number of layout entries in the mixed video stream."
      },
      {
        "layoutlist": "Detailed layout information of a mixed video stream. See VideoLayout."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_ontranscodingupdated",
    "name": "OnTranscodingUpdated",
    "description": "Callback when the RTMP transcoding settings are updated.\n\nThe OnTranscodingUpdated callback is triggered and reports update information to the host when the LiveTranscoding parameters in the StartRtmpStreamWithTranscoding method are updated. This callback is not triggered when you call StartRtmpStreamWithTranscoding for the first time to set the LiveTranscoding parameters.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onuplinknetworkinfoupdated",
    "name": "OnUplinkNetworkInfoUpdated",
    "description": "Callback for uplink network information changes.\n\nThe SDK triggers this callback only when the uplink network information changes. This callback only applies when pushing externally encoded video data in H.264 format to the SDK.",
    "parameters": [
      {
        "info": "Uplink network information. See UplinkNetworkInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onuserenablelocalvideo",
    "name": "OnUserEnableLocalVideo",
    "description": "Callback when a remote user enables or disables local video capture.\n\nDeprecated Deprecated: This callback is deprecated. Use the OnRemoteVideoStateChanged callback with the following enumerations: REMOTE_VIDEO_STATE_STOPPED (0) and REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED (5). REMOTE_VIDEO_STATE_DECODING (2) and REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED (6). This callback is triggered when a remote user calls the EnableLocalVideo method to enable or disable video capture.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "User ID indicating which user's video stream it is."
      },
      {
        "enabled": "Whether the remote user enables video capture: true : The user has enabled the video feature. Other users can receive this user's video stream. false : The user has disabled the video feature. The user can still receive other users' video streams, but others cannot receive this user's video stream."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onuserenablevideo",
    "name": "OnUserEnableVideo",
    "description": "Callback when a remote user enables or disables the video module.\n\nDisabling the video feature means the user can only make voice calls, cannot display or send their own video, nor receive or display others' video.\nThis callback is triggered when a remote user calls the EnableVideo or DisableVideo method to enable or disable the video module.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "User ID indicating which user's video stream it is."
      },
      {
        "enabled": "true : The user has enabled the video feature. false : The user has disabled the video feature."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onuserinfoupdated",
    "name": "OnUserInfoUpdated",
    "description": "Callback when remote user information is updated.\n\nAfter a remote user joins a channel, the SDK obtains the UID and User Account of the remote user, then caches a mapping table containing the remote user's UID and User Account, and triggers this callback locally.",
    "parameters": [
      {
        "uid": "Remote user ID."
      },
      {
        "info": "The UserInfo object identifying user information, including UID and User Account. See the UserInfo class."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onuserjoined",
    "name": "OnUserJoined",
    "description": "Callback when a remote user (in communication) or host (in live broadcast) joins the current channel.\n\nIn communication scenarios, this callback indicates that a remote user has joined the channel. If other users are already in the channel before the new user joins, the new user also receives callbacks for those existing users.\n In live broadcast scenarios, this callback indicates that a host has joined the channel. If other hosts are already in the channel before the new one joins, the new user also receives callbacks for those existing hosts. It is recommended to keep the number of co-hosts under 32 (including no more than 17 video co-hosts).",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "ID of the remote user/host who joined the channel."
      },
      {
        "elapsed": "Time elapsed (ms) from the local user calling JoinChannel [1/2] or JoinChannel [2/2] to the triggering of this callback."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onusermuteaudio",
    "name": "OnUserMuteAudio",
    "description": "Callback when a remote user (in a communication scenario) or host (in a live streaming scenario) stops or resumes sending audio stream.\n\nThis callback is triggered when the remote user calls the MuteLocalAudioStream method to disable or enable audio sending. When there are more than 32 users (in a communication scenario) or hosts (in a live streaming scenario) in the channel, this callback may be inaccurate.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "User ID."
      },
      {
        "muted": "Whether the user is muted: true : The user has muted the audio. false : The user has unmuted the audio."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onusermutevideo",
    "name": "OnUserMuteVideo",
    "description": "Callback when a remote user stops or resumes publishing the video stream.\n\nWhen a remote user calls MuteLocalVideoStream to stop or resume publishing the video stream, the SDK triggers this callback to report the remote user's publishing status to the local user. When the number of users (in communication scenario) or hosts (in live streaming scenario) in the channel exceeds 32, this callback may be inaccurate.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "Remote user ID."
      },
      {
        "muted": "Whether the remote user stops publishing the video stream: true : Stops publishing the video stream. false : Publishes the video stream."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onuseroffline",
    "name": "OnUserOffline",
    "description": "Callback when a remote user (in communication) or host (in live broadcast) leaves the current channel.\n\nUsers generally leave the channel for the following reasons:\n Normal departure: The remote user or host sends a 'goodbye' message and leaves the channel voluntarily.\n Timeout disconnection: If no data packet is received from the other party within a certain period (20 seconds for communication, slightly longer for live broadcast), the user is considered disconnected. In poor network conditions, false positives may occur. It is recommended to use the RTM SDK for reliable disconnection detection.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "remoteUid": "ID of the remote user or host who went offline."
      },
      {
        "reason": "Reason why the remote user (in communication) or host (in live broadcast) went offline. See USER_OFFLINE_REASON_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onvideodevicestatechanged",
    "name": "OnVideoDeviceStateChanged",
    "description": "Callback for video device state changes.\n\nThis callback notifies you when the system video device state changes, such as being unplugged or removed. If an external camera is used for capturing and it is unplugged, the video will be interrupted. (Windows and macOS only)",
    "parameters": [
      {
        "deviceId": "Device ID."
      },
      {
        "deviceType": "Device type. See MEDIA_DEVICE_TYPE."
      },
      {
        "deviceState": "Device state. See MEDIA_DEVICE_STATE_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onvideopublishstatechanged",
    "name": "OnVideoPublishStateChanged",
    "description": "Callback when the video publishing state changes.",
    "parameters": [
      {
        "channel": "Channel name."
      },
      {
        "source": "Type of video source. See VIDEO_SOURCE_TYPE."
      },
      {
        "oldState": "Previous publishing state. See STREAM_PUBLISH_STATE."
      },
      {
        "newState": "Current publishing state. See STREAM_PUBLISH_STATE."
      },
      {
        "elapseSinceLastState": "Time interval (ms) between the two state changes."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onvideorenderingtracingresult",
    "name": "OnVideoRenderingTracingResult",
    "description": "Reports video frame rendering events.\n\nAfter calling the StartMediaRenderingTracing method or joining a channel, the SDK triggers this callback to report video frame rendering events and metrics during the rendering process. Developers can optimize based on these metrics to improve rendering efficiency.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "uid": "User ID."
      },
      {
        "currentEvent": "Current video frame rendering event. See MEDIA_TRACE_EVENT."
      },
      {
        "tracingInfo": "Metrics during the video frame rendering process. Developers should minimize these values to improve rendering efficiency. See VideoRenderingTracingInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onvideosizechanged",
    "name": "OnVideoSizeChanged",
    "description": "Callback when the size or rotation of local or remote video changes.",
    "parameters": [
      {
        "connection": "Connection information. See RtcConnection."
      },
      {
        "sourceType": "Type of video source. See VIDEO_SOURCE_TYPE."
      },
      {
        "uid": "User ID whose image size or rotation changes (the uid of the local user is 0, in which case the video is a local preview)."
      },
      {
        "width": "Width of the video stream (pixels)."
      },
      {
        "height": "Height of the video stream (pixels)."
      },
      {
        "rotation": "Rotation information, range [0,360). On iOS, this parameter is always 0."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onvideostopped",
    "name": "OnVideoStopped",
    "description": "Callback when the video function is stopped.\n\nDeprecated Deprecated: Use the OnLocalVideoStateChanged callback with LOCAL_VIDEO_STREAM_STATE_STOPPED (0) instead. If the app needs to handle the view after stopping the video (such as displaying other content), it can do so in this callback.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_irtcengineeventhandler_onvideosubscribestatechanged",
    "name": "OnVideoSubscribeStateChanged",
    "description": "Callback for video subscribe state change.",
    "parameters": [
      {
        "channel": "Channel name."
      },
      {
        "uid": "ID of the remote user."
      },
      {
        "oldState": "Previous subscribe state. See STREAM_SUBSCRIBE_STATE."
      },
      {
        "newState": "Current subscribe state. See STREAM_SUBSCRIBE_STATE."
      },
      {
        "elapseSinceLastState": "Time interval between the two state changes (ms)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "callback_ivideoencodedframeobserver_onencodedvideoframereceived",
    "name": "OnEncodedVideoFrameReceived",
    "description": "Reports that the receiver has received an encoded video frame sent by a remote user.\n\nWhen you call the SetRemoteVideoSubscriptionOptions method and set encodedFrameOnly to true, the SDK triggers this callback locally to report the received encoded video frame information.",
    "parameters": [
      {
        "channelId": "Channel name."
      },
      {
        "uid": "Remote user ID."
      },
      {
        "imageBufferPtr": "Video image buffer."
      },
      {
        "length": "Data length of the video image."
      },
      {
        "videoEncodedFrameInfo": "Encoded video frame information. See EncodedVideoFrameInfo."
      }
    ],
    "returns": "No actual meaning.",
    "is_hide": false
  },
  {
    "id": "callback_ivideoframeobserver_oncapturevideoframe",
    "name": "OnCaptureVideoFrame",
    "description": "Obtains video data captured by the local device.\n\nYou can obtain the raw video data captured by the local device in this callback and perform pre-processing as needed. After completing the pre-processing, you can directly modify videoFrame in this callback and return true to send the modified video data to the SDK.\n If the video data type you obtain is RGBA, the SDK does not support processing the Alpha channel values.\n When modifying parameters in videoFrame, it is recommended to ensure that the modified parameters match the actual conditions of the video frame in the buffer. Otherwise, unexpected rotation, distortion, or other issues may occur in the local preview or the remote video.",
    "parameters": [
      {
        "sourceType": "Type of video source, which may include: camera, screen, or media player. See VIDEO_SOURCE_TYPE."
      },
      {
        "videoFrame": "Video frame data. See VideoFrame."
      }
    ],
    "returns": "true : Instructs the SDK to receive the video frame. false : Instructs the SDK to discard the video frame.",
    "is_hide": false
  },
  {
    "id": "callback_ivideoframeobserver_onpreencodevideoframe",
    "name": "OnPreEncodeVideoFrame",
    "description": "Obtains local video data before encoding.\n\nAfter successfully registering the video data observer, the SDK triggers this callback when each video frame is captured. You can obtain the video data before encoding in this callback and process it as needed based on your scenario.\nAfter processing, you can pass the processed video data back to the SDK in this callback.\n You need to set the position parameter of RegisterVideoFrameObserver to POSITION_PRE_ENCODER (1 << 2) to use this callback to obtain local video data before encoding.\n The video data obtained here has already been pre-processed, such as cropping, rotation, and beautification.\n When modifying parameters in videoFrame, it is recommended to ensure that the modified parameters match the actual conditions of the video frame in the buffer. Otherwise, unexpected rotation, distortion, or other issues may occur in the local preview or the remote video.",
    "parameters": [
      {
        "sourceType": "Type of video source. See VIDEO_SOURCE_TYPE."
      },
      {
        "videoFrame": "Video frame data. See VideoFrame."
      }
    ],
    "returns": "true : Instructs the SDK to receive the video frame. false : Instructs the SDK to discard the video frame.",
    "is_hide": false
  },
  {
    "id": "callback_ivideoframeobserver_onrendervideoframe",
    "name": "OnRenderVideoFrame",
    "description": "Obtains video data sent by the remote user.\n\nAfter successfully registering the video data observer, the SDK triggers this callback when each video frame is captured. You can obtain the video data sent by the remote user before rendering and process it as needed based on your scenario. Unity only supports sending YUV format video data back to the SDK. Make sure to set mode to INTPTR when calling RegisterVideoFrameObserver to register the raw video frame observer.",
    "parameters": [
      {
        "remoteUid": "Remote user ID who sent the video frame."
      },
      {
        "videoFrame": "Video frame data. See VideoFrame."
      },
      {
        "channelId": "Channel ID."
      }
    ],
    "returns": "true : Instructs the SDK to receive the video frame. false : Instructs the SDK to discard the video frame.",
    "is_hide": false
  },
  {
    "id": "callback_videosurface_ontexturesizemodify",
    "name": "OnTextureSizeModify",
    "description": "Occurs when the width or height of the Texture changes.\n\nThis callback is triggered when the width or height of the Texture changes.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_advancedaudiooptions",
    "name": "AdvancedAudioOptions",
    "description": "Advanced options for audio.",
    "parameters": [
      {
        "audioProcessingChannels": "Number of channels for audio pre-processing. See AUDIO_PROCESSING_CHANNELS."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_advancedconfiginfo",
    "name": "AdvancedConfigInfo",
    "description": "Advanced options for Local Access Point.",
    "parameters": [
      {
        "logUploadServer": "Custom log upload server. By default, the SDK uploads logs to the Agora log server. You can modify the log upload server using this parameter. See LogUploadServerInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_advanceoptions",
    "name": "AdvanceOptions",
    "description": "Advanced options for video encoding.",
    "parameters": [
      {
        "encodingPreference": "Video encoder preference. See ENCODING_PREFERENCE."
      },
      {
        "compressionPreference": "Compression preference for video encoding. See COMPRESSION_PREFERENCE."
      },
      {
        "encodeAlpha": "When the video frame contains Alpha channel data, sets whether to encode and send the Alpha data to the remote end: true : Encode and send Alpha data. false : (Default) Do not encode and send Alpha data."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_agorarhythmplayerconfig",
    "name": "AgoraRhythmPlayerConfig",
    "description": "Virtual metronome configuration.",
    "parameters": [
      {
        "beatsPerMeasure": "Number of beats per measure, range [1,9]. Default is 4, which means 1 strong beat and 3 weak beats per measure."
      },
      {
        "beatsPerMinute": "Tempo (beats per minute), range [60,360]. Default is 60, meaning 60 beats per minute."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audioencodedframeobserverconfig",
    "name": "AudioEncodedFrameObserverConfig",
    "description": "Configuration for encoded audio frame observer.",
    "parameters": [
      {
        "postionType": "Audio encoding content. See AUDIO_ENCODED_FRAME_OBSERVER_POSITION."
      },
      {
        "encodingType": "Audio encoding type. See AUDIO_ENCODING_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audioframe",
    "name": "AudioFrame",
    "description": "Raw audio data.",
    "parameters": [
      {
        "type": "Audio frame type. See AUDIO_FRAME_TYPE."
      },
      {
        "samplesPerChannel": "Number of samples per channel."
      },
      {
        "bytesPerSample": "Number of bytes per sample. For PCM, typically 16 bits, i.e., two bytes."
      },
      {
        "channels": "Number of channels (for stereo, data is interleaved).\n 1: Mono\n 2: Stereo"
      },
      {
        "samplesPerSec": "Number of samples per second per channel."
      },
      {
        "RawBuffer": "Audio data buffer (for stereo, data is interleaved).\nBuffer size buffer = samples Ã— channels Ã— bytesPerSample."
      },
      {
        "renderTimeMs": "Render timestamp of the external audio frame.\nYou can use this timestamp to restore the order of audio frames. In scenarios with video (including those using external video sources), this parameter can be used to achieve audio-video synchronization."
      },
      {
        "avsync_type": "Reserved parameter."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audioparams",
    "name": "AudioParams",
    "description": "Audio data format.\n\nYou can pass an AudioParams object in the following APIs to set the audio data format for the corresponding callback: SetRecordingAudioFrameParameters : Sets the data format for the OnRecordAudioFrame callback. SetPlaybackAudioFrameParameters : Sets the data format for the OnPlaybackAudioFrame callback. SetMixedAudioFrameParameters : Sets the data format for the OnMixedAudioFrame callback. SetEarMonitoringAudioFrameParameters : Sets the data format for the OnEarMonitoringAudioFrame callback.\n The SDK calculates the sampling interval using the samplesPerCall, sampleRate, and channel parameters in AudioParams, and triggers the OnRecordAudioFrame, OnPlaybackAudioFrame, OnMixedAudioFrame, and OnEarMonitoringAudioFrame callbacks based on this interval.\n Sampling interval = samplesPerCall / (sampleRate Ã— channel).\n Make sure the sampling interval is not less than 0.01 (s).",
    "parameters": [
      {
        "sample_rate": "Sampling rate of the data in Hz. Valid values:\n 8000\n 16000 (default)\n 32000\n 44100\n 48000"
      },
      {
        "channels": "Number of audio channels. Valid values:\n 1: Mono (default)\n 2: Stereo"
      },
      {
        "mode": "Usage mode of the data. See RAW_AUDIO_FRAME_OP_MODE_TYPE."
      },
      {
        "samples_per_call": "Number of samples per call. Typically 1024 in scenarios like media stream relay."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audiopcmframe",
    "name": "AudioPcmFrame",
    "description": "Information about external PCM format audio frames.",
    "parameters": [
      {
        "capture_timestamp": "Timestamp of the audio frame (ms)."
      },
      {
        "samples_per_channel_": "Number of samples per channel."
      },
      {
        "sample_rate_hz_": "Audio sampling rate (Hz)."
      },
      {
        "num_channels_": "Number of audio channels."
      },
      {
        "bytes_per_sample": "Number of bytes in the audio data."
      },
      {
        "data_": "Audio frame data."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audiorecordingconfiguration",
    "name": "AudioFileRecordingConfig",
    "description": "Recording configuration.",
    "parameters": [
      {
        "filePath": "The absolute path where the recording file is saved locally. Must include the file name and extension. For example: C:\\music\\audio.aac. Make sure the path you specify exists and is writable."
      },
      {
        "encode": "Specifies whether to encode the audio data: true : Encode the audio data using AAC. false : (Default) Do not encode the audio data. Save the raw recorded audio data directly."
      },
      {
        "sampleRate": "If you set this parameter to 44100 or 48000, to ensure recording quality, we recommend recording a WAV file or an AAC file with quality set to AUDIO_RECORDING_QUALITY_MEDIUM or AUDIO_RECORDING_QUALITY_HIGH. Recording sample rate (Hz).\n 16000\n 32000 (Default)\n 44100\n 48000"
      },
      {
        "fileRecordingType": "Recording content. See AUDIO_FILE_RECORDING_TYPE."
      },
      {
        "quality": "Recording quality. See AUDIO_RECORDING_QUALITY_TYPE. This parameter applies to AAC files only."
      },
      {
        "recordingChannel": "The actual recorded audio channel depends on the captured audio channel:\n If the captured audio is mono and recordingChannel is set to 2, the recorded audio is stereo created by duplicating the mono data, not true stereo.\n If the captured audio is stereo and recordingChannel is set to 1, the recorded audio is mono created by mixing the stereo data. In addition, the integration solution may affect the final recorded audio channel. If you want to record true stereo, please [contact technical support](https://ticket.shengwang.cn/) for assistance. Audio channel for recording. The following values are supported:\n 1: (Default) Mono.\n 2: Stereo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audiospectrumdata",
    "name": "AudioSpectrumData",
    "description": "Audio spectrum data.",
    "parameters": [
      {
        "audioSpectrumData": "Audio spectrum data. Agora divides the audio frequency into 256 frequency bands and reports the energy value of each band through this parameter. The value range of each energy is [-300, 1], in dBFS."
      },
      {
        "dataLength": "The length of the audio spectrum data is 256."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audiotrackconfig",
    "name": "AudioTrackConfig",
    "description": "Configuration options for custom audio tracks.",
    "parameters": [
      {
        "enableLocalPlayback": "Whether to enable local audio playback: true : (Default) Enable local audio playback. false : Disable local audio playback."
      },
      {
        "enableAudioProcessing": "This parameter only takes effect for custom audio capture tracks of type AUDIO_TRACK_DIRECT. Whether to enable the audio processing module: true : Enable the audio processing module, including Echo Cancellation (AEC), Noise Suppression (ANS), and Automatic Gain Control (AGC). false : (Default) Disable the audio processing module."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_audiovolumeinfo",
    "name": "AudioVolumeInfo",
    "description": "User volume information.",
    "parameters": [
      {
        "uid": "User ID.\n In the callback for the local user, uid is 0.\n In the callback for remote users, uid is the ID of the remote user with the highest instantaneous volume (up to 3 users)."
      },
      {
        "volume": "User's volume, ranging from [0,255]. If the user mutes themselves (sets MuteLocalAudioStream to true) but audio capture is still enabled, the volume value indicates the volume of the locally captured signal."
      },
      {
        "vad": "vad cannot report the voice activity status of remote users. For remote users, the value of vad is always 1.\n To use this parameter, set reportVad to true when calling EnableAudioVolumeIndication. Voice activity status of the local user.\n 0: No voice detected locally.\n 1: Voice detected locally."
      },
      {
        "voicePitch": "Voice pitch of the local user (Hz). Value range: [0.0, 4000.0]. voicePitch cannot report the voice pitch of remote users. For remote users, the value of voicePitch is always 0.0."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_beautyoptions",
    "name": "BeautyOptions",
    "description": "Beauty options.",
    "parameters": [
      {
        "lighteningContrastLevel": "Contrast level, usually used with lighteningLevel. The larger the value, the greater the contrast between light and dark. See LIGHTENING_CONTRAST_LEVEL."
      },
      {
        "lighteningLevel": "Whitening level, ranging from [0.0, 1.0], where 0.0 means original brightness. Default is 0.0. The larger the value, the greater the whitening effect."
      },
      {
        "smoothnessLevel": "Smoothing level, ranging from [0.0, 1.0], where 0.0 means original smoothness. Default is 0.0. The larger the value, the greater the smoothing effect."
      },
      {
        "rednessLevel": "Redness level, ranging from [0.0, 1.0], where 0.0 means original redness. Default is 0.0. The larger the value, the more rosy the effect."
      },
      {
        "sharpnessLevel": "Sharpening level, ranging from [0.0, 1.0], where 0.0 means original sharpness. Default is 0.0. The larger the value, the sharper the image."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_cachestatistics",
    "name": "CacheStatistics",
    "description": "Statistics of cached files.",
    "parameters": [
      {
        "fileSize": "Size of the media file being played, in bytes."
      },
      {
        "cacheSize": "Size of the cached data of the media file being played, in bytes."
      },
      {
        "downloadSize": "Size of the downloaded media file being played, in bytes."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_cameracapturerconfiguration",
    "name": "CameraCapturerConfiguration",
    "description": "Camera capture configuration.",
    "parameters": [
      {
        "cameraDirection": "(Optional) Camera direction. See CAMERA_DIRECTION. This parameter applies to Android and iOS only."
      },
      {
        "cameraId": "(Optional) Camera ID. Defaults to the ID of the front-facing camera. You can obtain the camera ID via Android native system APIs. See [Camera.open()](https://developer.android.google.cn/reference/android/hardware/Camera#open(int)) and [CameraManager.getCameraIdList()](https://developer.android.google.cn/reference/android/hardware/camera2/CameraManager?hl=en#getCameraIdList).\n This parameter applies to Android only.\n This parameter and cameraDirection are both used to specify the camera and are mutually exclusive. You can choose either one as needed. The differences are as follows:\n Using cameraDirection is simpler. You only need to specify the direction (front or rear), and the SDK will retrieve and determine the actual camera ID using system APIs.\n Using cameraId allows you to precisely specify a particular camera. On multi-camera devices, cameraDirection may not be able to identify or access all available cameras. In such cases, it is recommended to use cameraId to directly specify the desired camera ID."
      },
      {
        "cameraFocalLengthType": "(Optional) Camera focal length type. See CAMERA_FOCAL_LENGTH_TYPE.\n This parameter applies to Android and iOS only.\n To set the camera focal length type, only cameraDirection is supported. cameraId is not supported.\n Some iOS devices have composite rear cameras, such as dual (wide and ultra-wide) or triple (wide, ultra-wide, and telephoto) lenses. For such composite lenses with ultra-wide capabilities, you can achieve ultra-wide capture using either of the following methods:\n Method 1: Set this parameter to CAMERA_FOCAL_LENGTH_ULTRA_WIDE (2) (ultra-wide lens).\n Method 2: Set this parameter to CAMERA_FOCAL_LENGTH_DEFAULT (0) (standard lens), then call SetCameraZoomFactor to set the camera zoom factor to a value less than 1.0 (minimum 0.5). The difference is that Method 1 provides a fixed ultra-wide view, while Method 2 allows flexible zoom adjustment."
      },
      {
        "format": "(Optional) Video frame format. See VideoFormat."
      },
      {
        "deviceId": "(Optional) ID of the camera. This parameter applies to Windows and macOS only."
      },
      {
        "followEncodeDimensionRatio": "(Optional) Whether to follow the video aspect ratio set in SetVideoEncoderConfiguration : true : (Default) Follow. The SDK crops the captured video to match the configured aspect ratio, and this affects local preview, OnCaptureVideoFrame, and OnPreEncodeVideoFrame. false : Do not follow. The SDK does not change the aspect ratio of the captured video frames."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_channelmediainfo",
    "name": "ChannelMediaInfo",
    "description": "Channel media information.",
    "parameters": [
      {
        "channelName": "Channel name."
      },
      {
        "token": "Token used to join the channel."
      },
      {
        "uid": "User ID."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_channelmediaoptions",
    "name": "ChannelMediaOptions",
    "description": "Channel media configuration options.\n\nRtcConnection publishMicrophoneTrack publishCustomAudioTrack publishMediaPlayerAudioTrack true publishCameraTrack publishScreenCaptureVideo, publishScreenTrack, publishCustomVideoTrack publishEncodedVideoTrack true It is recommended that you set the member parameter values according to your business scenario. Otherwise, the SDK will assign values to the member parameters automatically.",
    "parameters": [
      {
        "publishCameraTrack": "Sets whether to publish the video captured by the camera: true : Publishes the video captured by the camera. false : Does not publish the video captured by the camera."
      },
      {
        "publishSecondaryCameraTrack": "Sets whether to publish the video captured by the second camera: true : Publishes the video captured by the second camera. false : Does not publish the video captured by the second camera."
      },
      {
        "publishMicrophoneTrack": "Sets whether to publish the audio captured by the microphone: true : Publishes the audio captured by the microphone. false : Does not publish the audio captured by the microphone."
      },
      {
        "publishThirdCameraTrack": "This parameter is only applicable to Android, Windows, and macOS platforms. Sets whether to publish the video captured by the third camera: true : Publishes the video captured by the third camera. false : Does not publish the video captured by the third camera."
      },
      {
        "publishFourthCameraTrack": "This parameter is only applicable to Android, Windows, and macOS platforms. Sets whether to publish the video captured by the fourth camera: true : Publishes the video captured by the fourth camera. false : Does not publish the video captured by the fourth camera."
      },
      {
        "publishScreenTrack": "This parameter is only applicable to Windows and macOS platforms. Sets whether to publish the video captured from the screen: true : Publishes the video captured from the screen. false : Does not publish the video captured from the screen."
      },
      {
        "publishScreenCaptureVideo": "This parameter is only applicable to Android and iOS platforms. Sets whether to publish the video captured from the screen: true : Publishes the video captured from the screen. false : Does not publish the video captured from the screen."
      },
      {
        "publishScreenCaptureAudio": "This parameter is only applicable to Android and iOS platforms. Sets whether to publish the audio captured from the screen: true : Publishes the audio captured from the screen. false : Does not publish the audio captured from the screen."
      },
      {
        "publishSecondaryScreenTrack": "Sets whether to publish the video captured from the second screen: true : Publishes the video captured from the second screen. false : Does not publish the video captured from the second screen."
      },
      {
        "publishThirdScreenTrack": "This parameter is only applicable to Windows and macOS platforms. Sets whether to publish the video captured from the third screen: true : Publishes the video captured from the third screen. false : Does not publish the video captured from the third screen."
      },
      {
        "publishFourthScreenTrack": "This parameter is only applicable to Windows and macOS platforms. Sets whether to publish the video captured from the fourth screen: true : Publishes the video captured from the fourth screen. false : Does not publish the video captured from the fourth screen."
      },
      {
        "publishTranscodedVideoTrack": "Sets whether to publish the local transcoded video: true : Publishes the local transcoded video. false : Does not publish the local transcoded video."
      },
      {
        "publishMixedAudioTrack": "Sets whether to publish the local audio mixing: true : Publishes the local audio mixing. false : Does not publish the local audio mixing."
      },
      {
        "publishLipSyncTrack": "Sets whether to publish the video processed by the voice-driven plugin: true : Publishes the video processed by the voice-driven plugin. false : (default) Does not publish the video processed by the voice-driven plugin."
      },
      {
        "publishCustomAudioTrack": "Sets whether to publish the custom captured audio: true : Publishes the custom captured audio. false : Does not publish the custom captured audio."
      },
      {
        "publishCustomAudioTrackId": "ID of the custom audio track to be published. The default value is 0. You can get the custom audio track ID through the CreateCustomAudioTrack method."
      },
      {
        "publishCustomVideoTrack": "Sets whether to publish the custom captured video: true : Publishes the custom captured video. false : Does not publish the custom captured video."
      },
      {
        "publishEncodedVideoTrack": "Sets whether to publish the encoded video: true : Publishes the encoded video. false : Does not publish the encoded video."
      },
      {
        "publishMediaPlayerAudioTrack": "Sets whether to publish the audio from the media player: true : Publishes the audio from the media player. false : Does not publish the audio from the media player."
      },
      {
        "publishMediaPlayerVideoTrack": "Sets whether to publish the video from the media player: true : Publishes the video from the media player. false : Does not publish the video from the media player."
      },
      {
        "autoSubscribeAudio": "Sets whether to automatically subscribe to all audio streams: true : Automatically subscribes to all audio streams. false : Does not automatically subscribe to any audio stream."
      },
      {
        "autoSubscribeVideo": "Sets whether to automatically subscribe to all video streams: true : Automatically subscribes to all video streams. false : Does not automatically subscribe to any video stream."
      },
      {
        "enableAudioRecordingOrPlayout": "If you need to publish the audio stream captured by the microphone, make sure this parameter is set to true. Sets whether to enable audio recording or playback: true : Enables audio recording or playback. false : Disables audio recording or playback."
      },
      {
        "publishMediaPlayerId": "ID of the media player to be published. The default value is 0."
      },
      {
        "clientRoleType": "User role. See CLIENT_ROLE_TYPE. Users with the audience role cannot publish audio or video streams in the channel. When publishing streams in a live broadcast scenario, make sure the user role is set to broadcaster."
      },
      {
        "audienceLatencyLevel": "Audience latency level. See AUDIENCE_LATENCY_LEVEL_TYPE."
      },
      {
        "defaultVideoStreamType": "Default video stream type to subscribe to: VIDEO_STREAM_TYPE."
      },
      {
        "channelProfile": "Channel usage scenario. See CHANNEL_PROFILE_TYPE."
      },
      {
        "audioDelayMs": "Delay (in milliseconds) for sending audio frames. You can use this parameter to set the delay for sending audio frames to ensure audio-video synchronization.\nTo disable the delay, set this parameter to 0."
      },
      {
        "token": "(Optional) A dynamic key generated on the server for authentication. See [Use Token for Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication).\n This parameter takes effect only when calling UpdateChannelMediaOptions or UpdateChannelMediaOptionsEx.\n Make sure the App ID, channel name, and user name used to generate the token are the same as those used in the Initialize method to initialize the engine, and the channel name and user name used in JoinChannel [2/2] or JoinChannelEx to join the channel."
      },
      {
        "publishRhythmPlayerTrack": "Sets whether to publish the virtual metronome sound to remote users: true : Publishes. Both local and remote users can hear the metronome. false : Does not publish. Only the local user can hear the metronome."
      },
      {
        "isInteractiveAudience": "This parameter is used to implement cross-room co-hosting scenarios. The co-host needs to call the JoinChannelEx method to join the other live room as an audience and set isInteractiveAudience to true.\n This parameter takes effect only when the user role is CLIENT_ROLE_AUDIENCE. Whether to enable interactive audience mode: true : Enables interactive audience mode. After successfully enabling, the local user, as an interactive audience, receives low-latency and smooth video from remote users. false : Disables interactive audience mode. The local user, as a regular audience, receives remote user video with default settings."
      },
      {
        "customVideoTrackId": "Video track ID returned by the CreateCustomVideoTrack method. The default value is 0."
      },
      {
        "isAudioFilterable": "To enable this feature, please [contact sales](https://www.shengwang.cn/contact-sales/). Sets whether the current audio stream participates in stream selection based on volume level algorithm. true : Participates in volume-based stream selection. If volume-based stream selection is not enabled, this parameter has no effect. false : Does not participate in volume-based stream selection."
      },
      {
        "enableMultipath": "Permissions and system requirements:\n Android: Android 7.0 or later (API level 24 or above), requires ACCESS_NETWORK_STATE and CHANGE_NETWORK_STATE permissions.\n iOS: iOS 12.0 or later.\n macOS: 10.14 or later.\n Windows: Windows Vista or later. Whether to enable multipath transmission: true : Enables multipath transmission. false : Disables multipath transmission."
      },
      {
        "uplinkMultipathMode": "Uplink transmission mode. See MultipathMode. When using this parameter, make sure enableMultipath is set to true."
      },
      {
        "downlinkMultipathMode": "Downlink transmission mode. See MultipathMode. When using this parameter, make sure enableMultipath is set to true."
      },
      {
        "preferMultipathType": "Preferred transmission path type. See MultipathType. When using this parameter, make sure enableMultipath is set to true."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_channelmediarelayconfiguration",
    "name": "ChannelMediaRelayConfiguration",
    "description": "Configuration information for media stream relay across channels.",
    "parameters": [
      {
        "srcInfo": "Source channel information ChannelMediaInfo, includes the following members: channelName : Name of the source channel. Default is NULL, which means the SDK fills in the current channel name. token : The token used to join the source channel. It is generated based on the channelName and uid you set in srcInfo.\n If App Certificate is not enabled, you can set this parameter to the default value NULL, which means the SDK fills in the App ID.\n If App Certificate is enabled, you must provide a token generated using channelName and uid, and the uid must be 0. uid : UID identifying the media stream being relayed in the source channel. Default is 0. Do not modify."
      },
      {
        "destInfos": "Because the expiration of the token in any target channel will cause all cross-channel streaming to stop, it is recommended that you set the same expiration duration for the tokens in all target channels. Target channel information ChannelMediaInfo, includes the following members: channelName : Name of the target channel. token : The token used to join the target channel. It is generated based on the channelName and uid you set in destInfos.\n If App Certificate is not enabled, you can set this parameter to the default value NULL, which means the SDK fills in the App ID.\n If App Certificate is enabled, you must provide a token generated using channelName and uid. uid : UID identifying the media stream being relayed in the target channel. The value range is [0, 2^32 - 1]. Make sure it is different from all UIDs in the target channel. Default is 0, which means the SDK assigns a UID randomly."
      },
      {
        "destCount": "Number of target channels. Default is 0. Value range is [0,6]. This parameter should match the number of ChannelMediaInfo objects you define in destInfos."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_clientroleoptions",
    "name": "ClientRoleOptions",
    "description": "User role property settings.",
    "parameters": [
      {
        "audienceLatencyLevel": "Latency level for audience. See AUDIENCE_LATENCY_LEVEL_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_codeccapinfo",
    "name": "CodecCapInfo",
    "description": "Information about codec capabilities supported by the SDK.",
    "parameters": [
      {
        "codecType": "Video codec type. See VIDEO_CODEC_TYPE."
      },
      {
        "codecCapMask": "Bit mask of codec types supported by the SDK. See CODEC_CAP_MASK."
      },
      {
        "codecLevels": "Codec capability levels supported by the SDK. See CodecCapLevels."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_codeccaplevels",
    "name": "CodecCapLevels",
    "description": "Codec capability levels.",
    "parameters": [
      {
        "hwDecodingLevel": "Hardware decoding capability level, indicating the device's ability to decode videos of different qualities using hardware. See VIDEO_CODEC_CAPABILITY_LEVEL."
      },
      {
        "swDecodingLevel": "Software decoding capability level, indicating the device's ability to decode videos of different qualities using software. See VIDEO_CODEC_CAPABILITY_LEVEL."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_colorenhanceoptions",
    "name": "ColorEnhanceOptions",
    "description": "Color enhancement options.",
    "parameters": [
      {
        "strengthLevel": "Degree of color enhancement. Value range is [0.0,1.0]. 0.0 means no color enhancement is applied to the video. The higher the value, the stronger the enhancement. Default is 0.5."
      },
      {
        "skinProtectLevel": "Degree of skin tone protection. Value range is [0.0,1.0]. 0.0 means no skin tone protection. The higher the value, the greater the protection. Default is 1.0.\n When the color enhancement level is high, facial skin tones may appear distorted, so you need to set the skin protection level.\n A higher skin protection level may slightly reduce the color enhancement effect. Therefore, to achieve the best color enhancement result, it is recommended that you dynamically adjust strengthLevel and skinProtectLevel to achieve the optimal effect."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_contentinspectconfig",
    "name": "ContentInspectConfig",
    "description": "Local screenshot upload configuration.",
    "parameters": [
      {
        "extraInfo": "Additional information, with a maximum length of 1024 bytes.\nThe SDK uploads the additional information along with the screenshot to the Agora server. After the screenshot is completed, the Agora server sends the additional information to your server along with the callback notification."
      },
      {
        "serverConfig": "(Optional) Cloud Marketplace video moderation related server configuration. This parameter takes effect only when the type in ContentInspectModule is set to CONTENT_INSPECT_IMAGE_MODERATION. To use this feature, [contact technical support](https://ticket.shengwang.cn/)."
      },
      {
        "modules": "Functional modules. See ContentInspectModule.\nSupports up to 32 ContentInspectModule instances. The value range for MAX_CONTENT_INSPECT_MODULE_COUNT is an integer between [1, 32]. Only one instance can be configured for each functional module. Currently, only screenshot upload is supported."
      },
      {
        "moduleCount": "Number of functional modules, i.e., the number of configured ContentInspectModule instances. Must match the number of instances configured in modules. Maximum value is 32."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_contentinspectmodule",
    "name": "ContentInspectModule",
    "description": "The ContentInspectModule struct is used to configure the frequency of local screenshot uploads.",
    "parameters": [
      {
        "type": "Type of functional module. See CONTENT_INSPECT_TYPE."
      },
      {
        "interval": "Interval for local screenshot upload, in seconds. The value must be greater than 0. Default is 0, which means no screenshot upload. Recommended value is 10 seconds, but you can adjust it based on your business needs."
      },
      {
        "position": "Position of the video observer. See VIDEO_MODULE_POSITION."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_datastreamconfig",
    "name": "DataStreamConfig",
    "description": "Data stream settings.\n\nThe table below shows the SDK behavior for different parameter settings: syncWithAudio ordered\nSDK Behavior false false\nThe SDK immediately triggers the OnStreamMessage callback upon receiving the data packet. true false\nIf the data packet delay is within the audio delay range, the SDK triggers the OnStreamMessage callback synchronized with the audio packet during playback. If the delay exceeds the audio delay, the SDK triggers the callback immediately upon receiving the data packet; this may cause desynchronization between audio and data packets. false true\nIf the data packet delay is within 5 seconds, the SDK corrects the out-of-order issue. If the delay exceeds 5 seconds, the SDK discards the data packet. true true\nIf the data packet delay is within the audio delay range, the SDK corrects the out-of-order issue. If the delay exceeds the audio delay, the SDK discards the data packet.",
    "parameters": [
      {
        "syncWithAudio": "Whether to synchronize with the locally sent audio stream. true : The data stream is synchronized with the audio stream. This setting is suitable for special scenarios such as lyrics synchronization. false : The data stream is not synchronized with the audio stream. This setting is suitable for scenarios where data packets need to reach the receiver immediately. When synchronization is enabled, if the data packet delay is within the audio delay range, the SDK triggers the OnStreamMessage callback synchronized with the audio packet during playback."
      },
      {
        "ordered": "Whether to ensure that received data is in the same order as sent. true : The SDK outputs data packets in the same order as sent by the sender. false : The SDK does not guarantee the order of data packets. When data packets need to reach the receiver immediately, this parameter should not be set to true."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_deviceinfo",
    "name": "DeviceInfoMobile",
    "description": "Audio device information.\n\nThis class is for Android only.",
    "parameters": [
      {
        "isLowLatencyAudioSupported": "Whether ultra-low latency audio capture and playback is supported: true : Supported false : Not supported"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_directcdnstreamingmediaoptions",
    "name": "DirectCdnStreamingMediaOptions",
    "description": "Media options for the host.\n\nDeprecated Deprecated since v4.6.2.",
    "parameters": [
      {
        "publishCameraTrack": "Sets whether to publish the video captured by the camera. true : Publish camera-captured video. false : (Default) Do not publish camera-captured video."
      },
      {
        "publishMicrophoneTrack": "Sets whether to publish the audio captured by the microphone. true : Publish microphone-captured audio. false : (Default) Do not publish microphone-captured audio."
      },
      {
        "publishCustomAudioTrack": "Sets whether to publish custom-captured audio. true : Publish custom-captured audio. false : (Default) Do not publish custom-captured audio."
      },
      {
        "publishCustomVideoTrack": "Sets whether to publish custom-captured video. true : Publish custom-captured video. false : (Default) Do not publish custom-captured video."
      },
      {
        "customVideoTrackId": "The video track ID returned by the CreateCustomVideoTrack method. Default is 0."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_directcdnstreamingstats",
    "name": "DirectCdnStreamingStats",
    "description": "Current CDN streaming statistics.\n\nDeprecated Deprecated since v4.6.2.",
    "parameters": [
      {
        "videoWidth": "Video width (px)."
      },
      {
        "videoHeight": "Video height (px)."
      },
      {
        "fps": "Current video frame rate (fps)."
      },
      {
        "videoBitrate": "Current video bitrate (bps)."
      },
      {
        "audioBitrate": "Current audio bitrate (bps)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_echotestconfiguration",
    "name": "EchoTestConfiguration",
    "description": "Configuration for audio and video loopback test.",
    "parameters": [
      {
        "view": "The view used to render the local user's video. This parameter applies only to scenarios where video device testing is needed. Make sure enableVideo is set to true."
      },
      {
        "enableAudio": "Whether to enable audio device: true : (default) Enables the audio device. Set to true to test audio devices. false : Disables the audio device."
      },
      {
        "enableVideo": "Whether to enable video device. Video device detection is not supported yet. Set this parameter to false."
      },
      {
        "token": "The token used to ensure the security of the audio and video loopback test. If you have not enabled the App Certificate in the console, you do not need to provide a value for this parameter. If you have enabled the App Certificate in the console, you must provide a token for this parameter, and the uid used when generating the token must be 0xFFFFFFFF. The channel name used must uniquely identify each audio and video loopback test. For how to generate tokens on the server, see [Use Token Authentication](https://doc.shengwang.cn/doc/rtc/unity/basic-features/token-authentication)."
      },
      {
        "channelId": "The channel name that identifies each audio and video loopback test. To ensure the loopback test functions correctly, the channel names passed in by different terminal users under the same project (App ID) on different devices must be unique."
      },
      {
        "intervalInSeconds": "Sets the interval or delay for returning the audio and video loopback test results. The value range is [2,10] seconds, with a default of 2 seconds.\n For audio loopback tests, the results are returned based on the interval you set.\n For video loopback tests, the video will display briefly, then the delay gradually increases until it reaches the set delay."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_encodedaudioframeinfo",
    "name": "EncodedAudioFrameInfo",
    "description": "Information about encoded audio.",
    "parameters": [
      {
        "codec": "Audio codec specification: AUDIO_CODEC_TYPE."
      },
      {
        "sampleRateHz": "Audio sample rate (Hz)."
      },
      {
        "samplesPerChannel": "Number of audio samples per channel."
      },
      {
        "numberOfChannels": "Number of channels."
      },
      {
        "advancedSettings": "This feature is not supported yet."
      },
      {
        "captureTimeMs": "Unix timestamp (ms) when the external encoded video frame was captured."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_encodedvideoframeinfo",
    "name": "EncodedVideoFrameInfo",
    "description": "Information about external encoded video frames.",
    "parameters": [
      {
        "codecType": "Video codec type. See VIDEO_CODEC_TYPE. Default is VIDEO_CODEC_H264 (2)."
      },
      {
        "width": "Width of the video frame (px)."
      },
      {
        "height": "Height of the video frame (px)."
      },
      {
        "framesPerSecond": "Frames per second of the video.\nWhen this parameter is not 0, you can use it to calculate the Unix timestamp of the external encoded video frame."
      },
      {
        "frameType": "Type of the video frame. See VIDEO_FRAME_TYPE."
      },
      {
        "rotation": "Rotation information of the video frame. See VIDEO_ORIENTATION."
      },
      {
        "trackId": "Reserved parameter."
      },
      {
        "captureTimeMs": "Unix timestamp (ms) when the external encoded video frame was captured."
      },
      {
        "streamType": "Type of video stream. See VIDEO_STREAM_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_encryptionconfig",
    "name": "EncryptionConfig",
    "description": "Configure built-in encryption mode and key.",
    "parameters": [
      {
        "encryptionMode": "Built-in encryption mode. See ENCRYPTION_MODE. It is recommended to use AES_128_GCM2 or AES_256_GCM2 modes, which support salt and offer higher security."
      },
      {
        "encryptionKey": "Built-in encryption key, string type, no length limit. It is recommended to use a 32-byte key. If this parameter is not specified or is set to NULL, built-in encryption cannot be enabled and the SDK returns error code -2."
      },
      {
        "encryptionKdfSalt": "Salt, 32 bytes in length. It is recommended to generate the salt on the server using OpenSSL. This parameter takes effect only when using AES_128_GCM2 or AES_256_GCM2 encryption modes. In this case, ensure the value of this parameter is not all 0."
      },
      {
        "datastreamEncryptionEnabled": "Whether to enable data stream encryption: true : Enable data stream encryption. false : (default) Disable data stream encryption."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_extensioncontext",
    "name": "ExtensionContext",
    "description": "Plugin context information.",
    "parameters": [
      {
        "isValid": "Whether the uid reported in ExtensionContext is valid: true : uid is valid. false : uid is invalid."
      },
      {
        "uid": "User ID. 0 represents the local user; values greater than 0 represent remote users."
      },
      {
        "providerName": "Name of the provider offering the plugin."
      },
      {
        "extensionName": "Name of the plugin."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_externalvideoframe",
    "name": "ExternalVideoFrame",
    "description": "External video frame.",
    "parameters": [
      {
        "type": "Video type. See VIDEO_BUFFER_TYPE."
      },
      {
        "format": "Pixel format. See VIDEO_PIXEL_FORMAT."
      },
      {
        "buffer": "Video buffer."
      },
      {
        "stride": "Stride of the input video frame, in pixels (not bytes). For Texture, this refers to the width of the Texture."
      },
      {
        "height": "Height of the input video frame."
      },
      {
        "eglContext": "(Texture only)\n When using the Khronos-defined OpenGL interface (javax.microedition.khronos.egl.*), set eglContext to this field.\n When using the Android-defined OpenGL interface (android.opengl.*), set eglContext to this field."
      },
      {
        "eglType": "(Texture only) Type of the Texture ID for the video frame."
      },
      {
        "textureId": "(Texture only) A 4x4 transformation matrix input, typically an identity matrix."
      },
      {
        "metadataBuffer": "(Texture only) Metadata buffer. Default is NULL."
      },
      {
        "metadataSize": "(Texture only) Size of the metadata. Default is 0."
      },
      {
        "d3d11Texture2d": "(Windows Texture only) A pointer to an ID3D11Texture2D object used by the video frame."
      },
      {
        "alphaBuffer": "Alpha channel data output by portrait segmentation algorithm. The data matches the video frame size, with pixel values ranging from [0,255], where 0 represents background and 255 represents foreground (portrait).\nYou can use this parameter to render the video background with various effects, such as transparency, solid color, image, or video. In custom video rendering scenarios, ensure that both the video frame and alphaBuffer are Full Range. Other types may cause abnormal Alpha rendering."
      },
      {
        "fillAlphaBuffer": "For BGRA or RGBA video data, you can set Alpha channel data using either of the following:\n Automatically fill by setting this parameter to true.\n Set via the alphaBuffer parameter. (BGRA or RGBA only) Whether to extract the Alpha channel data from the video frame and automatically fill it into alphaBuffer : true : Extract and fill Alpha channel data. false : (default) Do not extract or fill Alpha channel data."
      },
      {
        "alphaStitchMode": "When the video frame contains Alpha channel data, sets the relative position of alphaBuffer and the video frame. See ALPHA_STITCH_MODE."
      },
      {
        "textureSliceIndex": "(Windows Texture only) Index of the ID3D11Texture2D texture object used by the video frame in the ID3D11Texture2D array."
      },
      {
        "cropLeft": "(Raw video only)"
      },
      {
        "cropTop": "(Raw video only)"
      },
      {
        "cropRight": "(Raw video only)"
      },
      {
        "cropBottom": "(Raw video only)"
      },
      {
        "rotation": "Raw data field. Specifies clockwise rotation of the input video group. Options: 0, 90, 180, 270. Default is 0."
      },
      {
        "timestamp": "Timestamp of the input video frame in milliseconds. Incorrect timestamps may cause frame drops or AV sync issues."
      },
      {
        "colorSpace": "Color space property of the video frame. By default, Full Range and BT.709 configurations are applied. You can customize this based on custom capture or rendering needs. See [VideoColorSpace](https://developer.mozilla.org/en-US/docs/Web/API/VideoColorSpace)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_faceshapeareaoptions",
    "name": "FaceShapeAreaOptions",
    "description": "Filter effect options.",
    "parameters": [
      {
        "shapeArea": "Facial area. See FACE_SHAPE_AREA."
      },
      {
        "shapeIntensity": "Intensity of the modification. Definitions vary by area (including direction, range, preset values, etc.). See FACE_SHAPE_AREA."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_faceshapebeautyoptions",
    "name": "FaceShapeBeautyOptions",
    "description": "Beauty style options.",
    "parameters": [
      {
        "shapeStyle": "Beauty style. See FACE_SHAPE_BEAUTY_STYLE."
      },
      {
        "styleIntensity": "Beauty style intensity. Range: [0,100]. Default is 0.0, meaning no effect. Higher values result in more noticeable changes."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_filtereffectoptions",
    "name": "FilterEffectOptions",
    "description": "Filter effect options.",
    "parameters": [
      {
        "path": "The local absolute path to the 3D LUT (Lookup Table) file used to implement custom filter effects. The referenced.cube file must strictly follow the Cube LUT specification; otherwise, the filter effect will not work. Below is an example of a.cube file: LUT_3D_SIZE 32\n0.0039215689 0 0.0039215682\n0.0086021447 0.0037950677 0\n...\n0.0728652592 0.0039215689 0\n The first line of the LUT file must contain the identifier LUT_3D_SIZE, which indicates the size of the 3D lookup table. Currently, only a LUT size of 32 is supported.\n The SDK provides a built-in built_in_whiten_filter.cube file. Passing the absolute path of this file applies a whitening filter effect."
      },
      {
        "strength": "The strength of the filter effect, ranging from [0.0, 1.0], where 0.0 means no filter effect. The default value is 0.5. A higher value results in a stronger filter effect."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_focallengthinfo",
    "name": "FocalLengthInfo",
    "description": "Focal length information supported by the camera, including camera direction and focal length type.\n\n(Android and iOS only)",
    "parameters": [
      {
        "cameraDirection": "Camera direction. See CAMERA_DIRECTION."
      },
      {
        "focalLengthType": "Focal length type. See CAMERA_FOCAL_LENGTH_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_iagoraparameter",
    "name": "IAgoraParameter",
    "description": "Interface class of the RTC SDK that provides JSON configuration information for the SDK.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_iaudiodevicemanager",
    "name": "IAudioDeviceManager",
    "description": "Audio device management methods.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_iaudioencodedframeobserver",
    "name": "IAudioEncodedFrameObserver",
    "description": "Observer for encoded audio.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_iaudioframeobserver",
    "name": "IAudioFrameObserver",
    "description": "Audio frame observer.\n\nYou can call RegisterAudioFrameObserver to register or unregister the IAudioFrameObserver audio observer.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_iaudioframeobserverbase",
    "name": "IAudioFrameObserverBase",
    "description": "Audio observer.\n\nYou can call RegisterAudioFrameObserver to register or unregister the IAudioFrameObserverBase audio observer.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_iaudiopcmframesink",
    "name": "IAudioPcmFrameSink",
    "description": "This class is used to obtain raw PCM audio data.\n\nYou can inherit this class and implement the OnFrame callback to get PCM audio data.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_iaudiospectrumobserver",
    "name": "IAudioSpectrumObserver",
    "description": "Audio spectrum observer.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_ibasespatialaudioengine",
    "name": "IBaseSpatialAudioEngine",
    "description": "This class contains some APIs from the ILocalSpatialAudioEngine class.\n\nThe ILocalSpatialAudioEngine class inherits from IBaseSpatialAudioEngine.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_idirectcdnstreamingeventhandler",
    "name": "IDirectCdnStreamingEventHandler",
    "description": "The IDirectCdnStreamingEventHandler interface class is used by the SDK to send CDN streaming event notifications to the App. The App receives the SDK's event notifications by inheriting methods of this interface class.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_ifaceinfoobserver",
    "name": "IFaceInfoObserver",
    "description": "Face information observer.\n\nYou can call RegisterFaceInfoObserver to register the IFaceInfoObserver observer.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_ilocalspatialaudioengine",
    "name": "ILocalSpatialAudioEngine",
    "description": "This class implements spatial audio by calculating user coordinates through the SDK.\n\nBefore calling other APIs in this class, you need to call the Initialize method to initialize the class.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imagetrackoptions",
    "name": "ImageTrackOptions",
    "description": "Settings options for placeholder images.",
    "parameters": [
      {
        "imageUrl": "The URL of the placeholder image. Currently supports JPEG, JPG, PNG, and GIF formats. You can add a placeholder image from a local absolute or relative path. On Android, adding placeholder images from /assets/ is not supported."
      },
      {
        "fps": "Video frame rate, ranging from [1, 30]. The default value is 1."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imediaengine",
    "name": "IMediaEngine",
    "description": "IMediaEngine class.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imediaplayer",
    "name": "IMediaPlayer",
    "description": "Class that provides media player functionality and supports multiple instances.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imediaplayeraudioframeobserver",
    "name": "IMediaPlayerAudioFrameObserver",
    "description": "Audio data observer for the media player.\n\nYou can call RegisterAudioFrameObserver [2/2] to register or unregister the IMediaPlayerAudioFrameObserver observer.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imediaplayercachemanager",
    "name": "IMediaPlayerCacheManager",
    "description": "This class provides methods to manage cached media files in the media player.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imediaplayercustomdataprovider",
    "name": "IMediaPlayerCustomDataProvider",
    "description": "Provides callbacks for opening custom media resource files.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imediaplayersourceobserver",
    "name": "IMediaPlayerSourceObserver",
    "description": "Provides callbacks for the media player.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_imetadataobserver",
    "name": "IMetadataObserver",
    "description": "Metadata observer.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_irtcengine",
    "name": "IRtcEngine",
    "description": "The base interface class of the RTC SDK that implements the core functions of real-time audio and video.\n\nIRtcEngine provides the main methods for the App to call.\nYou must call CreateAgoraRtcEngine to create an IRtcEngine object before calling other APIs.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_irtcengineeventhandler",
    "name": "IRtcEngineEventHandler",
    "description": "The IRtcEngineEventHandler interface class is used by the SDK to send event notifications to the App. The App receives the SDK's event notifications by inheriting methods of this interface class.\n\nAll methods in this interface class have default (empty) implementations. The App can choose to inherit only the events it cares about.\n In callback methods, the App should not perform time-consuming operations or call APIs that might block (such as sendMessage), otherwise it may affect the SDK's operation.\n The SDK no longer catches exceptions in the code logic implemented by the developer in the IRtcEngineEventHandler class callbacks. You need to handle such exceptions yourself; otherwise, they may cause the App to crash when they occur.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_irtcengineex",
    "name": "IRtcEngineEx",
    "description": "Interface class that provides multi-channel methods.\n\nInherits from IRtcEngine.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_ivideodevicemanager",
    "name": "IVideoDeviceManager",
    "description": "Video device management methods.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_ivideoeffectobject",
    "name": "IVideoEffectObject",
    "description": "Used to manage and configure video effects, such as beauty filters, makeup styles, and filters.\n\nSince Available since v4.6.2.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_ivideoencodedframeobserver",
    "name": "IVideoEncodedFrameObserver",
    "description": "A class used to receive encoded video frames.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_ivideoframeobserver",
    "name": "IVideoFrameObserver",
    "description": "Video frame observer.\n\nYou can call RegisterVideoFrameObserver to register or unregister the IVideoFrameObserver video observer.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_lastmileprobeconfig",
    "name": "LastmileProbeConfig",
    "description": "Last mile network probe configuration.",
    "parameters": [
      {
        "probeUplink": "Whether to probe the uplink network. Some users, such as audience members in a live broadcast channel, do not need network probing: true : Probe the uplink network. false : Do not probe the uplink network."
      },
      {
        "probeDownlink": "Whether to probe the downlink network: true : Probe the downlink network. false : Do not probe the downlink network."
      },
      {
        "expectedUplinkBitrate": "The expected maximum uplink bitrate in bps, ranging from [100000, 5000000]. It is recommended to refer to the bitrate values in SetVideoEncoderConfiguration when setting this parameter."
      },
      {
        "expectedDownlinkBitrate": "The expected maximum downlink bitrate in bps, ranging from [100000, 5000000]."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_lastmileprobeonewayresult",
    "name": "LastmileProbeOneWayResult",
    "description": "One-way (uplink or downlink) last mile network quality probe result.",
    "parameters": [
      {
        "packetLossRate": "Packet loss rate."
      },
      {
        "jitter": "Network jitter (ms)."
      },
      {
        "availableBandwidth": "Estimated available network bandwidth (bps)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_lastmileproberesult",
    "name": "LastmileProbeResult",
    "description": "Uplink and downlink last mile network quality probe result.",
    "parameters": [
      {
        "state": "The state of the last mile probe result. See: LASTMILE_PROBE_RESULT_STATE."
      },
      {
        "uplinkReport": "Uplink network quality report. See LastmileProbeOneWayResult."
      },
      {
        "downlinkReport": "Downlink network quality report. See LastmileProbeOneWayResult."
      },
      {
        "rtt": "Round-trip time (ms)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_leavechanneloptions",
    "name": "LeaveChannelOptions",
    "description": "Options for leaving a channel.",
    "parameters": [
      {
        "stopAudioMixing": "Whether to stop playing music files and audio mixing when leaving the channel: true : (Default) Stop playing music files and audio mixing. false : Do not stop playing music files and audio mixing."
      },
      {
        "stopAllEffect": "Whether to stop playing sound effects when leaving the channel: true : (Default) Stop playing sound effects. false : Do not stop playing sound effects."
      },
      {
        "stopMicrophoneRecording": "Whether to stop microphone capture when leaving the channel: true : (Default) Stop microphone capture. false : Do not stop microphone capture."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_livestreamadvancedfeature",
    "name": "LiveStreamAdvancedFeature",
    "description": "Advanced configuration for transcoding live streaming.\n\nTo use advanced features for transcoding live streaming, please [contact sales](https://www.shengwang.cn/contact-sales/).",
    "parameters": [
      {
        "featureName": "The name of the advanced transcoding live streaming feature, including LBHQ (low-bitrate high-quality video) and VEO (optimized video encoder)."
      },
      {
        "opened": "Whether to enable the advanced transcoding live streaming feature: true : Enables the advanced transcoding live streaming feature. false : (Default) Disables the advanced transcoding live streaming feature."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_livetranscoding",
    "name": "LiveTranscoding",
    "description": "Transcoding properties for RTMP streaming.",
    "parameters": [
      {
        "width": "The total width of the video stream, in pixels. Default is 360.\n For video streams, the value range is [64,1920]. If the value is less than 64, the Agora server adjusts it to 64; if greater than 1920, it adjusts to 1920.\n For audio-only streams, set both width and height to 0."
      },
      {
        "height": "The total height of the video stream, in pixels. Default is 640.\n For video streams, the value range is [64,1080]. If the value is less than 64, the Agora server adjusts it to 64; if greater than 1080, it adjusts to 1080.\n For audio-only streams, set both width and height to 0."
      },
      {
        "videoBitrate": "Video encoding bitrate in Kbps. See BITRATE. You don't need to set this parameter; keep the default STANDARD_BITRATE. The SDK automatically matches the optimal bitrate based on your video resolution and frame rate. For more on resolution and frame rate, see [Video Profile](https://doc.shengwang.cn/doc/rtc/unity/basic-features/video-profile#%E8%A7%86%E9%A2%91%E5%B1%9E%E6%80%A7%E5%8F%82%E8%80%83)."
      },
      {
        "videoFramerate": "Frame rate of the output video for RTMP streaming. Range is (0,30], in fps. Default is 15 fps. The Agora server adjusts any frame rate above 30 fps to 30 fps."
      },
      {
        "lowLatency": "Deprecated. Not recommended for use. Low-latency mode true : Low latency, lower video quality. false : (Default) Higher latency, better video quality."
      },
      {
        "videoGop": "GOP (Group of Pictures) of the output video for RTMP streaming, in frames. Default is 30."
      },
      {
        "videoCodecProfile": "Codec profile of the output video for RTMP streaming. Can be set to 66, 77, or 100. See VIDEO_CODEC_PROFILE_TYPE. If you set this to another value, the Agora server resets it to the default."
      },
      {
        "videoCodecType": "Codec type of the output video for RTMP streaming. See VIDEO_CODEC_TYPE_FOR_STREAM."
      },
      {
        "transcodingUsers": "Manages the users participating in the video mixing for RTMP streaming. Supports up to 17 users. See TranscodingUser."
      },
      {
        "transcodingExtraInfo": "Reserved parameter: Custom information sent to the RTMP client, used to populate SEI frames in H264/H265 video. Max length: 4096 bytes. For more details on SEI, see [SEI Frame Issues](https://doc.shengwang.cn/faq/quality-issues/sei)."
      },
      {
        "backgroundColor": "Background color of the output video for RTMP streaming, represented as a hexadecimal RGB integer without the # symbol. For example, 0xFFB6C1 is light pink. Default is 0x000000 (black)."
      },
      {
        "userCount": "Number of users participating in the video mixing. Default is 0. Range: [0,17]."
      },
      {
        "metadata": "Metadata sent to CDN clients. Deprecated. Not recommended for use."
      },
      {
        "watermark": "Watermark(s) on the live video. PNG format is required. See RtcImage.\nYou can add one watermark or use an array to add multiple. Use this parameter together with watermarkCount."
      },
      {
        "backgroundImage": "Background image(s) on the live video. PNG format is required. See RtcImage.\nYou can add one background image or use an array to add multiple. Use this parameter together with backgroundImageCount."
      },
      {
        "audioSampleRate": "Audio sample rate (Hz) of the output media stream for RTMP streaming. See AUDIO_SAMPLE_RATE_TYPE."
      },
      {
        "audioBitrate": "Bitrate of the output audio for RTMP streaming, in Kbps. Default is 48, maximum is 128."
      },
      {
        "audioChannels": "Number of audio channels in the output audio for RTMP streaming. Default is 1. Valid values are integers in [1,5]. Recommended values are 1 or 2. Values 3, 4, and 5 require special player support:\n 1: (Default) Mono\n 2: Stereo\n 3: Three channels\n 4: Four channels\n 5: Five channels"
      },
      {
        "audioCodecProfile": "Codec profile of the output audio for RTMP streaming. See AUDIO_CODEC_PROFILE_TYPE."
      },
      {
        "watermarkCount": "Number of watermarks on the live video. The total number of watermarks and background images must be between 0 and 10. Use this parameter together with watermark."
      },
      {
        "backgroundImageCount": "Number of background images on the live video. The total number of watermarks and background images must be between 0 and 10. Use this parameter together with backgroundImage."
      },
      {
        "advancedFeatures": "Advanced features for transcoding and streaming. See LiveStreamAdvancedFeature."
      },
      {
        "advancedFeatureCount": "Number of enabled advanced features. Default is 0."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_localaccesspointconfiguration",
    "name": "LocalAccessPointConfiguration",
    "description": "Local Access Point configuration.",
    "parameters": [
      {
        "ipList": "Internal IP address list of the Local Access Point. Either ipList or domainList must be provided."
      },
      {
        "ipListSize": "Number of internal IP addresses of the Local Access Point. This value must match the number of IP addresses you provide."
      },
      {
        "domainList": "Domain name list of the Local Access Point. The SDK resolves the IP addresses of the Local Access Point based on the provided domain names. The domain name resolution timeout is 10 seconds. Either ipList or domainList must be provided. If you specify both IP addresses and domain names, the SDK merges and deduplicates the resolved IP addresses and the specified IP addresses, then randomly connects to one IP to achieve load balancing."
      },
      {
        "domainListSize": "Number of domain names of the Local Access Point. This value must match the number of domain names you provide."
      },
      {
        "verifyDomainName": "Domain name for internal certificate verification. If left empty, the SDK uses the default certificate verification domain name secure-edge.local."
      },
      {
        "mode": "Connection mode. See LOCAL_PROXY_MODE."
      },
      {
        "advancedConfig": "Advanced options for the Local Access Point. See AdvancedConfigInfo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_localaudiomixerconfiguration",
    "name": "LocalAudioMixerConfiguration",
    "description": "Local audio mixing configuration.",
    "parameters": [
      {
        "streamCount": "Number of audio streams to be mixed locally."
      },
      {
        "audioInputStreams": "Audio sources to be mixed locally. See MixedAudioStream."
      },
      {
        "syncWithLocalMic": "Whether the mixed audio stream uses the timestamp of audio frames captured by the local microphone: true : (default) Uses the timestamp of audio frames captured by the local microphone. Set this value if you want all locally captured audio streams to stay synchronized. false : Does not use the timestamp of audio frames captured by the local microphone. The SDK uses the timestamp when the mixed audio frame is constructed."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_localaudiostats",
    "name": "LocalAudioStats",
    "description": "Local audio statistics.",
    "parameters": [
      {
        "numChannels": "Number of audio channels."
      },
      {
        "sentSampleRate": "Sampling rate of the sent local audio, in Hz."
      },
      {
        "sentBitrate": "Average bitrate of the sent local audio, in Kbps."
      },
      {
        "txPacketLossRate": "Packet loss rate (%) from the local end to the Agora edge server before network resilience."
      },
      {
        "internalCodec": "Internal payload type."
      },
      {
        "audioDeviceDelay": "Delay of the audio device module during audio playback or recording (ms)."
      },
      {
        "earMonitorDelay": "Ear monitoring delay (ms), i.e., the delay from microphone input to headphone output."
      },
      {
        "aecEstimatedDelay": "Acoustic Echo Cancellation (AEC) delay (ms), i.e., the delay between the audio played locally and the signal captured again locally as estimated by the AEC module."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_localspatialaudioconfig",
    "name": "LocalSpatialAudioConfig",
    "description": "Configuration for ILocalSpatialAudioEngine.",
    "parameters": [
      {
        "rtcEngine": "IRtcEngine."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_localtranscoderconfiguration",
    "name": "LocalTranscoderConfiguration",
    "description": "Configuration for local video mixing.",
    "parameters": [
      {
        "streamCount": "Number of video streams participating in local video mixing."
      },
      {
        "videoInputStreams": "Video streams participating in local video mixing. See TranscodingVideoStream."
      },
      {
        "videoOutputConfiguration": "Encoding configuration for the mixed video after local mixing. See VideoEncoderConfiguration."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_localvideostats",
    "name": "LocalVideoStats",
    "description": "Statistics of the local video stream.",
    "parameters": [
      {
        "uid": "The ID of the local user."
      },
      {
        "sentBitrate": "Actual sending bitrate (Kbps) Excludes bitrate of retransmitted video due to packet loss."
      },
      {
        "sentFrameRate": "Actual sending frame rate (fps). Excludes frame rate of retransmitted video due to packet loss."
      },
      {
        "captureFrameRate": "Local video capture frame rate (fps)."
      },
      {
        "captureFrameWidth": "Local video capture width (px)."
      },
      {
        "captureFrameHeight": "Local video capture height (px)."
      },
      {
        "regulatedCaptureFrameRate": "Camera capture frame rate (fps) adjusted by the SDK's built-in video capture adapter (regulator). The regulator adjusts the camera capture frame rate based on the video encoding configuration."
      },
      {
        "regulatedCaptureFrameWidth": "Camera capture width (px) adjusted by the SDK's built-in video capture adapter (regulator). The regulator adjusts the camera capture resolution based on the video encoding configuration."
      },
      {
        "regulatedCaptureFrameHeight": "Camera capture height (px) adjusted by the SDK's built-in video capture adapter (regulator). The regulator adjusts the camera capture resolution based on the video encoding configuration."
      },
      {
        "encoderOutputFrameRate": "Output frame rate of the local video encoder, in fps."
      },
      {
        "rendererOutputFrameRate": "Output frame rate of the local video renderer, in fps."
      },
      {
        "targetBitrate": "Target encoding bitrate (Kbps) of the current encoder. This value is estimated by the SDK based on the current network conditions."
      },
      {
        "targetFrameRate": "Target encoding frame rate (fps) of the current encoder."
      },
      {
        "qualityAdaptIndication": "Adaptation status of local video quality (based on target frame rate and target bitrate) during the statistical period. See QUALITY_ADAPT_INDICATION."
      },
      {
        "encodedBitrate": "Video encoding bitrate (Kbps). Excludes bitrate of retransmitted video due to packet loss."
      },
      {
        "encodedFrameHeight": "Video encoding height (px)."
      },
      {
        "encodedFrameWidth": "Video encoding width (px)."
      },
      {
        "encodedFrameCount": "Number of video frames sent, cumulative value."
      },
      {
        "codecType": "Video codec type. See VIDEO_CODEC_TYPE."
      },
      {
        "txPacketLossRate": "Video packet loss rate (%) from the local end to the Agora edge server before network resilience."
      },
      {
        "captureBrightnessLevel": "Brightness level of the locally captured video. See CAPTURE_BRIGHTNESS_LEVEL_TYPE."
      },
      {
        "hwEncoderAccelerating": "Local video encoder acceleration type.\n 0: Uses software encoding, no acceleration.\n 1: Uses hardware encoding for acceleration."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_logconfig",
    "name": "LogConfig",
    "description": "Configuration for SDK log files.",
    "parameters": [
      {
        "filePath": "Full path of the log file. Agora recommends using the default log path. If you need to change the default path, make sure the specified path exists and is writable.\nDefault paths:\n Android: /storage/emulated/0/Android/data/<packagename>/files/agorasdk.log\n iOS: App Sandbox/Library/caches/agorasdk.log\n macOS:\n Sandbox enabled: App Sandbox/Library/Logs/agorasdk.log, e.g., /Users/<username>/Library/Containers/<AppBundleIdentifier>/Data/Library/Logs/agorasdk.log\n Sandbox disabled: ~/Library/Logs/agorasdk.log\n Windows: C:\\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\agorasdk.log"
      },
      {
        "fileSizeInKB": "Size of a single agorasdk.log file in KB. The valid range is [128, 20480], with a default of 2048 KB. If you set fileSizeInKByte to less than 128 KB, the SDK automatically adjusts it to 128 KB; if you set it to more than 20480 KB, the SDK adjusts it to 20480 KB."
      },
      {
        "level": "Log output level of the SDK. See LOG_LEVEL.\nFor example, if you choose WARN level, you will see all log messages at FATAL, ERROR, and WARN levels."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_loguploadserverinfo",
    "name": "LogUploadServerInfo",
    "description": "Configuration information of the log server.",
    "parameters": [
      {
        "serverDomain": "Domain name of the log server."
      },
      {
        "serverPath": "Storage path of logs on the server."
      },
      {
        "serverPort": "Port of the log server."
      },
      {
        "serverHttps": "Whether the log server uses HTTPS: true : Uses HTTPS protocol. false : Uses HTTP protocol."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_lowlightenhanceoptions",
    "name": "LowlightEnhanceOptions",
    "description": "Low-light enhancement options.",
    "parameters": [
      {
        "level": "Low-light enhancement level. See LOW_LIGHT_ENHANCE_LEVEL."
      },
      {
        "mode": "Low-light enhancement mode. See LOW_LIGHT_ENHANCE_MODE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_mediasource",
    "name": "MediaSource",
    "description": "Information and playback settings for the media file to be played.",
    "parameters": [
      {
        "url": "URL of the media resource to be played. If you are opening a regular media resource, assign a value to url; if you are opening a custom media resource, assign a value to provider. Assigning values to both will cause the method call to fail."
      },
      {
        "uri": "URI (Uniform Resource Identifier) of the media file, used to identify the media file."
      },
      {
        "startPos": "Start playback position in milliseconds. Default is 0."
      },
      {
        "autoPlay": "If you disable auto-play, call the Play method after opening the media file to start playback. Whether to enable auto-play after opening the media file: true : (Default) Enable auto-play. false : Disable auto-play."
      },
      {
        "enableCache": "The SDK currently supports caching for on-demand streams, but not for on-demand streams delivered via HLS protocol.\n Before caching, assign a value to uri, otherwise the player will use the media file's url as the cache index.\n When real-time caching is enabled, the player preloads part of the currently playing media file to local storage. The next time you play the file, the player loads data directly from the cache, saving network traffic. Statistics for the cached media file are updated every second after playback starts. See CacheStatistics. Whether to enable real-time caching for this playback: true : Enable real-time caching. false : (Default) Disable real-time caching."
      },
      {
        "enableMultiAudioTrack": "Whether to allow selecting different audio tracks for this playback: true : Allow selecting different audio tracks. false : (Default) Do not allow selecting different audio tracks. If you need to set different audio tracks for local playback and publishing to remote, set this parameter to true and then call the SelectMultiAudioTrack method to configure audio tracks."
      },
      {
        "isAgoraSource": "If the media resource to be opened is a live or on-demand stream delivered via Agora Fusion CDN, assign the stream URL to url and set isAgoraSource to true. Otherwise, there is no need to set isAgoraSource. Whether the media resource is a live or on-demand stream delivered via Agora Fusion CDN: true : The media resource is delivered via Agora Fusion CDN. false : (Default) The media resource is not delivered via Agora Fusion CDN."
      },
      {
        "isLiveSource": "Only when the media resource is a live stream, setting isLiveSource to true can speed up the opening of the media resource. Whether the media resource is a live stream: true : Live stream. false : (Default) Not a live stream. If the media resource is a live stream, it is recommended to set this parameter to true to speed up the opening of the live stream."
      },
      {
        "provider": "Callback for custom media resource files. See IMediaPlayerCustomDataProvider. If you are opening a custom media resource, assign a value to provider only. If you are opening a regular media resource, assign a value to url. Assigning values to both url and provider will cause the method call to fail."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_metadata",
    "name": "Metadata",
    "description": "Media metadata.",
    "parameters": [
      {
        "channelId": "Channel name."
      },
      {
        "uid": "User ID.\n For receiver: ID of the remote user who sent this Metadata.\n For sender: Ignore this."
      },
      {
        "size": "Buffer size of the received or sent Metadata."
      },
      {
        "buffer": "Buffer address of the received Metadata."
      },
      {
        "timeStampMs": "Timestamp when the Metadata is sent, in milliseconds."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_multipathstats",
    "name": "MultipathStats",
    "description": "Used to aggregate statistics of each network path in multipath transmission.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "lanTxBytes": "Total bytes sent via LAN path."
      },
      {
        "lanRxBytes": "Total bytes received via LAN path."
      },
      {
        "wifiTxBytes": "Total bytes sent via Wi-Fi path."
      },
      {
        "wifiRxBytes": "Total bytes received via Wi-Fi path."
      },
      {
        "mobileTxBytes": "Total bytes sent via mobile network path."
      },
      {
        "mobileRxBytes": "Total bytes received via mobile network path."
      },
      {
        "activePathNum": "Number of currently active transmission paths."
      },
      {
        "pathStats": "Array of statistics for each active transmission path. See PathStats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_pathstats",
    "name": "PathStats",
    "description": "Used to obtain statistics of a specific network path.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "type": "Type of network path. See MultipathType."
      },
      {
        "txKBitRate": "Transmission bitrate of the path, in Kbps."
      },
      {
        "rxKBitRate": "Reception bitrate of the path, in Kbps."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_playerplaybackstats",
    "name": "PlayerPlaybackStats",
    "description": "Information about the currently playing media resource.",
    "parameters": [
      {
        "videoFps": "Video frame rate, in fps."
      },
      {
        "videoBitrateInKbps": "Video bitrate, in kbps."
      },
      {
        "audioBitrateInKbps": "Audio bitrate, in kbps."
      },
      {
        "totalBitrateInKbps": "Total bitrate of the media stream, in kbps."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_playerstreaminfo",
    "name": "PlayerStreamInfo",
    "description": "All information about the media stream of the player.",
    "parameters": [
      {
        "streamIndex": "Index of the media stream."
      },
      {
        "streamType": "Type of the media stream. See MEDIA_STREAM_TYPE."
      },
      {
        "codecName": "Codec specification of the media stream."
      },
      {
        "language": "Language of the media stream."
      },
      {
        "videoFrameRate": "This parameter applies only to video streams and indicates the video frame rate (fps)."
      },
      {
        "videoBitRate": "This parameter applies only to video streams and indicates the video bitrate (bps)."
      },
      {
        "videoWidth": "This parameter applies only to video streams and indicates the video width (px)."
      },
      {
        "videoHeight": "This parameter applies only to video streams and indicates the video height (px)."
      },
      {
        "videoRotation": "This parameter applies only to video streams and indicates the rotation angle."
      },
      {
        "audioSampleRate": "This parameter applies only to audio streams and indicates the audio sample rate (Hz)."
      },
      {
        "audioChannels": "This parameter applies only to audio streams and indicates the number of audio channels."
      },
      {
        "audioBitsPerSample": "This parameter applies only to audio streams and indicates the number of bits per audio sample (bit)."
      },
      {
        "duration": "Duration of the media stream (milliseconds)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_playerupdatedinfo",
    "name": "PlayerUpdatedInfo",
    "description": "Information related to the media player.",
    "parameters": [
      {
        "deviceId": "Device ID, identifies a device."
      },
      {
        "videoHeight": "Video height (pixel)."
      },
      {
        "videoWidth": "Video width (pixel)."
      },
      {
        "audioSampleRate": "Audio sample rate (Hz)."
      },
      {
        "audioChannels": "Number of audio channels."
      },
      {
        "audioBitsPerSample": "Number of bits per audio sample (bit)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_rectangle",
    "name": "Rectangle",
    "description": "Position of the target area relative to the entire screen or window. If not set, it refers to the entire screen or window.",
    "parameters": [
      {
        "x": "Horizontal offset of the top-left corner."
      },
      {
        "y": "Vertical offset of the top-left corner."
      },
      {
        "width": "Width of the target area."
      },
      {
        "height": "Height of the target area."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_remoteaudiostats",
    "name": "RemoteAudioStats",
    "description": "Audio statistics of a remote user.",
    "parameters": [
      {
        "uid": "User ID of the remote user."
      },
      {
        "quality": "Audio stream quality sent by the remote user. See QUALITY_TYPE."
      },
      {
        "networkTransportDelay": "Network delay from the audio sender to the receiver (ms)."
      },
      {
        "jitterBufferDelay": "Network delay from the receiver to the jitter buffer (ms). This parameter is not valid when the receiver is an audience member and ClientRoleOptions 's audienceLatencyLevel is 1."
      },
      {
        "audioLossRate": "Audio frame loss rate (%) of the remote stream during the reporting interval."
      },
      {
        "numChannels": "Number of audio channels."
      },
      {
        "receivedSampleRate": "Sampling rate of the received remote audio stream during the reporting interval."
      },
      {
        "receivedBitrate": "Average bitrate (Kbps) of the received remote audio stream during the reporting interval."
      },
      {
        "totalFrozenTime": "Total duration (ms) of audio freezes after the remote user joins the channel. An audio freeze is defined as a frame loss rate of 4% or higher during a call."
      },
      {
        "frozenRate": "Percentage (%) of total freeze time relative to the total duration of valid audio. Valid audio duration refers to the time after the remote user joins the channel during which audio is neither stopped nor disabled."
      },
      {
        "totalActiveTime": "Valid duration (ms) from the start of the audio call to the current callback.\nValid duration excludes the total time the remote user was muted."
      },
      {
        "publishDuration": "Total publishing duration (ms) of the remote audio stream."
      },
      {
        "qoeQuality": "Subjective quality of experience perceived by the local user when receiving remote audio. See EXPERIENCE_QUALITY_TYPE."
      },
      {
        "qualityChangedReason": "Reason for poor subjective experience quality when receiving remote audio. See EXPERIENCE_POOR_REASON."
      },
      {
        "mosValue": "During the reporting interval, the quality score of the received remote audio stream as assessed by Agoraâ€™s real-time audio MOS (Mean Opinion Score) method. The return value ranges from [0, 500]. Divide the value by 100 to get the MOS score, which ranges from 0 to 5. The higher the score, the better the audio quality. MOS Score Audio Quality Greater than 4 Excellent audio quality, clear and smooth. 3.5 - 4 Good audio quality, occasional artifacts, but still clear. 3 - 3.5 Fair audio quality, occasional stutters, not very smooth, requires some attention to understand. 2.5 - 3 Poor audio quality, frequent stutters, requires concentration to understand. 2 - 2.5 Very poor audio quality, occasional noise, partial semantic loss, difficult to communicate. Less than 2 Extremely poor audio quality, frequent noise, significant semantic loss, communication impossible."
      },
      {
        "e2eDelay": "End-to-end audio delay (ms), i.e., the total time from when the remote user captures the audio to when the local user starts playing it."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_remotevideostats",
    "name": "RemoteVideoStats",
    "description": "Statistics of the remote video stream.",
    "parameters": [
      {
        "uid": "User ID specifying which user's video stream."
      },
      {
        "delay": "Delay (ms). Deprecated: In audio-video scenarios with A/V sync mechanisms, refer to the networkTransportDelay and jitterBufferDelay members in RemoteAudioStats for video delay data."
      },
      {
        "e2eDelay": "End-to-end video delay (ms). That is, the total time from when the remote user captures the video to when the local user receives and renders it."
      },
      {
        "width": "Width of the video stream (pixels)."
      },
      {
        "height": "Height of the video stream (pixels)."
      },
      {
        "receivedBitrate": "Bitrate (Kbps) received since the last report."
      },
      {
        "decoderOutputFrameRate": "Output frame rate of the remote video decoder, in fps."
      },
      {
        "rendererOutputFrameRate": "Output frame rate of the remote video renderer, in fps."
      },
      {
        "frameLossRate": "Packet loss rate (%) of the remote video."
      },
      {
        "packetLossRate": "Packet loss rate (%) of the remote video after applying anti-packet-loss techniques."
      },
      {
        "rxStreamType": "Video stream type: high stream or low stream. See VIDEO_STREAM_TYPE."
      },
      {
        "totalFrozenTime": "Total duration (ms) of video freezes after the remote user joins the channel. During the call, if the video frame rate is set to no less than 5 fps and the interval between two consecutive rendered frames exceeds 500 ms, it is counted as a video freeze."
      },
      {
        "frozenRate": "Percentage (%) of total freeze time relative to the total duration of valid video. Valid video duration refers to the time after the remote user joins the channel during which video is neither stopped nor disabled."
      },
      {
        "totalActiveTime": "Valid video duration (ms).\nTotal valid video duration refers to the time after the remote user or host joins the channel during which video is neither stopped nor disabled."
      },
      {
        "publishDuration": "Total publishing duration (ms) of the remote video stream."
      },
      {
        "avSyncTimeMs": "Time (ms) that audio leads video. If the value is negative, it means audio lags behind video."
      },
      {
        "mosValue": "Quality of the remote audio stream during the reporting interval. The quality is measured by Agoraâ€™s real-time audio MOS (Mean Opinion Score) method. The return value ranges from [0, 500]; divide by 100 to get the MOS score, ranging from 0 to 5. The higher the score, the better the audio quality. The subjective audio quality corresponding to the Agora real-time audio MOS score is as follows:\n Greater than 4: Excellent audio quality, clear and smooth.\n 3.5 - 4: Good audio quality, occasional artifacts, but still clear.\n 3 - 3.5: Fair audio quality, occasional stutters, not very smooth, requires some attention to understand.\n 2.5 - 3: Poor audio quality, frequent stutters, requires concentration to understand.\n 2 - 2.5: Very poor audio quality, occasional noise, partial semantic loss, difficult to communicate.\n Less than 2: Extremely poor audio quality, frequent noise, significant semantic loss, communication impossible."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_remotevoicepositioninfo",
    "name": "RemoteVoicePositionInfo",
    "description": "Spatial position information of a remote user or media player.",
    "parameters": [
      {
        "position": "Coordinates in the world coordinate system. This parameter is an array of length 3, with the three values representing the coordinates of the forward, right, and up directions, respectively. Forward, right, and up correspond to the positive directions of the z, x, and y axes of Unity's Vector3."
      },
      {
        "forward": "Unit vector of the forward axis in the world coordinate system. This parameter is an array of length 3, with the three values representing the coordinates of the forward, right, and up directions, respectively. Forward, right, and up correspond to the positive directions of the z, x, and y axes of Unity's Vector3."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_rtcconnection",
    "name": "RtcConnection",
    "description": "Class that contains connection information.",
    "parameters": [
      {
        "channelId": "Channel name."
      },
      {
        "localUid": "Local user ID."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_rtcengineconfig",
    "name": "RtcEngineContext",
    "description": "Definition of RtcEngineContext.",
    "parameters": [
      {
        "eventHandler": "Event handler of IRtcEngine. See IRtcEngineEventHandler."
      },
      {
        "appId": "The App ID issued by Agora to the developer. Only apps using the same App ID can join the same channel for a call or live broadcast. An App ID can only be used to create one IRtcEngine. To change the App ID, you must call Dispose to destroy the current IRtcEngine and then create a new one."
      },
      {
        "context": "On Windows, context is the window handle. If set, it indicates support for hot-plugging devices.\n On Android, context is the Android activity context."
      },
      {
        "channelProfile": "Channel profile. See CHANNEL_PROFILE_TYPE."
      },
      {
        "audioScenario": "Audio scenario. Different audio scenarios have different volume types.\nSee AUDIO_SCENARIO_TYPE."
      },
      {
        "areaCode": "Region for accessing the server. This is an advanced setting suitable for scenarios with access security restrictions. Supported regions are listed in AREA_CODE. Area codes support bitwise operations."
      },
      {
        "logConfig": "Sets the log files output by the SDK. See LogConfig.\nBy default, the SDK generates 5 SDK log files and 5 API call log files, following these rules:"
      },
      {
        "domainLimit": "Whether to enable domain name restriction: true : Enable domain name restriction. This setting is suitable for IoT devices accessing the network using IoT SIM cards. The SDK will only connect to servers in the domain or IP whitelist reported to the carrier. false : (Default) Disable domain name restriction. This setting is suitable for most common scenarios."
      },
      {
        "autoRegisterAgoraExtensions": "Whether to automatically register Agora extensions when initializing IRtcEngine : true : (Default) Automatically register Agora extensions when initializing IRtcEngine. false : Do not register Agora extensions when initializing IRtcEngine. You need to call EnableExtension to register the Agora extensions."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_rtcimage",
    "name": "RtcImage",
    "description": "Image properties.\n\nUsed to set the watermark and background image properties for live video.",
    "parameters": [
      {
        "url": "HTTP/HTTPS address of the image on the live video. The character length must not exceed 1024 bytes."
      },
      {
        "x": "The x-coordinate (in px) of the image on the video frame, with the top-left corner of the output video frame as the origin."
      },
      {
        "y": "The y-coordinate (in px) of the image on the video frame, with the top-left corner of the output video frame as the origin."
      },
      {
        "width": "The width (in px) of the image on the video frame."
      },
      {
        "height": "The height (in px) of the image on the video frame."
      },
      {
        "zOrder": "Z-order of the watermark or background image. When using an array of watermarks to add one or more watermarks, you must assign a value to zOrder, with a valid range of [1,255], otherwise the SDK will report an error. In other cases, zOrder is optional, with a valid range of [0,255]. 0 is the default value. 0 represents the bottom layer, and 255 represents the top layer."
      },
      {
        "alpha": "Transparency of the watermark or background image. Value range is [0.0,1.0]:\n 0.0: Fully transparent.\n 1.0: (Default) Fully opaque."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_rtcstats",
    "name": "RtcStats",
    "description": "Call-related statistics.",
    "parameters": [
      {
        "duration": "Call duration of the local user (seconds), cumulative value."
      },
      {
        "txBytes": "Bytes sent."
      },
      {
        "rxBytes": "Bytes received."
      },
      {
        "txAudioBytes": "Audio bytes sent, cumulative value."
      },
      {
        "txVideoBytes": "Video bytes sent, cumulative value."
      },
      {
        "rxAudioBytes": "Audio bytes received, cumulative value."
      },
      {
        "rxVideoBytes": "Video bytes received, cumulative value."
      },
      {
        "txKBitRate": "Sending bitrate (Kbps)."
      },
      {
        "rxKBitRate": "Receiving bitrate (Kbps)."
      },
      {
        "rxAudioKBitRate": "Audio receiving bitrate (Kbps)."
      },
      {
        "txAudioKBitRate": "Audio packet sending bitrate (Kbps)."
      },
      {
        "rxVideoKBitRate": "Video receiving bitrate (Kbps)."
      },
      {
        "txVideoKBitRate": "Video sending bitrate (Kbps)."
      },
      {
        "lastmileDelay": "Client-to-access-server latency (ms)."
      },
      {
        "txPacketLossRate": "Uplink packet loss rate (%) from client to server before anti-packet-loss technology is applied."
      },
      {
        "rxPacketLossRate": "Downlink packet loss rate (%) from server to client before anti-packet-loss technology is applied."
      },
      {
        "userCount": "Number of users in the current channel."
      },
      {
        "cpuAppUsage": "CPU usage of the current app (%).\n The cpuAppUsage reported in the OnLeaveChannel callback is always 0.\n Starting from Android 8.1, due to system restrictions, you may not be able to obtain CPU usage through this property."
      },
      {
        "cpuTotalUsage": "CPU usage of the current system (%).\nOn Windows, in a multi-core environment, this member represents the average usage of multi-core CPUs. It is calculated as (100 - CPU usage of system idle process shown in Task Manager)/100.\n The cpuTotalUsage reported in the OnLeaveChannel callback is always 0.\n Starting from Android 8.1, due to system restrictions, you cannot obtain CPU usage through this property."
      },
      {
        "connectTimeMs": "Time from connection initiation to successful connection (ms). A value of 0 indicates invalid."
      },
      {
        "gatewayRtt": "Round-trip latency from client to local router (ms). This property is enabled by default on devices running iOS versions earlier than 14 and disabled on iOS 14 and later.\n\n To enable this property on devices running iOS 14 and later, please [contact technical support](https://ticket.shengwang.cn/).\nOn Android, to retrieve gatewayRtt, make sure to add the android.permission.ACCESS_WIFI_STATE permission after the </application> tag in your project's AndroidManifest.xml file."
      },
      {
        "memoryAppUsageRatio": "Memory usage ratio of the current app (%). This value is for reference only. It may not be available due to system limitations."
      },
      {
        "memoryTotalUsageRatio": "Memory usage ratio of the current system (%). This value is for reference only. It may not be available due to system limitations."
      },
      {
        "memoryAppUsageInKbytes": "Memory size of the current app (KB). This value is for reference only. It may not be available due to system limitations."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_screenaudioparameters",
    "name": "ScreenAudioParameters",
    "description": "Audio configuration for the shared screen stream.\n\nOnly applicable when captureAudio is set to true.",
    "parameters": [
      {
        "sampleRate": "Audio sampling rate (Hz). Default is 16000."
      },
      {
        "channels": "Number of audio channels. Default is 2, indicating stereo."
      },
      {
        "captureSignalVolume": "Captured system volume. Value range is [0,100]. Default is 100."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_screencaptureconfiguration",
    "name": "ScreenCaptureConfiguration",
    "description": "Screen capture configuration.",
    "parameters": [
      {
        "isCaptureWindow": "Whether to capture a window on the screen: true : Capture the window. false : (Default) Capture the screen, not the window."
      },
      {
        "displayId": "(macOS only) The display ID of the screen. Use this parameter only when capturing the screen on Mac devices."
      },
      {
        "screenRect": "(Windows only) The position of the screen to be shared relative to the virtual screen. Use this parameter only when capturing the screen on Windows devices."
      },
      {
        "windowId": "(Windows and macOS only) The window ID. Use this parameter only when capturing a window."
      },
      {
        "parameters": "(Windows and macOS only) Encoding parameter configuration for screen sharing stream. See ScreenCaptureParameters."
      },
      {
        "regionRect": "(Windows and macOS only) The position of the region to be shared relative to the entire screen. See Rectangle. If not set, the entire screen is shared. If the shared region exceeds the screen boundaries, only the content within the screen is shared. If the width or height in Rectangle is set to 0, the entire screen is shared."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_screencaptureparameters",
    "name": "ScreenCaptureParameters",
    "description": "Configuration parameters for screen sharing.",
    "parameters": [
      {
        "dimensions": "When setting the encoding resolution in a document sharing scenario (SCREEN_SCENARIO_DOCUMENT), choose one of the following options:\n If you want the best image quality, it is recommended to set the encoding resolution equal to the capture resolution.\n If you want a balance between image quality, bandwidth, and system performance:\n When the capture resolution is greater than 1920 Ã— 1080, it is recommended that the encoding resolution is no less than 1920 Ã— 1080.\n When the capture resolution is less than 1920 Ã— 1080, it is recommended that the encoding resolution is no less than 1280 Ã— 720. The video encoding resolution of the screen sharing stream. See VideoDimensions. The default value is 1920 Ã— 1080, i.e., 2073600 pixels. This pixel value is used for billing. When the aspect ratio of the shared screen resolution does not match this setting, the SDK encodes using the following strategy. Suppose dimensions is set to 1920 Ã— 1080:\n If the screen resolution is smaller than dimensions, e.g., 1000 Ã— 1000, the SDK encodes directly at 1000 Ã— 1000.\n If the screen resolution is larger than dimensions, e.g., 2000 Ã— 1500, the SDK uses the screen resolution's aspect ratio (4:3) to select the maximum resolution within dimensions, i.e., 1440 Ã— 1080."
      },
      {
        "frameRate": "On Windows and macOS platforms, specifies the video encoding frame rate of the screen sharing stream. Unit: fps; default is 5. It is recommended not to exceed 15."
      },
      {
        "bitrate": "Bitrate of the shared video. On Windows and macOS platforms, specifies the video encoding bitrate of the screen sharing stream. Unit: Kbps; default is 0, which means the SDK calculates a reasonable value based on the current shared screen resolution."
      },
      {
        "captureMouseCursor": "Due to macOS system limitations, setting this parameter to false has no effect when sharing the screen (no effect when sharing a window). Whether to capture the mouse for screen sharing: true : (default) capture the mouse. false : do not capture the mouse."
      },
      {
        "windowFocus": "Due to macOS system limitations, when setting this member to bring the window to the front, only the main window is brought to the front if the current application has multiple windows. When calling the StartScreenCaptureByWindowId method to share a window, whether to bring the window to the front: true : bring the window to the front. false : (default) do not bring the window to the front."
      },
      {
        "excludeWindowList": "List of IDs of windows to be excluded. When calling StartScreenCaptureByDisplayId to start screen sharing, you can use this parameter to exclude specific windows. You can also dynamically exclude specific windows by using this parameter when calling UpdateScreenCaptureParameters to update the screen sharing configuration."
      },
      {
        "enableHighLight": "When sharing a partial area of a window or screen, if this parameter is set to true, the SDK highlights the entire window or screen. (Applicable only to macOS and Windows) Whether to highlight the shared window or screen: true : highlight. false : (default) do not highlight."
      },
      {
        "highLightColor": "(Applicable only to macOS and Windows)\n On Windows, specifies the highlight ARGB color. Default is 0xFF8CBF26.\n On macOS, COLOR_CLASS refers to NSColor."
      },
      {
        "highLightWidth": "(Applicable only to macOS and Windows) Width of the highlight border (px). Default is 5. Value range is (0,50]. This parameter only takes effect when highLighted is set to true."
      },
      {
        "excludeWindowCount": "Number of windows to be excluded. On Windows, the maximum value for this parameter is 24. If it exceeds this value, the window exclusion feature becomes ineffective."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_screencaptureparameters2",
    "name": "ScreenCaptureParameters2",
    "description": "Parameter configuration for screen sharing.",
    "parameters": [
      {
        "captureAudio": "Due to system limitations, capturing system audio is only supported on Android API level 29 and above, i.e., Android 10 and above.\n To improve the success rate of capturing system audio during screen sharing, make sure you have called the SetAudioScenario method and set the audio scenario to AUDIO_SCENARIO_GAME_STREAMING. Whether to capture system audio during screen sharing: true : Capture system audio. false : (Default) Do not capture system audio."
      },
      {
        "audioParams": "Audio configuration for the shared screen stream. See ScreenAudioParameters. This parameter takes effect only when captureAudio is set to true."
      },
      {
        "captureVideo": "Due to system limitations, screen capture is only supported on Android API level 21 and above, i.e., Android 5 and above. Whether to capture the screen during screen sharing: true : (Default) Capture the screen. false : Do not capture the screen."
      },
      {
        "videoParams": "Video encoding configuration for the shared screen stream. See ScreenVideoParameters. This parameter takes effect only when captureVideo is set to true."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_screencapturesourceinfo",
    "name": "ScreenCaptureSourceInfo",
    "description": "Information about shareable windows or screens.",
    "parameters": [
      {
        "type": "Type of the sharing target. See ScreenCaptureSourceType."
      },
      {
        "sourceId": "For a window, this is the Window ID; for a screen, this is the Display ID."
      },
      {
        "sourceName": "Name of the window or screen. UTF-8 encoded."
      },
      {
        "thumbImage": "Image content of the thumbnail. See ThumbImageBuffer."
      },
      {
        "iconImage": "Image content of the icon. See ThumbImageBuffer."
      },
      {
        "processPath": "Process to which the window belongs. UTF-8 encoded."
      },
      {
        "sourceTitle": "Window title. UTF-8 encoded."
      },
      {
        "primaryMonitor": "Whether the screen is the primary display: true : The screen is the primary display. false : The screen is not the primary display."
      },
      {
        "position": "Position of the window relative to the entire screen space (including all shareable screens). See Rectangle."
      },
      {
        "sourceDisplayId": "(Windows only) ID of the screen where the window is located. If the window spans multiple screens, this is the ID of the screen with the largest intersection area. If the window is outside the visible screen area, the value is -2."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_screenvideoparameters",
    "name": "ScreenVideoParameters",
    "description": "Video encoding configuration for the shared screen stream.",
    "parameters": [
      {
        "dimensions": "Video encoding resolution. Default is 1280 Ã— 720."
      },
      {
        "frameRate": "Video encoding frame rate (fps). Default is 15."
      },
      {
        "bitrate": "Video encoding bitrate (Kbps)."
      },
      {
        "contentHint": "Content type of the screen sharing video."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_segmentationproperty",
    "name": "SegmentationProperty",
    "description": "Processing properties for background images.",
    "parameters": [
      {
        "modelType": "Algorithm used for background processing. See SEG_MODEL_TYPE."
      },
      {
        "greenCapacity": "Accuracy range for recognizing background colors in the image. Value range is [0,1], default is 0.5. A larger value indicates a wider range of solid colors can be recognized. If the value is too large, solid colors at the edge or within the portrait may also be recognized. It is recommended to adjust this value dynamically based on actual results. This parameter takes effect only when modelType is set to SEG_MODEL_GREEN."
      },
      {
        "screenColorType": "Screen color type. See SCREEN_COLOR_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_simulcaststreamconfig",
    "name": "SimulcastStreamConfig",
    "description": "Configuration for video low stream.",
    "parameters": [
      {
        "dimensions": "Video resolution. See VideoDimensions. Default is 50% of the high stream resolution."
      },
      {
        "kBitrate": "Video bitrate (Kbps), default is -1. This parameter does not need to be set; the SDK automatically matches the optimal bitrate based on the configured resolution and frame rate."
      },
      {
        "framerate": "Video frame rate (fps). Default is 5."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_snapshotconfig",
    "name": "SnapshotConfig",
    "description": "Video snapshot settings.",
    "parameters": [
      {
        "filePath": "Make sure the directory exists and is writable. The local path to save the snapshot, including the file name and format. For example:\n Windows: C:\\Users\\<user_name>\\AppData\\Local\\Agora\\<process_name>\\example.jpg\n iOS: /App Sandbox/Library/Caches/example.jpg\n macOS: ï½ž/Library/Logs/example.jpg\n Android: /storage/emulated/0/Android/data/<package name>/files/example.jpg"
      },
      {
        "position": "The position of the video frame in the video pipeline to capture the snapshot. See VIDEO_MODULE_POSITION."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_spatialaudioparams",
    "name": "SpatialAudioParams",
    "description": "Spatial audio parameters.",
    "parameters": [
      {
        "speaker_azimuth": "The horizontal angle of the remote user or media player relative to the local user. Range: [0,360], in degrees:\n 0: (default) 0 degrees, directly in front.\n 90: 90 degrees, to the left.\n 180: 180 degrees, behind.\n 270: 270 degrees, to the right.\n 360: 360 degrees, directly in front."
      },
      {
        "speaker_elevation": "The elevation angle of the remote user or media player relative to the local user. Range: [-90,90], in degrees:\n 0: (default) 0 degrees, no vertical rotation.\n -90: -90 degrees, rotated downward.\n 90: 90 degrees, rotated upward."
      },
      {
        "speaker_distance": "The distance between the remote user or media player and the local user. Range: [1,50], in meters. Default is 1 meter."
      },
      {
        "speaker_orientation": "The orientation of the remote user or media player relative to the local user. Range: [0,180], in degrees:\n 0: (default) 0 degrees, facing the same direction.\n 180: 180 degrees, facing each other."
      },
      {
        "enable_blur": "Whether to enable sound blur processing: true : Enable blur. false : (default) Disable blur."
      },
      {
        "enable_air_absorb": "Whether to enable air absorption, simulating timbre attenuation during sound propagation in air: high frequencies attenuate faster than low frequencies over distance. true : (default) Enable air absorption. Make sure speaker_attenuation is not 0, otherwise this setting has no effect. false : Disable air absorption."
      },
      {
        "speaker_attenuation": "The sound attenuation coefficient of the remote user or media player. Range: [0,1]:\n 0: Broadcast mode, no volume or timbre attenuation with distance.\n (0,0.5): Weak attenuation, slight volume and timbre attenuation (requires enable_air_absorb), allowing sound to travel farther than in real environments.\n 0.5: (default) Simulates real-world volume attenuation, same as not setting speaker_attenuation.\n (0.5,1]: Strong attenuation, rapid volume and timbre attenuation (requires enable_air_absorb)."
      },
      {
        "enable_doppler": "This parameter applies to scenarios with fast-moving sound sources (e.g., racing games). It is not recommended for typical audio/video interaction scenarios (voice chat, co-hosting, online karaoke).\n When enabled, it is recommended to update the relative distance between the source and receiver at regular intervals (e.g., every 30 ms) using UpdatePlayerPositionInfo, UpdateSelfPosition, and UpdateRemotePosition. The Doppler effect may not work as expected or may cause audio jitter if: the update interval is too long, updates are irregular, or distance info is lost due to packet loss or latency. Whether to enable Doppler effect: when there is relative motion between the sound source and receiver, the pitch changes. true : Enable Doppler effect. false : (default) Disable Doppler effect."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_spatialaudiozone",
    "name": "SpatialAudioZone",
    "description": "Sound insulation zone settings.",
    "parameters": [
      {
        "zoneSetId": "The ID of the sound insulation zone."
      },
      {
        "position": "The spatial center of the sound insulation zone. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions."
      },
      {
        "forward": "The unit vector in the forward direction from position. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions."
      },
      {
        "right": "The unit vector in the right direction from position. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions."
      },
      {
        "up": "The unit vector in the upward direction from position. This parameter is an array of length 3, representing the coordinates in the forward, right, and up directions."
      },
      {
        "forwardLength": "Assuming the sound insulation zone is a cube, this represents the length in the forward direction, in game engine units."
      },
      {
        "rightLength": "Assuming the sound insulation zone is a cube, this represents the length in the right direction, in game engine units."
      },
      {
        "upLength": "Assuming the sound insulation zone is a cube, this represents the length in the upward direction, in game engine units."
      },
      {
        "audioAttenuation": "The sound attenuation coefficient when users inside and outside the sound insulation zone communicate. Range: [0,1]:\n 0: Broadcast mode, no volume or timbre attenuation with distance.\n (0,0.5): Weak attenuation, slight volume and timbre attenuation, allowing sound to travel farther than in real environments.\n 0.5: Simulates real-world volume attenuation, same as not setting the audioAttenuation parameter.\n (0.5,1]: Strong attenuation (default is 1), rapid volume and timbre attenuation during propagation."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_srcinfo",
    "name": "SrcInfo",
    "description": "Video bitrate information during media playback.",
    "parameters": [
      {
        "bitrateInKbps": "The video bitrate (Kbps) during media playback."
      },
      {
        "name": "The name of the media resource."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_thumbimagebuffer",
    "name": "ThumbImageBuffer",
    "description": "Image content of a thumbnail or icon. Set in ScreenCaptureSourceInfo.\n\nThe image is in ARGB format by default. If you need another format, please convert it manually.",
    "parameters": [
      {
        "buffer": "The buffer of the thumbnail or icon."
      },
      {
        "length": "The buffer length of the thumbnail or icon, in bytes."
      },
      {
        "width": "The actual width (px) of the thumbnail or icon."
      },
      {
        "height": "The actual height (px) of the thumbnail or icon."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_transcodinguser",
    "name": "TranscodingUser",
    "description": "Settings for each host participating in the transcoding mix.",
    "parameters": [
      {
        "uid": "User ID of the host."
      },
      {
        "x": "The x-coordinate (px) of the host video in the output video, with the top-left corner of the output video as the origin. Value range: [0,width], where width is set in LiveTranscoding."
      },
      {
        "y": "The y-coordinate (px) of the host video in the output video, with the top-left corner of the output video as the origin. Value range: [0,height], where height is set in LiveTranscoding."
      },
      {
        "width": "Width (px) of the host video."
      },
      {
        "height": "Height (px) of the host video."
      },
      {
        "zOrder": "If the value is less than 0 or greater than 100, the error ERR_INVALID_ARGUMENT is returned.\n Setting zOrder to 0 is supported. Layer number of the host video. Value range: [0,100].\n 0: (Default) Video is at the bottom layer.\n 100: Video is at the top layer."
      },
      {
        "alpha": "Transparency of the host video. Value range: [0.0,1.0].\n 0.0: Fully transparent.\n 1.0: (Default) Fully opaque."
      },
      {
        "audioChannel": "When the value is not 0, a special player is required. The audio channel occupied by the host's audio in the output audio. Default is 0. Value range: [0,5]: 0 : (Recommended) Default audio mixing setting, supports up to stereo, related to the host's upstream audio. 1 : Host audio is in the FL channel of the output audio. If the upstream audio is multi-channel, the Agora server mixes it into mono first. 2 : Host audio is in the FC channel of the output audio. If the upstream audio is multi-channel, the Agora server mixes it into mono first. 3 : Host audio is in the FR channel of the output audio. If the upstream audio is multi-channel, the Agora server mixes it into mono first. 4 : Host audio is in the BL channel of the output audio. If the upstream audio is multi-channel, the Agora server mixes it into mono first. 5 : Host audio is in the BR channel of the output audio. If the upstream audio is multi-channel, the Agora server mixes it into mono first. 0xFF or values greater than 5 : This host's audio is muted, and the Agora server removes the host's audio."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_transcodingvideostream",
    "name": "TranscodingVideoStream",
    "description": "Video streams participating in local composition.",
    "parameters": [
      {
        "sourceType": "The video source type participating in local composition. See VIDEO_SOURCE_TYPE."
      },
      {
        "remoteUserUid": "Remote user ID. Use this parameter only when the video source type for local composition is VIDEO_SOURCE_REMOTE."
      },
      {
        "imageUrl": "Use this parameter only when the video source type for local composition is an image. Path to the local image. Example paths:\n Android: /storage/emulated/0/Pictures/image.png\n iOS: /var/mobile/Containers/Data/Application/<APP-UUID>/Documents/image.png\n macOS: ~/Pictures/image.png\n Windows: C:\\\\Users\\\\{username}\\\\Pictures\\\\image.png"
      },
      {
        "mediaPlayerId": "(Optional) Media player ID. You need to set this parameter when sourceType is VIDEO_SOURCE_MEDIA_PLAYER."
      },
      {
        "x": "Horizontal offset of the top-left corner of the video participating in local composition relative to the top-left corner (origin) of the composition canvas."
      },
      {
        "y": "Vertical offset of the top-left corner of the video participating in local composition relative to the top-left corner (origin) of the composition canvas."
      },
      {
        "width": "Width (px) of the video participating in local composition."
      },
      {
        "height": "Height (px) of the video participating in local composition."
      },
      {
        "zOrder": "Layer number of the video participating in local composition. Value range: [0,100].\n 0: (Default) Layer is at the bottom.\n 100: Layer is at the top."
      },
      {
        "alpha": "Transparency of the video participating in local composition. Value range: [0.0,1.0]. 0.0 means fully transparent, 1.0 means fully opaque."
      },
      {
        "mirror": "This parameter only takes effect for camera video sources. Whether to mirror the video participating in local composition: true : Mirror the video. false : (Default) Do not mirror the video."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_uplinknetworkinfo",
    "name": "UplinkNetworkInfo",
    "description": "Uplink network information.",
    "parameters": [
      {
        "video_encoder_target_bitrate_bps": "Target bitrate (bps) of the video encoder."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_useraudiospectruminfo",
    "name": "UserAudioSpectrumInfo",
    "description": "Audio spectrum information of a remote user.",
    "parameters": [
      {
        "uid": "Remote user ID."
      },
      {
        "spectrumData": "Audio spectrum data of the remote user. See AudioSpectrumData."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_userinfo",
    "name": "UserInfo",
    "description": "User information.",
    "parameters": [
      {
        "uid": "User ID."
      },
      {
        "userAccount": "User account. Length limit: MAX_USER_ACCOUNT_LENGTH_TYPE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videocanvas",
    "name": "VideoCanvas",
    "description": "Properties of the video canvas object.",
    "parameters": [
      {
        "uid": "For Android and iOS platforms, when the video source is a composite video stream (VIDEO_SOURCE_TRANSCODED), this parameter represents the user ID that publishes the composite video stream."
      },
      {
        "subviewUid": "The user ID that publishes a specific sub-video stream of the composite stream."
      },
      {
        "view": "The video display window. In a VideoCanvas, you can only set either view or surfaceTexture. If both are set, only the configuration in view takes effect."
      },
      {
        "renderMode": "Video rendering mode. See RENDER_MODE_TYPE."
      },
      {
        "mirrorMode": "View mirroring mode. See VIDEO_MIRROR_MODE_TYPE.\n Local view mirroring mode: If you use the front camera, local view mirroring is enabled by default; if you use the rear camera, it is disabled by default.\n Remote user view mirroring mode: Mirroring is disabled by default for remote users."
      },
      {
        "sourceType": "Type of video source. See VIDEO_SOURCE_TYPE."
      },
      {
        "setupMode": "View setup mode. See VIDEO_VIEW_SETUP_MODE."
      },
      {
        "mediaPlayerId": "Media player ID. You can obtain it via GetId."
      },
      {
        "cropArea": "(Optional) Display area of the video frame. See Rectangle. width and height indicate the pixel width and height of the area. The default is null (width or height is 0), which means the actual resolution of the video frame is displayed."
      },
      {
        "backgroundColor": "Background color of the video canvas in RGBA format. The default value is 0x00000000, which represents black."
      },
      {
        "enableAlphaMask": "The receiver can render alpha channel information only when the sender enables the alpha transmission feature.\n To enable the alpha transmission feature, please [contact technical support](https://ticket.shengwang.cn/). (Optional) Whether to enable alpha mask rendering: true : Enable alpha mask rendering. false : (Default) Disable alpha mask rendering. Alpha mask rendering can create transparent images and extract portraits from videos. When used with other methods, it enables effects like portrait picture-in-picture and watermarking."
      },
      {
        "position": "The position of the video frame in the video pipeline. See VIDEO_MODULE_POSITION."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videodenoiseroptions",
    "name": "VideoDenoiserOptions",
    "description": "Video denoising options.",
    "parameters": [
      {
        "level": "Video denoising level."
      },
      {
        "mode": "Video denoising mode."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videodeviceinfo",
    "name": "DeviceInfo",
    "description": "The DeviceInfo class, containing the video device ID and name.",
    "parameters": [
      {
        "deviceId": "Device ID."
      },
      {
        "deviceName": "Device name."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videodimensions",
    "name": "VideoDimensions",
    "description": "Video dimensions.",
    "parameters": [
      {
        "width": "Video width in pixels."
      },
      {
        "height": "Video height in pixels."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videoencoderconfiguration",
    "name": "VideoEncoderConfiguration",
    "description": "Configuration for the video encoder.",
    "parameters": [
      {
        "dimensions": "Resolution (px) for video encoding. See VideoDimensions. This parameter is used to measure encoding quality, expressed as width Ã— height. The default value is 960 Ã— 540. You can set the resolution as needed."
      },
      {
        "codecType": "Video codec type. See VIDEO_CODEC_TYPE."
      },
      {
        "frameRate": "Frame rate (fps) for video encoding. Default is 15. See FRAME_RATE."
      },
      {
        "bitrate": "Bitrate for video encoding in Kbps. See BITRATE. You don't need to set this parameter; keep the default value STANDARD_BITRATE. The SDK automatically selects the optimal bitrate based on your configured video resolution and frame rate. For details on the relationship between resolution and frame rate, see [Video Profile](https://doc.shengwang.cn/doc/rtc/unity/basic-features/video-profile#%E8%A7%86%E9%A2%91%E5%B1%9E%E6%80%A7%E5%8F%82%E8%80%83)."
      },
      {
        "minBitrate": "Minimum encoding bitrate in Kbps.\nThe SDK automatically adjusts the video encoding bitrate based on network conditions. Setting this parameter higher than the default forces the encoder to output high-quality images, but may cause packet loss and video stuttering under poor network conditions. Therefore, unless you have specific quality requirements, Agora recommends not modifying this parameter. This parameter applies to live streaming only."
      },
      {
        "orientationMode": "Orientation mode for video encoding. See ORIENTATION_MODE."
      },
      {
        "degradationPreference": "Video degradation preference when bandwidth is limited. See DEGRADATION_PREFERENCE. When this parameter is set to MAINTAIN_FRAMERATE (1) or MAINTAIN_BALANCED (2), you must also set orientationMode to ORIENTATION_MODE_ADAPTIVE (0), otherwise the setting will not take effect."
      },
      {
        "mirrorMode": "Whether to enable mirror mode when sending encoded video. This only affects what remote users see. See VIDEO_MIRROR_MODE_TYPE. Mirror mode is disabled by default."
      },
      {
        "advanceOptions": "Advanced options for video encoding. See AdvanceOptions."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videoformat",
    "name": "VideoFormat",
    "description": "Video frame format.",
    "parameters": [
      {
        "width": "Width of the video frame (px). Default is 960."
      },
      {
        "height": "Height of the video frame (px). Default is 540."
      },
      {
        "fps": "Frame rate of the video frame. Default is 15."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videoframe",
    "name": "VideoFrame",
    "description": "Video frame property settings.\n\nThe buffer is a pointer to a pointer. This interface cannot modify the buffer pointer, only the buffer content.",
    "parameters": [
      {
        "type": "Pixel format. See VIDEO_PIXEL_FORMAT."
      },
      {
        "width": "Video pixel width."
      },
      {
        "height": "Video pixel height."
      },
      {
        "yStride": "For YUV data, indicates the stride of the Y buffer; for RGBA data, indicates the total data length. When processing video data, you need to handle the offset between each row of pixel data according to this parameter, otherwise image distortion may occur."
      },
      {
        "uStride": "For YUV data, indicates the stride of the U buffer; for RGBA data, the value is 0. When processing video data, you need to handle the offset between each row of pixel data according to this parameter, otherwise image distortion may occur."
      },
      {
        "vStride": "For YUV data, indicates the stride of the V buffer; for RGBA data, the value is 0. When processing video data, you need to handle the offset between each row of pixel data according to this parameter, otherwise image distortion may occur."
      },
      {
        "yBuffer": "For YUV data, indicates the pointer to the Y buffer; for RGBA data, indicates the data buffer."
      },
      {
        "uBuffer": "For YUV data, indicates the pointer to the U buffer; for RGBA data, the value is null."
      },
      {
        "vBuffer": "For YUV data, indicates the pointer to the V buffer; for RGBA data, the value is null."
      },
      {
        "rotation": "Set the clockwise rotation angle of the frame before rendering the video. Currently supports 0, 90, 180, and 270 degrees."
      },
      {
        "renderTimeMs": "The Unix timestamp (in milliseconds) when the video frame is rendered. This timestamp can be used to guide the rendering of the video frame. This parameter is required."
      },
      {
        "avsync_type": "Reserved parameter."
      },
      {
        "metadata_buffer": "This parameter is only applicable to video data in Texture format. Refers to the metadata buffer. The default value is NULL."
      },
      {
        "metadata_size": "This parameter is only applicable to video data in Texture format. Refers to the size of the metadata. The default value is 0."
      },
      {
        "sharedContext": "This parameter is only applicable to video data in Texture format. EGL Context."
      },
      {
        "textureId": "This parameter is only applicable to video data in Texture format. Texture ID."
      },
      {
        "d3d11Texture2d": "This parameter is only applicable to video data in Windows Texture format. Represents a pointer to an object of type ID3D11Texture2D, which is used by the video frame."
      },
      {
        "matrix": "This parameter is only applicable to video data in Texture format. It is an input 4x4 transformation matrix, typically an identity matrix."
      },
      {
        "colorSpace": "Color space attributes of the video frame. By default, Full Range and BT.709 standard configurations are applied. You can customize the settings based on your custom capture and rendering requirements. See [VideoColorSpace](https://developer.mozilla.org/en-US/docs/Web/API/VideoColorSpace)."
      },
      {
        "alphaBuffer": "Alpha channel data output by the portrait segmentation algorithm. This data matches the size of the video frame. Each pixel value ranges from [0, 255], where 0 represents the background and 255 represents the foreground (portrait).\nYou can use this parameter to render the video background with various effects, such as transparency, solid color, image, video, etc.\n In custom video rendering scenarios, ensure that both the video frame and alphaBuffer are of Full Range type; other types may cause abnormal Alpha data rendering.\n Make sure that alphaBuffer exactly matches the size of the video frame (width Ã— height), otherwise the app may crash."
      },
      {
        "alphaStitchMode": "When the video frame contains Alpha channel data, sets the relative position of alphaBuffer and the video frame. See ALPHA_STITCH_MODE."
      },
      {
        "metaInfo": "Metadata in the video frame. This parameter requires [contacting technical support](https://ticket.shengwang.cn/) for use."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videoframebufferconfig",
    "name": "VideoFrameBufferConfig",
    "description": "Video frame settings.",
    "parameters": [
      {
        "type": "Video source type. See VIDEO_SOURCE_TYPE."
      },
      {
        "id": "User ID."
      },
      {
        "key": "Channel name."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videolayout",
    "name": "VideoLayout",
    "description": "Layout information of a sub video stream in a composite stream.",
    "parameters": [
      {
        "channelId": "Channel name to which the sub video stream belongs."
      },
      {
        "uid": "User ID that publishes the sub video stream."
      },
      {
        "strUid": "Reserved parameter."
      },
      {
        "x": "The x-coordinate (px) of the sub video stream on the composite canvas. That is, the horizontal offset of the top-left corner of the sub video relative to the top-left corner (origin) of the canvas."
      },
      {
        "y": "The y-coordinate (px) of the sub video stream on the composite canvas. That is, the vertical offset of the top-left corner of the sub video relative to the top-left corner (origin) of the canvas."
      },
      {
        "width": "Width (px) of the sub video stream."
      },
      {
        "height": "Height (px) of the sub video stream."
      },
      {
        "videoState": "State of the sub video stream on the composite canvas.\n 0: Normal. The video stream is rendered on the canvas.\n 1: Placeholder. The video stream has no video content and is displayed as a placeholder on the canvas.\n 2: Black image. The video stream is replaced with a black image."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videorenderingtracinginfo",
    "name": "VideoRenderingTracingInfo",
    "description": "Metrics during the video frame rendering process.",
    "parameters": [
      {
        "elapsedTime": "The time interval (ms) from calling StartMediaRenderingTracing to triggering the OnVideoRenderingTracingResult callback. It is recommended to call StartMediaRenderingTracing before joining the channel."
      },
      {
        "start2JoinChannel": "The time interval (ms) from calling StartMediaRenderingTracing to calling JoinChannel [1/2] or JoinChannel [2/2]. A negative value indicates that StartMediaRenderingTracing was called after JoinChannel [2/2]."
      },
      {
        "join2JoinSuccess": "The time interval (ms) from calling JoinChannel [1/2] or JoinChannel [2/2] to successfully joining the channel."
      },
      {
        "joinSuccess2RemoteJoined": "If the local user calls StartMediaRenderingTracing after the remote user has already joined the channel, this value is 0 and has no reference value.\n To improve the rendering speed of the remote user, it is recommended that the local user join the channel after the remote user has joined, to reduce this value.\n If the local user calls StartMediaRenderingTracing before successfully joining the channel, this value is the time interval (ms) from the local user successfully joining the channel to the remote user joining the channel.\n If the local user calls StartMediaRenderingTracing after successfully joining the channel, this value is the time interval (ms) from calling StartMediaRenderingTracing to the remote user joining the channel."
      },
      {
        "remoteJoined2SetView": "If the local user calls StartMediaRenderingTracing after setting the remote view, this value is 0 and has no reference value.\n To improve the rendering speed of the remote user, it is recommended to set the remote view before the remote user joins the channel, or immediately after the remote user joins the channel, to reduce this value.\n If the local user calls StartMediaRenderingTracing before the remote user joins the channel, this value is the time interval (ms) from the remote user joining the channel to the local user setting the remote view.\n If the local user calls StartMediaRenderingTracing after the remote user joins the channel, this value is the time interval (ms) from calling StartMediaRenderingTracing to setting the remote view."
      },
      {
        "remoteJoined2UnmuteVideo": "If StartMediaRenderingTracing is called after subscribing to the remote video stream, this value is 0 and has no reference value.\n To improve the rendering speed of the remote user, it is recommended that the local user subscribe to the remote video stream immediately after the remote user joins the channel, to reduce this value.\n If the local user calls StartMediaRenderingTracing before the remote user joins the channel, this value is the time interval (ms) from the remote user joining the channel to subscribing to the remote video stream.\n If the local user calls StartMediaRenderingTracing after the remote user joins the channel, this value is the time interval (ms) from calling StartMediaRenderingTracing to subscribing to the remote video stream."
      },
      {
        "remoteJoined2PacketReceived": "If StartMediaRenderingTracing is called after receiving the remote video stream, this value is 0 and has no reference value.\n To improve the rendering speed of the remote user, it is recommended that the remote user publish the video stream immediately after joining the channel, and the local user subscribe to the remote video stream immediately, to reduce this value.\n If the local user calls StartMediaRenderingTracing before the remote user joins the channel, this value is the time interval (ms) from the remote user joining the channel to the local user receiving the first remote data packet.\n If the local user calls StartMediaRenderingTracing after the remote user joins the channel, this value is the time interval (ms) from calling StartMediaRenderingTracing to receiving the first remote data packet."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videosubscriptionoptions",
    "name": "VideoSubscriptionOptions",
    "description": "Video subscription settings.",
    "parameters": [
      {
        "type": "Type of video stream to subscribe to. The default value is VIDEO_STREAM_HIGH, which subscribes to the high-quality video stream. See VIDEO_STREAM_TYPE."
      },
      {
        "encodedFrameOnly": "Whether to subscribe only to the encoded video stream: true : Subscribe only to encoded video data (structured data). The SDK does not decode or render this video data. false : (Default) Subscribe to both raw and encoded video data."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videosurface",
    "name": "VideoSurface",
    "description": "This class contains Unity native methods related to video rendering.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_videosurfaceyuv",
    "name": "VideoSurfaceYUV",
    "description": "Provides methods related to video rendering. This class inherits from VideoSurface, but renders faster and with higher frame rate when rendering high-resolution (e.g., 4K) video images.",
    "parameters": [],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_virtualbackgroundsource",
    "name": "VirtualBackgroundSource",
    "description": "Custom background.",
    "parameters": [
      {
        "background_source_type": "Custom background. See BACKGROUND_SOURCE_TYPE."
      },
      {
        "color": "Color of the custom background image. Format is a hexadecimal integer under RGB definition, without the # symbol, e.g., 0xFFB6C1 represents light pink. Default value is 0xFFFFFF, which represents white. Value range is [0x000000, 0xffffff]. If the value is invalid, the SDK replaces the original background with a white background. This parameter only takes effect when the custom background is one of the following types:\n BACKGROUND_COLOR: The background image is a solid color image of the specified color.\n BACKGROUND_IMG: If the image in source has a transparent background, the transparent area is filled with the specified color."
      },
      {
        "source": "Absolute local path to the custom background. Supports PNG, JPG, MP4, AVI, MKV, and FLV formats. If the path is invalid, the SDK uses the original background or the solid color specified by color. This parameter only takes effect when the custom background type is BACKGROUND_IMG or BACKGROUND_VIDEO."
      },
      {
        "blur_degree": "Blur level of the custom background. See BACKGROUND_BLUR_DEGREE. This parameter only takes effect when the custom background type is BACKGROUND_BLUR."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_watermarkbuffer",
    "name": "WatermarkBuffer",
    "description": "Used to configure the format, dimensions, and pixel buffer of a watermark image.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "width": "Width of the watermark image in pixels."
      },
      {
        "height": "Height of the watermark image in pixels."
      },
      {
        "length": "Length of the watermark image buffer in bytes."
      },
      {
        "format": "Pixel format of the watermark image. See VIDEO_PIXEL_FORMAT. Default is VIDEO_PIXEL_I420. Currently supported formats include: VIDEO_PIXEL_I420, VIDEO_PIXEL_RGBA, VIDEO_PIXEL_BGRA, and VIDEO_PIXEL_NV21."
      },
      {
        "buffer": "Pixel buffer data of the watermark image."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_watermarkconfig",
    "name": "WatermarkConfig",
    "description": "Used to configure watermark information.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "id": "Unique identifier for the watermark. It is recommended to use a UUID."
      },
      {
        "type": "Type of the watermark. See WATERMARK_SOURCE_TYPE."
      },
      {
        "buffer": "Buffer of the watermark. See WatermarkBuffer."
      },
      {
        "timestamp": "Timestamp of the watermark. (Linux only)"
      },
      {
        "literal": "Text content of the watermark. (Linux only)"
      },
      {
        "imageUrl": "URL of the watermark image file. Default is NULL."
      },
      {
        "options": "Configuration options for the watermark. See WatermarkOptions."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_watermarkliteral",
    "name": "WatermarkLiteral",
    "description": "Used to configure text watermark.\n\nSince Available since v4.6.2. (Linux only)",
    "parameters": [
      {
        "fontSize": "Font size of the text. Default is 10."
      },
      {
        "strokeWidth": "Stroke width of the text. Default is 1."
      },
      {
        "wmLiteral": "Text content of the watermark. Default is NULL. If used asynchronously, copy the string to memory that will not be released."
      },
      {
        "fontFilePath": "Path to the font file. Default is NULL. The font file should be in .ttf format. If not set, the SDK uses the system default font (if available). If used asynchronously, copy the string to memory that will not be released."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_watermarkoptions",
    "name": "WatermarkOptions",
    "description": "Configure watermark image.\n\nUsed to configure the watermark image to be added.",
    "parameters": [
      {
        "visibleInPreview": "Whether the watermark is visible in the local preview view: true : (Default) The watermark is visible in the local preview view. false : The watermark is not visible in the local preview view."
      },
      {
        "positionInLandscapeMode": "When the watermark fit mode is FIT_MODE_COVER_POSITION, this sets the area of the watermark image in landscape mode. See Rectangle."
      },
      {
        "positionInPortraitMode": "When the watermark fit mode is FIT_MODE_COVER_POSITION, this sets the area of the watermark image in portrait mode. See Rectangle."
      },
      {
        "watermarkRatio": "When the watermark fit mode is FIT_MODE_USE_IMAGE_RATIO, this parameter sets the coordinates of the watermark in scale mode. See WatermarkRatio."
      },
      {
        "mode": "Watermark fit mode. See WATERMARK_FIT_MODE."
      },
      {
        "zOrder": "Layer order of the watermark image. Default value is 0."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_watermarkratio",
    "name": "WatermarkRatio",
    "description": "Watermark position and size on the screen.\n\nThe position and size of the watermark on the screen are determined by xRatio, yRatio, and widthRatio :\n (xRatio, yRatio) specifies the coordinates of the top-left corner of the watermark, determining its distance from the top-left corner of the screen. widthRatio specifies the width of the watermark.",
    "parameters": [
      {
        "xRatio": "The x-coordinate of the top-left corner of the watermark. With the top-left corner of the screen as the origin, the x-coordinate is the horizontal offset of the watermark's top-left corner relative to the origin. Value range is [0.0,1.0], default is 0."
      },
      {
        "yRatio": "The y-coordinate of the top-left corner of the watermark. With the top-left corner of the screen as the origin, the y-coordinate is the vertical offset of the watermark's top-left corner relative to the origin. Value range is [0.0,1.0], default is 0."
      },
      {
        "widthRatio": "The width of the watermark. The SDK calculates the proportional height based on this value to ensure the watermark image is not distorted when scaled. Value range is [0.0,1.0], default is 0, which means the watermark is not displayed."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "class_watermarktimestamp",
    "name": "WatermarkTimestamp",
    "description": "Used to configure timestamp watermark.\n\nSince Available since v4.6.2. (Linux only)",
    "parameters": [
      {
        "fontSize": "Font size of the timestamp. Default is 10."
      },
      {
        "fontFilePath": "Path to the font file for the timestamp. Default is NULL. The font file must be in .ttf format. If not set, the SDK uses the system default font (if available). If used asynchronously, copy the path to memory that will not be released."
      },
      {
        "strokeWidth": "Stroke width of the timestamp. Default is 1."
      },
      {
        "format": "Format of the timestamp. Default is %F %X. The format follows the C standard library function strftime. See strftime. If used asynchronously, copy the format string to memory that will not be released."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_alphastitchmode",
    "name": "ALPHA_STITCH_MODE",
    "description": "Relative position of alphaBuffer and the video frame.",
    "parameters": [
      {
        "NO_ALPHA_STITCH": "0: (Default) Only the video frame, i.e., alphaBuffer is not stitched with the video frame."
      },
      {
        "ALPHA_STITCH_UP": "1: alphaBuffer is above the video frame."
      },
      {
        "ALPHA_STITCH_BELOW": "2: alphaBuffer is below the video frame."
      },
      {
        "ALPHA_STITCH_LEFT": "3: alphaBuffer is to the left of the video frame."
      },
      {
        "ALPHA_STITCH_RIGHT": "4: alphaBuffer is to the right of the video frame."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_areacode",
    "name": "AREA_CODE",
    "description": "Access region, i.e., the region of the server the SDK connects to.",
    "parameters": [
      {
        "AREA_CODE_CN": "Mainland China."
      },
      {
        "AREA_CODE_NA": "North America."
      },
      {
        "AREA_CODE_EU": "Europe."
      },
      {
        "AREA_CODE_AS": "Asia excluding China."
      },
      {
        "AREA_CODE_JP": "Japan."
      },
      {
        "AREA_CODE_IN": "India."
      },
      {
        "AREA_CODE_GLOB": "Global."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiencelatencyleveltype",
    "name": "AUDIENCE_LATENCY_LEVEL_TYPE",
    "description": "Latency level of audience in a live streaming channel. This enum is effective only when the user role is set to CLIENT_ROLE_AUDIENCE.",
    "parameters": [
      {
        "AUDIENCE_LATENCY_LEVEL_LOW_LATENCY": "1: Low latency."
      },
      {
        "AUDIENCE_LATENCY_LEVEL_ULTRA_LOW_LATENCY": "2: (Default) Ultra-low latency."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioainsmode",
    "name": "AUDIO_AINS_MODE",
    "description": "Mode of AI noise reduction.",
    "parameters": [
      {
        "AINS_MODE_BALANCED": "0: (Default) Balanced noise reduction mode; select this mode if you want a balanced effect between noise suppression and latency."
      },
      {
        "AINS_MODE_AGGRESSIVE": "1: Aggressive noise reduction mode; suitable for scenarios with high noise suppression requirements, such as outdoor live streaming. This mode can significantly reduce noise but may also slightly damage the voice."
      },
      {
        "AINS_MODE_ULTRALOWLATENCY": "2: Low-latency aggressive noise reduction mode. The noise reduction latency of this mode is about half that of weak and aggressive modes, suitable for scenarios requiring both noise reduction and low latency, such as real-time chorus."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiocodecprofiletype",
    "name": "AUDIO_CODEC_PROFILE_TYPE",
    "description": "Audio codec profile for streaming output. Defaults to LC-AAC.",
    "parameters": [
      {
        "AUDIO_CODEC_PROFILE_LC_AAC": "0: (Default) LC-AAC profile."
      },
      {
        "AUDIO_CODEC_PROFILE_HE_AAC": "1: HE-AAC profile."
      },
      {
        "AUDIO_CODEC_PROFILE_HE_AAC_V2": "2: HE-AAC v2 profile."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiocodectype",
    "name": "AUDIO_CODEC_TYPE",
    "description": "Audio codec format.",
    "parameters": [
      {
        "AUDIO_CODEC_OPUS": "1: OPUS."
      },
      {
        "AUDIO_CODEC_PCMA": "3: PCMA."
      },
      {
        "AUDIO_CODEC_PCMU": "4: PCMU."
      },
      {
        "AUDIO_CODEC_G722": "5: G722."
      },
      {
        "AUDIO_CODEC_AACLC": "8: LC-AAC."
      },
      {
        "AUDIO_CODEC_HEAAC": "9: HE-AAC."
      },
      {
        "AUDIO_CODEC_JC1": "10: JC1."
      },
      {
        "AUDIO_CODEC_HEAAC2": "11: HE-AAC v2."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiodualmonomode",
    "name": "AUDIO_DUAL_MONO_MODE",
    "description": "Channel mode.",
    "parameters": [
      {
        "AUDIO_DUAL_MONO_STEREO": "0: Original mode."
      },
      {
        "AUDIO_DUAL_MONO_L": "1: Left channel mode. This mode replaces the right channel audio with the left channel audio, so the user only hears the left channel."
      },
      {
        "AUDIO_DUAL_MONO_R": "2: Right channel mode. This mode replaces the left channel audio with the right channel audio, so the user only hears the right channel."
      },
      {
        "AUDIO_DUAL_MONO_MIX": "3: Mixed mode. This mode overlays the left and right channel data, so the user hears both channels simultaneously."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioeffectpreset",
    "name": "AUDIO_EFFECT_PRESET",
    "description": "Preset audio effects.\n\nSetAudioProfile [1/2] profile\nPreset audio effects profile\n ROOM_ACOUSTICS_VIRTUAL_STEREO\n ROOM_ACOUSTICS_3D_VOICE\n ROOM_ACOUSTICS_VIRTUAL_SURROUND_SOUND AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO or AUDIO_PROFILE_MUSIC_STANDARD_STEREO Other preset audio effects (excluding AUDIO_EFFECT_OFF) AUDIO_PROFILE_MUSIC_HIGH_QUALITY or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO",
    "parameters": [
      {
        "AUDIO_EFFECT_OFF": "Original sound, disables voice effects."
      },
      {
        "ROOM_ACOUSTICS_KTV": "KTV."
      },
      {
        "ROOM_ACOUSTICS_VOCAL_CONCERT": "Concert."
      },
      {
        "ROOM_ACOUSTICS_STUDIO": "Studio."
      },
      {
        "ROOM_ACOUSTICS_PHONOGRAPH": "Phonograph."
      },
      {
        "ROOM_ACOUSTICS_VIRTUAL_STEREO": "Virtual stereo, where the SDK renders mono audio into stereo effects."
      },
      {
        "ROOM_ACOUSTICS_SPACIAL": "Spacious."
      },
      {
        "ROOM_ACOUSTICS_ETHEREAL": "Ethereal."
      },
      {
        "ROOM_ACOUSTICS_VIRTUAL_SURROUND_SOUND": "Virtual surround sound, where the SDK simulates a surround sound field based on stereo audio to create a surround effect. To hear the expected effect when virtual surround sound is enabled, users must use audio playback devices that support stereo."
      },
      {
        "ROOM_ACOUSTICS_CHORUS": "Chorus. Agora recommends using this in chorus scenarios to make vocals sound more spatial and three-dimensional."
      },
      {
        "ROOM_ACOUSTICS_3D_VOICE": "3D voice, where the SDK renders audio to surround the user. The default surround cycle is 10 seconds. After setting this effect, you can also call SetAudioEffectParameters to modify the surround cycle. To hear the expected effect when 3D voice is enabled, users must use audio playback devices that support stereo."
      },
      {
        "VOICE_CHANGER_EFFECT_UNCLE": "Deep male voice. Recommended for male voice processing; otherwise, the expected effect may not be achieved."
      },
      {
        "VOICE_CHANGER_EFFECT_OLDMAN": "Elderly male. Recommended for male voice processing; otherwise, the expected effect may not be achieved."
      },
      {
        "VOICE_CHANGER_EFFECT_BOY": "Boy. Recommended for male voice processing; otherwise, the expected effect may not be achieved."
      },
      {
        "VOICE_CHANGER_EFFECT_SISTER": "Young woman. Recommended for female voice processing; otherwise, the expected effect may not be achieved."
      },
      {
        "VOICE_CHANGER_EFFECT_GIRL": "Girl. Recommended for female voice processing; otherwise, the expected effect may not be achieved."
      },
      {
        "VOICE_CHANGER_EFFECT_PIGKING": "Pig King."
      },
      {
        "VOICE_CHANGER_EFFECT_HULK": "Hulk."
      },
      {
        "STYLE_TRANSFORMATION_RNB": "R&B."
      },
      {
        "STYLE_TRANSFORMATION_POPULAR": "Pop."
      },
      {
        "PITCH_CORRECTION": "Auto-tune, where the SDK corrects the actual pitch based on the C major scale. After setting this effect, you can also call SetAudioEffectParameters to adjust the base scale and tonic pitch."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioencodedframeobserverposition",
    "name": "AUDIO_ENCODED_FRAME_OBSERVER_POSITION",
    "description": "Audio encoding content.",
    "parameters": [
      {
        "AUDIO_ENCODED_FRAME_OBSERVER_POSITION_RECORD": "1: Encode only the local user's audio."
      },
      {
        "AUDIO_ENCODED_FRAME_OBSERVER_POSITION_PLAYBACK": "2: Encode only the audio of all remote users."
      },
      {
        "AUDIO_ENCODED_FRAME_OBSERVER_POSITION_MIXED": "3: Encode the mixed audio of the local and all remote users."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioencodingtype",
    "name": "AUDIO_ENCODING_TYPE",
    "description": "Audio encoding type.",
    "parameters": [
      {
        "AUDIO_ENCODING_TYPE_AAC_16000_LOW": "0x010101: AAC encoding format, 16000 Hz sampling rate, low quality. A 10-minute audio file is approximately 1.2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_AAC_16000_MEDIUM": "0x010102: AAC encoding format, 16000 Hz sampling rate, medium quality. A 10-minute audio file is approximately 2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_AAC_32000_LOW": "0x010201: AAC encoding format, 32000 Hz sampling rate, low quality. A 10-minute audio file is approximately 1.2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_AAC_32000_MEDIUM": "0x010202: AAC encoding format, 32000 Hz sampling rate, medium quality. A 10-minute audio file is approximately 2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_AAC_32000_HIGH": "0x010203: AAC encoding format, 32000 Hz sampling rate, high quality. A 10-minute audio file is approximately 3.5 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_AAC_48000_MEDIUM": "0x010302: AAC encoding format, 48000 Hz sampling rate, medium quality. A 10-minute audio file is approximately 2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_AAC_48000_HIGH": "0x010303: AAC encoding format, 48000 Hz sampling rate, high quality. A 10-minute audio file is approximately 3.5 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_OPUS_16000_LOW": "0x020101: OPUS encoding format, 16000 Hz sampling rate, low quality. A 10-minute audio file is approximately 2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_OPUS_16000_MEDIUM": "0x020102: OPUS encoding format, 16000 Hz sampling rate, medium quality. A 10-minute audio file is approximately 2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_OPUS_48000_MEDIUM": "0x020302: OPUS encoding format, 48000 Hz sampling rate, medium quality. A 10-minute audio file is approximately 2 MB after encoding."
      },
      {
        "AUDIO_ENCODING_TYPE_OPUS_48000_HIGH": "0x020303: OPUS encoding format, 48000 Hz sampling rate, high quality. A 10-minute audio file is approximately 3.5 MB after encoding."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioequalizationbandfrequency",
    "name": "AUDIO_EQUALIZATION_BAND_FREQUENCY",
    "description": "Center frequencies of voice equalization bands.",
    "parameters": [
      {
        "AUDIO_EQUALIZATION_BAND_31": "0: 31 Hz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_62": "1: 62 Hz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_125": "2: 125 Hz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_250": "3: 250 Hz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_500": "4: 500 Hz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_1K": "5: 1 kHz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_2K": "6: 2 kHz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_4K": "7: 4 kHz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_8K": "8: 8 kHz"
      },
      {
        "AUDIO_EQUALIZATION_BAND_16K": "9: 16 kHz"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiofilerecordingtype",
    "name": "AUDIO_FILE_RECORDING_TYPE",
    "description": "Recording content. Set in StartAudioRecording [3/3].",
    "parameters": [
      {
        "AUDIO_FILE_RECORDING_MIC": "1: Record only the local user's audio."
      },
      {
        "AUDIO_FILE_RECORDING_PLAYBACK": "2: Record only the audio of all remote users."
      },
      {
        "AUDIO_FILE_RECORDING_MIXED": "3: Record the mixed audio of the local and all remote users."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioframetype",
    "name": "AUDIO_FRAME_TYPE",
    "description": "Audio frame type.",
    "parameters": [
      {
        "FRAME_TYPE_PCM16": "0: PCM 16"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiomixingdualmonomode",
    "name": "AUDIO_MIXING_DUAL_MONO_MODE",
    "description": "Channel mode.",
    "parameters": [
      {
        "AUDIO_MIXING_DUAL_MONO_AUTO": "0: Original mode."
      },
      {
        "AUDIO_MIXING_DUAL_MONO_L": "1: Left channel mode. This mode replaces the right channel audio with the left channel audio, so the user hears only the left channel."
      },
      {
        "AUDIO_MIXING_DUAL_MONO_R": "2: Right channel mode. This mode replaces the left channel audio with the right channel audio, so the user hears only the right channel."
      },
      {
        "AUDIO_MIXING_DUAL_MONO_MIX": "3: Mix mode. This mode overlays the left and right channel data so the user hears both channels simultaneously."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiomixingreasontype",
    "name": "AUDIO_MIXING_REASON_TYPE",
    "description": "Reason for music file playback state change. Reported in the OnAudioMixingStateChanged callback.",
    "parameters": [
      {
        "AUDIO_MIXING_REASON_OK": "0: Music file opened successfully."
      },
      {
        "AUDIO_MIXING_REASON_CAN_NOT_OPEN": "701: Failed to open music file. For example, the local music file does not exist, the file format is not supported, or the online music file URL is inaccessible."
      },
      {
        "AUDIO_MIXING_REASON_TOO_FREQUENT_CALL": "702: Music file opened too frequently. If you need to call startAudioMixing multiple times, ensure the interval between calls is greater than 500 ms."
      },
      {
        "AUDIO_MIXING_REASON_INTERRUPTED_EOF": "703: Music file playback interrupted."
      },
      {
        "AUDIO_MIXING_REASON_ONE_LOOP_COMPLETED": "721: One loop of music file playback completed."
      },
      {
        "AUDIO_MIXING_REASON_ALL_LOOPS_COMPLETED": "723: All loops of music file playback completed."
      },
      {
        "AUDIO_MIXING_REASON_STOPPED_BY_USER": "724: Music file playback stopped successfully by calling StopAudioMixing."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiomixingstatetype",
    "name": "AUDIO_MIXING_STATE_TYPE",
    "description": "Music file playback state.",
    "parameters": [
      {
        "AUDIO_MIXING_STATE_PLAYING": "710: Music file is playing normally."
      },
      {
        "AUDIO_MIXING_STATE_PAUSED": "711: Music file playback is paused."
      },
      {
        "AUDIO_MIXING_STATE_STOPPED": "713: Music file playback stopped.\nThis state may be caused by:\n AUDIO_MIXING_REASON_ALL_LOOPS_COMPLETED(723)\n AUDIO_MIXING_REASON_STOPPED_BY_USER(724)"
      },
      {
        "AUDIO_MIXING_STATE_FAILED": "714: Music file playback failed.\nThis state may be caused by:\n AUDIO_MIXING_REASON_CAN_NOT_OPEN(701)\n AUDIO_MIXING_REASON_TOO_FREQUENT_CALL(702)\n AUDIO_MIXING_REASON_INTERRUPTED_EOF(703)"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioprocessingchannels",
    "name": "AUDIO_PROCESSING_CHANNELS",
    "description": "Number of channels for audio preprocessing.\n\nIn scenarios such as concerts where enhanced realism is required, local users may need to capture and send stereo signals to remote users.\nFor example, on a concert stage, the lead singer, guitarist, and drummer stand in different positions. The on-site equipment captures stereo sound from all three and sends the stereo signal to remote users, allowing them to hear vocals, guitar, and drums from different directions as if they were on stage.\nWith this class, you can set dual-channel processing to achieve stereo. It is recommended to configure it as follows:\n Preprocessing: Call SetAdvancedAudioOptions and set audioProcessingChannels in AdvancedAudioOptions to AUDIO_PROCESSING_STEREO (2).\n Postprocessing: Call SetAudioProfile [2/2] and set profile to AUDIO_PROFILE_MUSIC_STANDARD_STEREO (3) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5).\n Stereo settings only take effect under media volume. To understand the difference between media volume and call volume, see [Volume Types](https://doc.shengwang.cn/faq/integration-issues/system-volume).\n On iOS, stereo is supported on iOS version 14.0 and above. Minimum device requirements:\n iPhone XS\n iPhone XS Max\n iPhone XR\n iPhone 11\n iPhone 11 Pro\n iPhone 11 Pro Max\n iPhone SE (2020)\n 11-inch or 12.9-inch iPad Pro (3rd generation)\n 11-inch or 12.9-inch iPad Pro (4th generation)",
    "parameters": [
      {
        "AUDIO_PROCESSING_MONO": "1: (Default) Mono."
      },
      {
        "AUDIO_PROCESSING_STEREO": "2: Stereo."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioprofiletype",
    "name": "AUDIO_PROFILE_TYPE",
    "description": "Audio encoding profile.",
    "parameters": [
      {
        "AUDIO_PROFILE_DEFAULT": "0: Default value.\n In live broadcast scenarios: 48 kHz sampling rate, music encoding, mono, max bitrate 64 Kbps.\n In communication scenarios:\n Windows: 16 kHz sampling rate, voice encoding, mono, max bitrate 16 Kbps.\n Android, macOS, iOS: 32 kHz sampling rate, voice encoding, mono, max bitrate 18 Kbps."
      },
      {
        "AUDIO_PROFILE_SPEECH_STANDARD": "1: Specifies 32 kHz sampling rate, voice encoding, mono, max bitrate 18 Kbps."
      },
      {
        "AUDIO_PROFILE_MUSIC_STANDARD": "2: Specifies 48 kHz sampling rate, music encoding, mono, max bitrate 64 Kbps."
      },
      {
        "AUDIO_PROFILE_MUSIC_STANDARD_STEREO": "3: Specifies 48 kHz sampling rate, music encoding, stereo, max bitrate 80 Kbps.\nTo enable stereo, you also need to call SetAdvancedAudioOptions and set audioProcessingChannels in AdvancedAudioOptions to AUDIO_PROCESSING_STEREO."
      },
      {
        "AUDIO_PROFILE_MUSIC_HIGH_QUALITY": "4: Specifies 48 kHz sampling rate, music encoding, mono, max bitrate 96 Kbps."
      },
      {
        "AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO": "5: Specifies 48 kHz sampling rate, music encoding, stereo, max bitrate 128 Kbps.\nTo enable stereo, you also need to call SetAdvancedAudioOptions and set audioProcessingChannels in AdvancedAudioOptions to AUDIO_PROCESSING_STEREO."
      },
      {
        "AUDIO_PROFILE_IOT": "6: Specifies 16 kHz sampling rate, voice encoding, mono, applies echo cancellation algorithm AEC."
      },
      {
        "AUDIO_PROFILE_NUM": "Enumeration boundary value."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiorecordingqualitytype",
    "name": "AUDIO_RECORDING_QUALITY_TYPE",
    "description": "Audio recording quality.",
    "parameters": [
      {
        "AUDIO_RECORDING_QUALITY_LOW": "0: Low quality. 32 kHz sampling rate, file size for 10 minutes is about 1.2 MB."
      },
      {
        "AUDIO_RECORDING_QUALITY_MEDIUM": "1: Medium quality. 32 kHz sampling rate, file size for 10 minutes is about 2 MB."
      },
      {
        "AUDIO_RECORDING_QUALITY_HIGH": "2: High quality. 32 kHz sampling rate, file size for 10 minutes is about 3.75 MB."
      },
      {
        "AUDIO_RECORDING_QUALITY_ULTRA_HIGH": "3: Ultra high quality. 32 kHz sampling rate, file size for 10 minutes is about 7.5 MB."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioreverbtype",
    "name": "AUDIO_REVERB_TYPE",
    "description": "Audio reverb types.",
    "parameters": [
      {
        "AUDIO_REVERB_DRY_LEVEL": "0: Original sound intensity, also known as dry signal, range [-20,10], unit: dB."
      },
      {
        "AUDIO_REVERB_WET_LEVEL": "1: Early reflection signal intensity, also known as wet signal, range [-20,10], unit: dB."
      },
      {
        "AUDIO_REVERB_ROOM_SIZE": "2: Room size for desired reverb effect. Generally, the larger the room, the stronger the reverb. Range [0,100], unit: dB."
      },
      {
        "AUDIO_REVERB_WET_DELAY": "3: Initial delay length of wet signal, range [0,200], unit: milliseconds."
      },
      {
        "AUDIO_REVERB_STRENGTH": "4: Intensity of reverb duration, range [0,100]."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioroute",
    "name": "AudioRoute",
    "description": "Type of audio route.",
    "parameters": [
      {
        "ROUTE_DEFAULT": "-1: Use the default audio route."
      },
      {
        "ROUTE_HEADSET": "0: Audio routed to headset with microphone."
      },
      {
        "ROUTE_EARPIECE": "1: Audio routed to earpiece."
      },
      {
        "ROUTE_HEADSETNOMIC": "2: Audio routed to headset without microphone."
      },
      {
        "ROUTE_SPEAKERPHONE": "3: Audio routed to the device's built-in speaker."
      },
      {
        "ROUTE_LOUDSPEAKER": "4: Audio routed to external speaker. (iOS and macOS only)"
      },
      {
        "ROUTE_BLUETOOTH_DEVICE_HFP": "5: Audio routed to Bluetooth device using HFP protocol."
      },
      {
        "ROUTE_USB": "6: Audio routed to USB peripheral device. (macOS only)"
      },
      {
        "ROUTE_HDMI": "7: Audio routed to HDMI peripheral device. (macOS only)"
      },
      {
        "ROUTE_DISPLAYPORT": "8: Audio routed to DisplayPort peripheral device. (macOS only)"
      },
      {
        "ROUTE_AIRPLAY": "9: Audio routed to Apple AirPlay. (macOS only)"
      },
      {
        "ROUTE_BLUETOOTH_DEVICE_A2DP": "10: Audio routed to Bluetooth device using A2DP protocol."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiosampleratetype",
    "name": "AUDIO_SAMPLE_RATE_TYPE",
    "description": "Sampling rate of audio for stream output.",
    "parameters": [
      {
        "AUDIO_SAMPLE_RATE_32000": "32000: 32 kHz"
      },
      {
        "AUDIO_SAMPLE_RATE_44100": "44100: 44.1 kHz"
      },
      {
        "AUDIO_SAMPLE_RATE_48000": "48000: (Default) 48 kHz"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audioscenariotype",
    "name": "AUDIO_SCENARIO_TYPE",
    "description": "Audio scenario.",
    "parameters": [
      {
        "AUDIO_SCENARIO_DEFAULT": "0: (Default) Auto scenario. Automatically matches appropriate audio quality based on user role and routing."
      },
      {
        "AUDIO_SCENARIO_GAME_STREAMING": "3: High-quality scenario suitable for music-focused use cases. Example: Instrument practice."
      },
      {
        "AUDIO_SCENARIO_CHATROOM": "5: Chatroom scenario, suitable for frequent mic on/off situations. Example: Education."
      },
      {
        "AUDIO_SCENARIO_CHORUS": "7: Chorus scenario. Suitable for real-time chorus with low latency and good network conditions."
      },
      {
        "AUDIO_SCENARIO_MEETING": "8: Meeting scenario, suitable for multi-person voice-focused meetings."
      },
      {
        "AUDIO_SCENARIO_AI_CLIENT": "10: AI conversation scenario. Only applicable for interaction with [Agora Conversational AI Engine](https://doc.shengwang.cn/doc/convoai/restful/landing-page)."
      },
      {
        "AUDIO_SCENARIO_NUM": "Number of enumerations."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiosessionoperationrestriction",
    "name": "AUDIO_SESSION_OPERATION_RESTRICTION",
    "description": "SDK operation permissions for Audio Session.",
    "parameters": [
      {
        "AUDIO_SESSION_OPERATION_RESTRICTION_NONE": "0: No restriction. SDK can modify the Audio Session."
      },
      {
        "AUDIO_SESSION_OPERATION_RESTRICTION_SET_CATEGORY": "1: SDK cannot change the Audio Session category."
      },
      {
        "AUDIO_SESSION_OPERATION_RESTRICTION_CONFIGURE_SESSION": "2: SDK cannot change the Audio Session's category, mode, or categoryOptions."
      },
      {
        "AUDIO_SESSION_OPERATION_RESTRICTION_DEACTIVATE_SESSION": "4: When leaving the channel, SDK keeps the Audio Session active, e.g., for background audio playback."
      },
      {
        "AUDIO_SESSION_OPERATION_RESTRICTION_ALL": "128: Fully restricts SDK from modifying Audio Session. SDK can no longer make any changes."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiosourcetype",
    "name": "AUDIO_SOURCE_TYPE",
    "description": "Audio source type.",
    "parameters": [
      {
        "AUDIO_SOURCE_MICROPHONE": "0: (Default) Microphone."
      },
      {
        "AUDIO_SOURCE_CUSTOM": "1: Custom captured audio stream."
      },
      {
        "AUDIO_SOURCE_MEDIA_PLAYER": "2: Media player."
      },
      {
        "AUDIO_SOURCE_LOOPBACK_RECORDING": "3: System audio stream captured during screen sharing."
      },
      {
        "AUDIO_SOURCE_REMOTE_USER": "5: Audio stream from a specified remote user."
      },
      {
        "AUDIO_SOURCE_REMOTE_CHANNEL": "6: Mixed audio stream of all audio in the current channel."
      },
      {
        "AUDIO_SOURCE_UNKNOWN": "100: Unknown audio source."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_audiotracktype",
    "name": "AUDIO_TRACK_TYPE",
    "description": "Type of custom audio capture track.",
    "parameters": [
      {
        "AUDIO_TRACK_MIXABLE": "0: Mixable audio track. Supports mixing with other audio streams (e.g., microphone audio) before playing locally or publishing to the channel. Higher latency compared to non-mixable tracks."
      },
      {
        "AUDIO_TRACK_DIRECT": "1: Non-mixable audio track. Replaces microphone capture and does not support mixing with other audio streams. Lower latency compared to mixable tracks. If AUDIO_TRACK_DIRECT is specified, you must set publishMicrophoneTrack to false in ChannelMediaOptions when calling JoinChannel [2/2]; otherwise, joining the channel fails and returns error code -2."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_backgroundblurdegree",
    "name": "BACKGROUND_BLUR_DEGREE",
    "description": "Blur level of the custom background image.",
    "parameters": [
      {
        "BLUR_DEGREE_LOW": "1: Low blur level for the custom background image. The background is still somewhat visible to the user."
      },
      {
        "BLUR_DEGREE_MEDIUM": "2: Medium blur level for the custom background image. The background is harder to distinguish."
      },
      {
        "BLUR_DEGREE_HIGH": "3: (Default) High blur level for the custom background image. The background is barely visible."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_backgroundsourcetype",
    "name": "BACKGROUND_SOURCE_TYPE",
    "description": "Custom background.",
    "parameters": [
      {
        "BACKGROUND_NONE": "0: Process the background as Alpha data without replacement, only segmenting the portrait and background. After setting this, you can call StartLocalVideoTranscoder to achieve a picture-in-picture effect for the portrait."
      },
      {
        "BACKGROUND_COLOR": "1: (Default) The background is a solid color."
      },
      {
        "BACKGROUND_IMG": "2: The background is an image in PNG or JPG format."
      },
      {
        "BACKGROUND_BLUR": "3: The background is a blurred version of the original background."
      },
      {
        "BACKGROUND_VIDEO": "4: The background is a local video in MP4, AVI, MKV, FLV, or similar formats."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_bitrate",
    "name": "BITRATE",
    "description": "Video encoding bitrate.",
    "parameters": [
      {
        "STANDARD_BITRATE": "0: (Default) Standard bitrate mode."
      },
      {
        "COMPATIBLE_BITRATE": "-1: Compatible bitrate mode."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_cameradirection",
    "name": "CAMERA_DIRECTION",
    "description": "Camera direction.",
    "parameters": [
      {
        "CAMERA_REAR": "0: Rear camera."
      },
      {
        "CAMERA_FRONT": "1: (Default) Front camera."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_camerafocallengthtype",
    "name": "CAMERA_FOCAL_LENGTH_TYPE",
    "description": "Camera focal length type.\n\n(Android and iOS only)",
    "parameters": [
      {
        "CAMERA_FOCAL_LENGTH_DEFAULT": "0: (Default) Standard lens."
      },
      {
        "CAMERA_FOCAL_LENGTH_WIDE_ANGLE": "1: Wide-angle lens."
      },
      {
        "CAMERA_FOCAL_LENGTH_ULTRA_WIDE": "2: Ultra wide-angle lens."
      },
      {
        "CAMERA_FOCAL_LENGTH_TELEPHOTO": "3: (iOS only) Telephoto lens."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_camerastabilizationmode",
    "name": "CAMERA_STABILIZATION_MODE",
    "description": "Camera stabilization mode.\n\nCamera stabilization effect increases in the order of 1 < 2 < 3, with corresponding increase in latency.",
    "parameters": [
      {
        "CAMERA_STABILIZATION_MODE_OFF": "-1: (Default) Camera stabilization is off."
      },
      {
        "CAMERA_STABILIZATION_MODE_AUTO": "0: Camera auto stabilization. The system automatically selects a stabilization mode based on the camera status. However, this mode has higher latency and is not recommended."
      },
      {
        "CAMERA_STABILIZATION_MODE_LEVEL_1": "1: (Recommended) Camera stabilization level 1."
      },
      {
        "CAMERA_STABILIZATION_MODE_LEVEL_2": "2: Camera stabilization level 2."
      },
      {
        "CAMERA_STABILIZATION_MODE_LEVEL_3": "3: Camera stabilization level 3."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_capturebrightnessleveltype",
    "name": "CAPTURE_BRIGHTNESS_LEVEL_TYPE",
    "description": "Brightness level of locally captured video quality.",
    "parameters": [
      {
        "CAPTURE_BRIGHTNESS_LEVEL_INVALID": "-1: SDK has not detected the brightness level of the locally captured video. Please wait a few seconds and get the brightness level from the next captureBrightnessLevel callback."
      },
      {
        "CAPTURE_BRIGHTNESS_LEVEL_NORMAL": "0: Normal brightness level of locally captured video."
      },
      {
        "CAPTURE_BRIGHTNESS_LEVEL_BRIGHT": "1: Locally captured video is too bright."
      },
      {
        "CAPTURE_BRIGHTNESS_LEVEL_DARK": "2: Locally captured video is too dark."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_channelmediarelayerror",
    "name": "CHANNEL_MEDIA_RELAY_ERROR",
    "description": "Error codes for cross-channel media stream relay failures.",
    "parameters": [
      {
        "RELAY_OK": "0: Everything works fine."
      },
      {
        "RELAY_ERROR_SERVER_ERROR_RESPONSE": "1: Server returned an error."
      },
      {
        "RELAY_ERROR_SERVER_NO_RESPONSE": "2: No response from server.\nThis error may be caused by poor network conditions. If this error is reported when initiating cross-channel media relay, you can try again later; if it occurs during the relay, you can call the LeaveChannel [2/2] method to leave the channel.\nIt may also be caused by the current App ID not having cross-channel relay enabled. You can [contact technical support](https://ticket.shengwang.cn/) to request enabling it."
      },
      {
        "RELAY_ERROR_NO_RESOURCE_AVAILABLE": "3: SDK cannot acquire the service, possibly due to limited server resources."
      },
      {
        "RELAY_ERROR_FAILED_JOIN_SRC": "4: Failed to initiate cross-channel media stream relay request."
      },
      {
        "RELAY_ERROR_FAILED_JOIN_DEST": "5: Failed to accept cross-channel media stream relay request."
      },
      {
        "RELAY_ERROR_FAILED_PACKET_RECEIVED_FROM_SRC": "6: Server failed to receive cross-channel media stream."
      },
      {
        "RELAY_ERROR_FAILED_PACKET_SENT_TO_DEST": "7: Server failed to send cross-channel media stream."
      },
      {
        "RELAY_ERROR_SERVER_CONNECTION_LOST": "8: SDK disconnected from the server due to poor network quality. You can call the LeaveChannel [2/2] method to leave the current channel."
      },
      {
        "RELAY_ERROR_INTERNAL_ERROR": "9: Internal server error."
      },
      {
        "RELAY_ERROR_SRC_TOKEN_EXPIRED": "10: The token for the source channel has expired."
      },
      {
        "RELAY_ERROR_DEST_TOKEN_EXPIRED": "11: The token for the destination channel has expired."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_channelmediarelaystate",
    "name": "CHANNEL_MEDIA_RELAY_STATE",
    "description": "Status codes for cross-channel media stream relay.",
    "parameters": [
      {
        "RELAY_STATE_IDLE": "0: Initial state. After successfully calling StopChannelMediaRelay to stop the relay, OnChannelMediaRelayStateChanged will callback this state."
      },
      {
        "RELAY_STATE_CONNECTING": "1: SDK is attempting cross-channel connection."
      },
      {
        "RELAY_STATE_RUNNING": "2: The broadcaster in the source channel has successfully joined the destination channel."
      },
      {
        "RELAY_STATE_FAILURE": "3: An error occurred. See the code parameter in OnChannelMediaRelayStateChanged for error details."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_channelprofiletype",
    "name": "CHANNEL_PROFILE_TYPE",
    "description": "Channel profile.",
    "parameters": [
      {
        "CHANNEL_PROFILE_COMMUNICATION": "0: Communication profile. Agora recommends using the live broadcasting profile for better audio and video experience."
      },
      {
        "CHANNEL_PROFILE_LIVE_BROADCASTING": "1: (Default) Live broadcasting profile."
      },
      {
        "CHANNEL_PROFILE_GAME": "2: Gaming profile. Deprecated: Use CHANNEL_PROFILE_LIVE_BROADCASTING instead."
      },
      {
        "CHANNEL_PROFILE_CLOUD_GAMING": "3: Interactive profile. This profile is optimized for low latency. If your scenario involves frequent user interaction, it is recommended. Deprecated: Use CHANNEL_PROFILE_LIVE_BROADCASTING instead."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_clientrolechangefailedreason",
    "name": "CLIENT_ROLE_CHANGE_FAILED_REASON",
    "description": "Reasons for user role switch failure.",
    "parameters": [
      {
        "CLIENT_ROLE_CHANGE_FAILED_TOO_MANY_BROADCASTERS": "1: The number of broadcasters in the channel has reached the limit. This enum is only reported when the 128-user feature is enabled. The limit depends on the actual configuration when enabling the feature."
      },
      {
        "CLIENT_ROLE_CHANGE_FAILED_NOT_AUTHORIZED": "2: Request was rejected by the server. It is recommended to prompt the user to try switching roles again."
      },
      {
        "CLIENT_ROLE_CHANGE_FAILED_REQUEST_TIME_OUT": "3: Request timed out. It is recommended to prompt the user to check the network connection and try switching roles again. Deprecated: This enum value is deprecated since v4.4.0 and is not recommended for use."
      },
      {
        "CLIENT_ROLE_CHANGE_FAILED_CONNECTION_FAILED": "4: Network connection lost. You can troubleshoot the specific reason based on the reason reported by OnConnectionStateChanged. Deprecated: This enum value is deprecated since v4.4.0 and is not recommended for use."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_clientroletype",
    "name": "CLIENT_ROLE_TYPE",
    "description": "User roles in live broadcasting profile.",
    "parameters": [
      {
        "CLIENT_ROLE_BROADCASTER": "1: Broadcaster. A broadcaster can both send and receive streams."
      },
      {
        "CLIENT_ROLE_AUDIENCE": "2: (Default) Audience. An audience can only receive streams but not send."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_cloudproxytype",
    "name": "CLOUD_PROXY_TYPE",
    "description": "Cloud proxy type.",
    "parameters": [
      {
        "NONE_PROXY": "0: Automatic mode. This is the default mode. In this mode, the SDK first connects to SD-RTNâ„¢. If it fails, it automatically switches to TLS 443."
      },
      {
        "UDP_PROXY": "1: UDP protocol cloud proxy, i.e., Force UDP mode. In this mode, the SDK always transmits data via UDP."
      },
      {
        "TCP_PROXY": "2: TCP (encrypted) protocol cloud proxy, i.e., Force TCP mode. In this mode, the SDK always transmits data via TLS 443."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_codeccapmask",
    "name": "CODEC_CAP_MASK",
    "description": "Codec type bit mask.",
    "parameters": [
      {
        "CODEC_CAP_MASK_NONE": "(0): Codec not supported."
      },
      {
        "CODEC_CAP_MASK_HW_DEC": "(1 << 0): Supports hardware decoding."
      },
      {
        "CODEC_CAP_MASK_HW_ENC": "(1 << 1): Supports hardware encoding."
      },
      {
        "CODEC_CAP_MASK_SW_DEC": "(1 << 2): Supports software decoding."
      },
      {
        "CODEC_CAP_MASK_SW_ENC": "(1 << 3): Supports software encoding."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_compressionpreference",
    "name": "COMPRESSION_PREFERENCE",
    "description": "Compression preference type for video encoding.",
    "parameters": [
      {
        "PREFER_COMPRESSION_AUTO": "-1: (Default) Auto mode. The SDK automatically selects PREFER_LOW_LATENCY or PREFER_QUALITY based on your video scenario settings to provide the best user experience."
      },
      {
        "PREFER_LOW_LATENCY": "0: Low latency preference. The SDK compresses video frames to reduce latency. This is suitable for scenarios where smoothness is prioritized over quality."
      },
      {
        "PREFER_QUALITY": "1: High quality preference. The SDK compresses video frames while maintaining video quality. This is suitable for scenarios where video quality is prioritized."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_connectionchangedreasontype",
    "name": "CONNECTION_CHANGED_REASON_TYPE",
    "description": "Reason for network connection state change.",
    "parameters": [
      {
        "CONNECTION_CHANGED_CONNECTING": "0: Establishing network connection."
      },
      {
        "CONNECTION_CHANGED_JOIN_SUCCESS": "1: Successfully joined the channel."
      },
      {
        "CONNECTION_CHANGED_INTERRUPTED": "2: Network connection interrupted."
      },
      {
        "CONNECTION_CHANGED_BANNED_BY_SERVER": "3: Network connection is banned by the server. For example, this status is returned when the user is kicked out of the channel."
      },
      {
        "CONNECTION_CHANGED_JOIN_FAILED": "4: Failed to join the channel. If the SDK fails to join the channel after trying for 20 minutes, this status is returned and it stops attempting to reconnect. Prompt the user to switch networks and try joining the channel again."
      },
      {
        "CONNECTION_CHANGED_LEAVE_CHANNEL": "5: Left the channel."
      },
      {
        "CONNECTION_CHANGED_INVALID_APP_ID": "6: Invalid App ID. Use a valid App ID to rejoin the channel and ensure the App ID matches the one generated in the Agora Console."
      },
      {
        "CONNECTION_CHANGED_INVALID_CHANNEL_NAME": "7: Invalid channel name. Use a valid channel name to rejoin the channel. A valid channel name is a string within 64 bytes. The supported character set includes 89 characters:"
      },
      {
        "CONNECTION_CHANGED_INVALID_TOKEN": "8: Invalid Token. Possible reasons:\n Your project has App Certificate enabled but you joined the channel without using a Token.\n The user ID specified in JoinChannel [2/2] does not match the one used to generate the Token.\n The generated Token does not match the one used to join the channel. Ensure that:\n When App Certificate is enabled, use Token to join the channel.\n The user ID used to generate the Token matches the one used to join the channel.\n The generated Token matches the one used to join the channel."
      },
      {
        "CONNECTION_CHANGED_TOKEN_EXPIRED": "9: The current Token has expired. Generate a new Token on your server and use it to rejoin the channel."
      },
      {
        "CONNECTION_CHANGED_REJECTED_BY_SERVER": "10: This user is banned by the server. Possible reasons:\n The user already joined the channel and calls the join channel API again, such as JoinChannel [2/2]. Stop calling this method.\n The user tries to join the channel during a call test. Wait until the test ends before joining the channel."
      },
      {
        "CONNECTION_CHANGED_SETTING_PROXY_SERVER": "11: SDK attempts to reconnect due to proxy server settings."
      },
      {
        "CONNECTION_CHANGED_RENEW_TOKEN": "12: Network connection status changed due to Token renewal."
      },
      {
        "CONNECTION_CHANGED_CLIENT_IP_ADDRESS_CHANGED": "13: Client IP address changed. If this status is received multiple times, prompt the user to switch networks and try joining the channel again."
      },
      {
        "CONNECTION_CHANGED_KEEP_ALIVE_TIMEOUT": "14: Keep-alive timeout between SDK and server, entering auto-reconnect state."
      },
      {
        "CONNECTION_CHANGED_REJOIN_SUCCESS": "15: Successfully rejoined the channel."
      },
      {
        "CONNECTION_CHANGED_LOST": "16: SDK lost connection with the server."
      },
      {
        "CONNECTION_CHANGED_ECHO_TEST": "17: Connection state changed due to echo test."
      },
      {
        "CONNECTION_CHANGED_CLIENT_IP_ADDRESS_CHANGED_BY_USER": "18: Local IP address changed by user."
      },
      {
        "CONNECTION_CHANGED_SAME_UID_LOGIN": "19: The same UID joined the same channel from a different device."
      },
      {
        "CONNECTION_CHANGED_TOO_MANY_BROADCASTERS": "20: The number of broadcasters in the channel has reached the limit."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_connectionstatetype",
    "name": "CONNECTION_STATE_TYPE",
    "description": "Network connection state.",
    "parameters": [
      {
        "CONNECTION_STATE_DISCONNECTED": "1: Network disconnected. This state indicates the SDK is:\n In the initialization phase before calling JoinChannel [2/2].\n Or in the leave phase after calling LeaveChannel [2/2]."
      },
      {
        "CONNECTION_STATE_CONNECTING": "2: Connecting to the network. This state indicates the SDK is establishing a connection to the specified channel after calling JoinChannel [2/2].\n If the channel is joined successfully, the app receives the OnConnectionStateChanged callback indicating the state changes to CONNECTION_STATE_CONNECTED.\n After the connection is established, the SDK initializes media and then triggers OnJoinChannelSuccess when ready."
      },
      {
        "CONNECTION_STATE_CONNECTED": "3: Network connected. This state indicates the user has joined the channel and can publish or subscribe to media streams. If the connection is interrupted due to network issues or switching, the SDK automatically reconnects. The app receives the OnConnectionStateChanged callback indicating the state changes to CONNECTION_STATE_RECONNECTING."
      },
      {
        "CONNECTION_STATE_RECONNECTING": "4: Reconnecting to the network. This state indicates the SDK had previously joined the channel but got disconnected due to network issues. The SDK automatically attempts to rejoin the channel.\n If the SDK fails to rejoin within 10 seconds, OnConnectionLost is triggered. The SDK remains in CONNECTION_STATE_RECONNECTING and keeps trying to rejoin.\n If the SDK fails to rejoin within 20 minutes, the app receives the OnConnectionStateChanged callback indicating the state changes to CONNECTION_STATE_FAILED, and the SDK stops trying to reconnect."
      },
      {
        "CONNECTION_STATE_FAILED": "5: Network connection failed. This state indicates the SDK has stopped trying to rejoin the channel. You need to call LeaveChannel [1/2] to leave the channel.\n If the user wants to rejoin, call JoinChannel [2/2] again.\n If the SDK is prevented from joining by the server using RESTful API, the app receives OnConnectionStateChanged."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_contentinspecttype",
    "name": "CONTENT_INSPECT_TYPE",
    "description": "Type of video content inspection module.",
    "parameters": [
      {
        "CONTENT_INSPECT_INVALID": "0: (Default) This module has no actual function. Do not set type to this value."
      },
      {
        "CONTENT_INSPECT_SUPERVISION": "2: Uses Agora's proprietary plugin for screenshot and upload. The SDK captures and uploads screenshots of the video stream."
      },
      {
        "CONTENT_INSPECT_IMAGE_MODERATION": "3: Uses cloud marketplace plugin for screenshot and upload. The SDK uses the cloud marketplace video moderation plugin to capture and upload screenshots of the video stream."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_degradationpreference",
    "name": "DEGRADATION_PREFERENCE",
    "description": "Video encoding degradation preference when bandwidth is limited.",
    "parameters": [
      {
        "MAINTAIN_AUTO": "-1: (Default) Auto mode. The SDK automatically selects MAINTAIN_FRAMERATE, MAINTAIN_BALANCED, or MAINTAIN_RESOLUTION based on your video scenario to achieve optimal overall quality experience (QoE)."
      },
      {
        "MAINTAIN_QUALITY": "0: When bandwidth is limited, video encoding prioritizes reducing frame rate while maintaining resolution. This preference is suitable for scenarios prioritizing image quality. Deprecated: This enumeration is deprecated. Use other enumerations instead."
      },
      {
        "MAINTAIN_FRAMERATE": "1: When bandwidth is limited, video encoding prioritizes reducing resolution while maintaining frame rate. This preference suits scenarios prioritizing smoothness and tolerating reduced image quality."
      },
      {
        "MAINTAIN_BALANCED": "2: When bandwidth is limited, video encoding reduces both frame rate and resolution. The degradation level of MAINTAIN_BALANCED is lower than that of MAINTAIN_QUALITY and MAINTAIN_FRAMERATE, suitable for scenarios with limited smoothness and image quality. The resolution of the locally sent video may change. Remote users must be able to handle this. See OnVideoSizeChanged."
      },
      {
        "MAINTAIN_RESOLUTION": "3: When bandwidth is limited, video encoding prioritizes reducing frame rate while keeping resolution unchanged. This preference is suitable for scenarios prioritizing image quality."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_directcdnstreamingreason",
    "name": "DIRECT_CDN_STREAMING_REASON",
    "description": "Reason for change in CDN streaming status.\n\nDeprecated Deprecated since v4.6.2.",
    "parameters": [
      {
        "DIRECT_CDN_STREAMING_REASON_OK": "0: Streaming status is normal."
      },
      {
        "DIRECT_CDN_STREAMING_REASON_FAILED": "1: General error with no specific reason. You may try restarting the stream."
      },
      {
        "DIRECT_CDN_STREAMING_REASON_AUDIO_PUBLICATION": "2: Audio streaming error. For example, local audio capture device not working properly, occupied by another process, or lacking permission."
      },
      {
        "DIRECT_CDN_STREAMING_REASON_VIDEO_PUBLICATION": "3: Video streaming error. For example, local video capture device not working properly, occupied by another process, or lacking permission."
      },
      {
        "DIRECT_CDN_STREAMING_REASON_NET_CONNECT": "4: Failed to connect to CDN."
      },
      {
        "DIRECT_CDN_STREAMING_REASON_BAD_NAME": "5: The URL has already been used for streaming. Please use a new URL."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_directcdnstreamingstate",
    "name": "DIRECT_CDN_STREAMING_STATE",
    "description": "Current CDN streaming state.\n\nDeprecated Deprecated since v4.6.2.",
    "parameters": [
      {
        "DIRECT_CDN_STREAMING_STATE_IDLE": "0: Initial state, streaming has not started yet."
      },
      {
        "DIRECT_CDN_STREAMING_STATE_RUNNING": "1: Streaming in progress. When you call StartDirectCdnStreaming and streaming starts successfully, the SDK returns this value."
      },
      {
        "DIRECT_CDN_STREAMING_STATE_STOPPED": "2: Streaming has ended normally. When you call StopDirectCdnStreaming to stop streaming manually, the SDK returns this value."
      },
      {
        "DIRECT_CDN_STREAMING_STATE_FAILED": "3: Streaming failed. You can troubleshoot using the information reported by the OnDirectCdnStreamingStateChanged callback and then restart streaming."
      },
      {
        "DIRECT_CDN_STREAMING_STATE_RECOVERING": "4: Attempting to reconnect to the Agora server and CDN. It retries up to 10 times. If reconnection still fails, the streaming state changes to DIRECT_CDN_STREAMING_STATE_FAILED."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_earmonitoringfiltertype",
    "name": "EAR_MONITORING_FILTER_TYPE",
    "description": "Ear monitoring audio filter type.",
    "parameters": [
      {
        "EAR_MONITORING_FILTER_NONE": "1<<0: Do not add audio filters in ear monitoring."
      },
      {
        "EAR_MONITORING_FILTER_BUILT_IN_AUDIO_FILTERS": "1<<1: Add vocal effect audio filters in ear monitoring. If you implement features like voice beautification or sound effects, users can hear the processed sound in ear monitoring."
      },
      {
        "EAR_MONITORING_FILTER_NOISE_SUPPRESSION": "1<<2: Add noise suppression audio filters in ear monitoring."
      },
      {
        "EAR_MONITORING_FILTER_REUSE_POST_PROCESSING_FILTER": "1<<15: Reuse audio filters that have already been applied on the sending side. Reusing filters reduces CPU usage for ear monitoring but increases latency, suitable for scenarios where lower CPU usage is preferred and latency is not critical."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_encodingpreference",
    "name": "ENCODING_PREFERENCE",
    "description": "Video encoder preference.",
    "parameters": [
      {
        "PREFER_AUTO": "-1: Adaptive preference. The SDK automatically selects the optimal encoder based on platform, device type, and other factors."
      },
      {
        "PREFER_SOFTWARE": "0: Software encoder preference. The SDK prioritizes using a software encoder for video encoding."
      },
      {
        "PREFER_HARDWARE": "1: Hardware encoder preference. The SDK prioritizes using a hardware encoder for video encoding. If the device does not support hardware encoding, the SDK automatically falls back to software encoding and reports the encoder type used via the hwEncoderAccelerating field in the OnLocalVideoStats callback."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_encryptionerrortype",
    "name": "ENCRYPTION_ERROR_TYPE",
    "description": "Error types for built-in encryption.",
    "parameters": [
      {
        "ENCRYPTION_ERROR_INTERNAL_FAILURE": "0: Internal error."
      },
      {
        "ENCRYPTION_ERROR_DECRYPTION_FAILURE": "1: Media stream decryption error. Make sure the encryption mode or key used by the receiver and sender are the same."
      },
      {
        "ENCRYPTION_ERROR_ENCRYPTION_FAILURE": "2: Media stream encryption error."
      },
      {
        "ENCRYPTION_ERROR_DATASTREAM_DECRYPTION_FAILURE": "3: Data stream decryption error. Make sure the encryption mode or key used by the receiver and sender are the same."
      },
      {
        "ENCRYPTION_ERROR_DATASTREAM_ENCRYPTION_FAILURE": "4: Data stream encryption error."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_encryptionmode",
    "name": "ENCRYPTION_MODE",
    "description": "Built-in encryption modes.\n\nIt is recommended to use AES_128_GCM2 or AES_256_GCM2 encryption modes. These modes support salt, providing higher security.",
    "parameters": [
      {
        "AES_128_XTS": "1: 128-bit AES encryption, XTS mode."
      },
      {
        "AES_128_ECB": "2: 128-bit AES encryption, ECB mode."
      },
      {
        "AES_256_XTS": "3: 256-bit AES encryption, XTS mode."
      },
      {
        "SM4_128_ECB": "4: 128-bit SM4 encryption, ECB mode."
      },
      {
        "AES_128_GCM": "5: 128-bit AES encryption, GCM mode."
      },
      {
        "AES_256_GCM": "6: 256-bit AES encryption, GCM mode."
      },
      {
        "AES_128_GCM2": "7: (Default) 128-bit AES encryption, GCM mode. This encryption mode requires setting a salt (encryptionKdfSalt)."
      },
      {
        "AES_256_GCM2": "8: 256-bit AES encryption, GCM mode. This encryption mode requires setting a salt (encryptionKdfSalt)."
      },
      {
        "MODE_END": "Enum boundary value."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_errorcode",
    "name": "ErrorCode",
    "description": "Error codes. See https://docs.agora.io/en/Interactive%20Broadcast/error_rtc.",
    "parameters": [],
    "returns": ""
  },
  {
    "id": "enum_errorcodetype",
    "name": "ERROR_CODE_TYPE",
    "description": "Error codes.\n\nError codes indicate that the SDK has encountered an unrecoverable error and requires intervention from the application. For example, an error is returned when the camera fails to open, and the app needs to notify the user that the camera cannot be used.",
    "parameters": [
      {
        "ERR_OK": "0: No error."
      },
      {
        "ERR_FAILED": "1: A general error (no specific classification of the cause). Please try calling the method again."
      },
      {
        "ERR_INVALID_ARGUMENT": "2: Invalid parameter set in the method. For example, the specified channel name contains illegal characters. Please reset the parameters."
      },
      {
        "ERR_NOT_READY": "3: SDK is not ready. Possible reasons include: IRtcEngine initialization failed. Please reinitialize IRtcEngine.\n User has not joined the channel when calling the method. Please check the method call logic.\n User has not left the channel when calling Rate or Complain. Please check the method call logic.\n Audio module is not enabled.\n Incomplete assembly."
      },
      {
        "ERR_NOT_SUPPORTED": "4: The current state of IRtcEngine does not support the operation. Possible reasons include:\n When using built-in encryption, the encryption mode is incorrect, or loading the external encryption library failed. Please check whether the encryption enum value is correct or reload the external encryption library."
      },
      {
        "ERR_REFUSED": "5: This method call was rejected. Possible reasons include: IRtcEngine initialization failed. Please reinitialize IRtcEngine.\n Channel name is set to an empty string \"\" when joining the channel. Please reset the channel name.\n In multi-channel scenarios, the specified channel name already exists when calling JoinChannelEx. Please reset the channel name."
      },
      {
        "ERR_BUFFER_TOO_SMALL": "6: Buffer size is insufficient to hold the returned data."
      },
      {
        "ERR_NOT_INITIALIZED": "7: IRtcEngine method called before initialization. Please ensure that the IRtcEngine object is created and initialized before calling the method."
      },
      {
        "ERR_INVALID_STATE": "8: Invalid current state."
      },
      {
        "ERR_NO_PERMISSION": "9: No permission to operate. Please check whether the user has granted the app permission to use audio and video devices."
      },
      {
        "ERR_TIMEDOUT": "10: Method call timed out. Some method calls require a result from the SDK. If the SDK takes too long (over 10 seconds) to respond, this error occurs."
      },
      {
        "ERR_JOIN_CHANNEL_REJECTED": "17: Join channel request rejected. Possible reasons include:\n User is already in the channel. It is recommended to use the OnConnectionStateChanged callback to determine whether the user is in the channel. Do not call this method again to join the channel unless receiving CONNECTION_STATE_DISCONNECTED (1).\n After calling StartEchoTest for a call test, the user tries to join a channel without first calling StopEchoTest to end the test. You must call StopEchoTest before joining a channel."
      },
      {
        "ERR_LEAVE_CHANNEL_REJECTED": "18: Failed to leave the channel. Possible reasons include:\n User has already left the channel before calling LeaveChannel [2/2]. You can stop calling this method.\n User has not joined the channel but calls LeaveChannel [2/2]. No additional action is required in this case."
      },
      {
        "ERR_ALREADY_IN_USE": "19: Resource already in use and cannot be reused."
      },
      {
        "ERR_ABORTED": "20: SDK aborted the request, possibly due to too many requests."
      },
      {
        "ERR_INIT_NET_ENGINE": "21: On Windows, specific firewall settings cause IRtcEngine initialization to fail and crash."
      },
      {
        "ERR_RESOURCE_LIMITED": "22: SDK failed to allocate resources, possibly due to excessive app resource usage or system resource exhaustion."
      },
      {
        "ERR_INVALID_APP_ID": "101: Invalid App ID. Please use a valid App ID to rejoin the channel."
      },
      {
        "ERR_INVALID_CHANNEL_NAME": "102: Invalid channel name. Possible reason is incorrect data type of the parameter. Please use a valid channel name to rejoin the channel."
      },
      {
        "ERR_NO_SERVER_RESOURCES": "103: Unable to acquire server resources in the current region. Try specifying a different region when initializing IRtcEngine."
      },
      {
        "ERR_TOKEN_EXPIRED": "109: The current Token has expired and is no longer valid. Please request a new Token from the server and call RenewToken to update it. Deprecated: This enum is deprecated. Use CONNECTION_CHANGED_TOKEN_EXPIRED (9) in the OnConnectionStateChanged callback instead."
      },
      {
        "ERR_INVALID_TOKEN": "Deprecated: This enum is deprecated. Use CONNECTION_CHANGED_INVALID_TOKEN (8) in the OnConnectionStateChanged callback instead. 110: Invalid Token. Possible reasons include:\n App certificate is enabled in the console, but App ID + Token authentication is not used. When the project enables the App certificate, Token authentication must be used.\n The uid field used to generate the Token does not match the uid used when the user joins the channel."
      },
      {
        "ERR_CONNECTION_INTERRUPTED": "111: Network connection interrupted. SDK lost connection for more than 4 seconds after establishing a connection with the server."
      },
      {
        "ERR_CONNECTION_LOST": "112: Network connection lost. Connection interrupted and SDK fails to reconnect to the server within 10 seconds."
      },
      {
        "ERR_NOT_IN_CHANNEL": "113: User is not in the channel when calling SendStreamMessage."
      },
      {
        "ERR_SIZE_TOO_LARGE": "114: Data length exceeds 1 KB when calling SendStreamMessage."
      },
      {
        "ERR_BITRATE_LIMIT": "115: Data sending frequency exceeds the limit (6 KB/s) when calling SendStreamMessage."
      },
      {
        "ERR_TOO_MANY_DATA_STREAMS": "116: Number of data streams exceeds the limit (5) when calling CreateDataStream [2/2]."
      },
      {
        "ERR_STREAM_MESSAGE_TIMEOUT": "117: Data stream sending timed out."
      },
      {
        "ERR_SET_CLIENT_ROLE_NOT_AUTHORIZED": "119: Failed to switch user role. Please try rejoining the channel."
      },
      {
        "ERR_DECRYPTION_FAILED": "120: Media stream decryption failed. Possibly due to incorrect key used when joining the channel. Please check the key entered when joining or guide the user to rejoin the channel."
      },
      {
        "ERR_INVALID_USER_ID": "121: Invalid user ID."
      },
      {
        "ERR_DATASTREAM_DECRYPTION_FAILED": "122: Data stream decryption failed. Possibly due to incorrect key used when joining the channel. Please check the key entered when joining or guide the user to rejoin the channel."
      },
      {
        "ERR_CLIENT_IS_BANNED_BY_SERVER": "123: This user is banned by the server."
      },
      {
        "ERR_ENCRYPTED_STREAM_NOT_ALLOWED_PUBLISH": "130: SDK does not support publishing encrypted streams to CDN."
      },
      {
        "ERR_INVALID_USER_ACCOUNT": "134: Invalid user account, possibly due to invalid parameters."
      },
      {
        "ERR_LOAD_MEDIA_ENGINE": "1001: Failed to load media engine."
      },
      {
        "ERR_PCMSEND_FORMAT": "200: Unsupported PCM format."
      },
      {
        "ERR_PCMSEND_BUFFEROVERFLOW": "201: Buffer overflow due to PCM send rate being too fast."
      },
      {
        "ERR_ADM_GENERAL_ERROR": "1005: Audio device error (unspecified). Please check whether the audio device is occupied by another application or try rejoining the channel."
      },
      {
        "ERR_ADM_INIT_PLAYOUT": "1008: Error initializing playback device. Please check whether the playback device is occupied by another application or try rejoining the channel."
      },
      {
        "ERR_ADM_START_PLAYOUT": "1009: Error starting playback device. Please check whether the playback device is functioning properly."
      },
      {
        "ERR_ADM_STOP_PLAYOUT": "1010: Error stopping playback device."
      },
      {
        "ERR_ADM_INIT_RECORDING": "1011: Error initializing recording device. Please check whether the recording device is functioning properly or try rejoining the channel."
      },
      {
        "ERR_ADM_START_RECORDING": "1012: Error starting recording device. Please check whether the recording device is functioning properly."
      },
      {
        "ERR_ADM_STOP_RECORDING": "1013: Error stopping recording device."
      },
      {
        "ERR_VDM_CAMERA_NOT_AUTHORIZED": "1501: No permission to use the camera. Please check whether camera access is enabled."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_experiencepoorreason",
    "name": "EXPERIENCE_POOR_REASON",
    "description": "The reason for poor subjective experience quality of the local user when receiving remote audio.",
    "parameters": [
      {
        "EXPERIENCE_REASON_NONE": "0: No reason, indicating good subjective experience quality."
      },
      {
        "REMOTE_NETWORK_QUALITY_POOR": "1: Poor network quality of the remote user."
      },
      {
        "LOCAL_NETWORK_QUALITY_POOR": "2: Poor network quality of the local user."
      },
      {
        "WIRELESS_SIGNAL_POOR": "4: Weak Wi-Fi or mobile data signal of the local user."
      },
      {
        "WIFI_BLUETOOTH_COEXIST": "8: Wi-Fi and Bluetooth are enabled simultaneously on the local device, causing signal interference and reduced audio transmission quality."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_experiencequalitytype",
    "name": "EXPERIENCE_QUALITY_TYPE",
    "description": "The subjective experience quality of the local user when receiving remote audio.",
    "parameters": [
      {
        "EXPERIENCE_QUALITY_GOOD": "0: Good subjective experience quality."
      },
      {
        "EXPERIENCE_QUALITY_BAD": "1: Poor subjective experience quality."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_externalvideosourcetype",
    "name": "EXTERNAL_VIDEO_SOURCE_TYPE",
    "description": "Encoding type of external video frames.",
    "parameters": [
      {
        "VIDEO_FRAME": "0: Unencoded video frame."
      },
      {
        "ENCODED_VIDEO_FRAME": "1: Encoded video frame."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_faceshapearea",
    "name": "FACE_SHAPE_AREA",
    "description": "Selects the specific facial area to be adjusted.\n\nSince Available since v4.4.0.",
    "parameters": [
      {
        "FACE_SHAPE_AREA_NONE": "(-1): Default value, indicates an invalid area, facial shaping effect is not applied."
      },
      {
        "FACE_SHAPE_AREA_HEADSCALE": "(100): Head area, used to achieve a smaller head effect. Value range is [0, 100], default is 50. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_FOREHEAD": "(101): Forehead area, used to adjust the hairline height. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_FACECONTOUR": "(102): Face contour area, used to achieve a slimming face effect. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_FACELENGTH": "(103): Face length area, used to elongate the face. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_FACEWIDTH": "(104): Face width area, used to achieve a narrower face effect. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_CHEEKBONE": "(105): Cheekbone area, used to adjust cheekbone width. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_CHEEK": "(106): Cheek area, used to adjust cheek width. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_MANDIBLE": "(107): Mandible area, used to adjust mandible width. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_CHIN": "(108): Chin area, used to adjust chin length. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_EYESCALE": "(200): Eye area, used to achieve a big eye effect. Value range is [0, 100], default is 50. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_EYEDISTANCE": "(201): Eye distance area, used to adjust the distance between the eyes. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_EYEPOSITION": "(202): Eye position area, used to adjust the overall eye position. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_LOWEREYELID": "(203): Lower eyelid area, used to adjust the shape of the lower eyelid. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_EYEPUPILS": "(204): Pupil area, used to adjust pupil size. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_EYEINNERCORNER": "(205): Inner eye corner area, used to adjust the shape of the inner eye corner. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_EYEOUTERCORNER": "(206): Outer eye corner area, used to adjust the shape of the outer eye corner. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_NOSELENGTH": "(300): Nose length area, used to elongate the nose. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_NOSEWIDTH": "(301): Nose width area, used to achieve a slimmer nose effect. Value range is [0, 100], default is 0. The larger the value, the more obvious the slimming effect."
      },
      {
        "FACE_SHAPE_AREA_NOSEWING": "(302): Nose wing area, used to adjust the width of the nose wings. Value range is [0, 100], default is 10. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_NOSEROOT": "(303): Nose root area, used to adjust the height of the nose root. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_NOSEBRIDGE": "(304): Nose bridge area, used to adjust the height of the nose bridge. Value range is [0, 100], default is 50. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_NOSETIP": "(305): Nose tip area, used to adjust the shape of the nose tip. Value range is [0, 100], default is 50. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_NOSEGENERAL": "(306): Overall nose area, used to uniformly adjust nose shape. Value range is [-100, 100], default is 50. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_MOUTHSCALE": "(400): Mouth area, used to achieve a larger mouth effect. Value range is [-100, 100], default is 20. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_MOUTHPOSITION": "(401): Mouth position area, used to adjust the overall mouth position. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_MOUTHSMILE": "(402): Mouth smile area, used to adjust the upward curve of the mouth corners. Value range is [0, 1], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_MOUTHLIP": "(403): Lip shape area, used to adjust the shape of the lips. Value range is [0, 100], default is 0. The larger the value, the more obvious the adjustment."
      },
      {
        "FACE_SHAPE_AREA_EYEBROWPOSITION": "(500): Eyebrow position area, used to adjust the overall position of the eyebrows. Value range is [-100, 100], default is 0. The greater the absolute value, the more obvious the adjustment. Negative values indicate the opposite direction."
      },
      {
        "FACE_SHAPE_AREA_EYEBROWTHICKNESS": "(501): Eyebrow thickness area, used to adjust the thickness of the eyebrows. Value range is [-100, 100], default is 0. The larger the value, the more obvious the adjustment."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_faceshapebeautystyle",
    "name": "FACE_SHAPE_BEAUTY_STYLE",
    "description": "Face shape beauty style effect options.\n\nSince Available since v4.4.0.",
    "parameters": [
      {
        "FACE_SHAPE_BEAUTY_STYLE_FEMALE": "(0): (Default) Female style beauty effect."
      },
      {
        "FACE_SHAPE_BEAUTY_STYLE_MALE": "(1): Male style beauty effect."
      },
      {
        "FACE_SHAPE_BEAUTY_STYLE_NATURAL": "(2): Natural style beauty effect, only minimal adjustments to facial features."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_featuretype",
    "name": "FeatureType",
    "description": "Advanced feature types.",
    "parameters": [
      {
        "VIDEO_VIRTUAL_BACKGROUND": "1: Virtual background feature."
      },
      {
        "VIDEO_BEAUTY_EFFECT": "2: Beauty effect feature."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_framerate",
    "name": "FRAME_RATE",
    "description": "Video frame rate.",
    "parameters": [
      {
        "FRAME_RATE_FPS_1": "1: 1 fps."
      },
      {
        "FRAME_RATE_FPS_7": "7: 7 fps."
      },
      {
        "FRAME_RATE_FPS_10": "10: 10 fps."
      },
      {
        "FRAME_RATE_FPS_15": "15: 15 fps."
      },
      {
        "FRAME_RATE_FPS_24": "24: 24 fps."
      },
      {
        "FRAME_RATE_FPS_30": "30: 30 fps."
      },
      {
        "FRAME_RATE_FPS_60": "60: 60 fps. (Windows and macOS only)"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_headphoneequalizerpreset",
    "name": "HEADPHONE_EQUALIZER_PRESET",
    "description": "Preset headphone equalizer types.",
    "parameters": [
      {
        "HEADPHONE_EQUALIZER_OFF": "Turn off headphone equalizer and listen to original audio."
      },
      {
        "HEADPHONE_EQUALIZER_OVEREAR": "Use equalizer for over-ear headphones."
      },
      {
        "HEADPHONE_EQUALIZER_INEAR": "Use equalizer for in-ear headphones."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_lastmileproberesultstate",
    "name": "LASTMILE_PROBE_RESULT_STATE",
    "description": "Status of the last mile probe result.",
    "parameters": [
      {
        "LASTMILE_PROBE_RESULT_COMPLETE": "1: Indicates the result of the last mile probe is complete."
      },
      {
        "LASTMILE_PROBE_RESULT_INCOMPLETE_NO_BWE": "2: Indicates the last mile probe did not perform bandwidth estimation, so the result is incomplete. One possible reason is temporarily limited testing resources."
      },
      {
        "LASTMILE_PROBE_RESULT_UNAVAILABLE": "3: Last mile probe was not performed. One possible reason is network disconnection."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_lighteningcontrastlevel",
    "name": "LIGHTENING_CONTRAST_LEVEL",
    "description": "Brightness contrast level.",
    "parameters": [
      {
        "LIGHTENING_CONTRAST_LOW": "0: Low contrast."
      },
      {
        "LIGHTENING_CONTRAST_NORMAL": "1: Normal contrast."
      },
      {
        "LIGHTENING_CONTRAST_HIGH": "2: High contrast."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_localaudiostreamreason",
    "name": "LOCAL_AUDIO_STREAM_REASON",
    "description": "Reason for local audio state change.",
    "parameters": [
      {
        "LOCAL_AUDIO_STREAM_REASON_OK": "0: Local audio state is normal."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_FAILURE": "1: Local audio error with unknown reason. Suggest prompting the user to rejoin the channel."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_DEVICE_NO_PERMISSION": "2: No permission to start local audio capture device. Prompt the user to grant permission. Deprecated: This enum is obsolete. Use OnPermissionError callback with RECORD_AUDIO instead."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_DEVICE_BUSY": "3: (Android and iOS only) Local audio capture device is in use. Prompt the user to check if the microphone is occupied by another app. Local audio capture will automatically resume after the microphone is idle for about 5 seconds, or you can try rejoining the channel after it becomes idle."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_RECORD_FAILURE": "4: Failed to capture local audio."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_ENCODE_FAILURE": "5: Failed to encode local audio."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_NO_RECORDING_DEVICE": "6: (Windows and macOS only) No local audio capture device. Prompt the user to check if the microphone is properly connected and working in the device control panel."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_NO_PLAYOUT_DEVICE": "7: (Windows and macOS only) No local audio playback device. Prompt the user to check if the speaker is properly connected and working in the device control panel."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_INTERRUPTED": "8: (Android and iOS only) Local audio capture was interrupted by incoming calls, voice assistants, or alarms. To resume local audio capture, ask the user to end the call, assistant, or alarm."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_RECORD_INVALID_ID": "9: (Windows only) Invalid ID of the local audio capture device. Prompt the user to check the audio capture device ID."
      },
      {
        "LOCAL_AUDIO_STREAM_REASON_PLAYOUT_INVALID_ID": "10: (Windows only) Invalid ID of the local audio playback device. Prompt the user to check the audio playback device ID."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_localaudiostreamstate",
    "name": "LOCAL_AUDIO_STREAM_STATE",
    "description": "Local audio state.",
    "parameters": [
      {
        "LOCAL_AUDIO_STREAM_STATE_STOPPED": "0: Default initial state of local audio."
      },
      {
        "LOCAL_AUDIO_STREAM_STATE_RECORDING": "1: Local audio capture device started successfully."
      },
      {
        "LOCAL_AUDIO_STREAM_STATE_ENCODING": "2: First frame of local audio encoded successfully."
      },
      {
        "LOCAL_AUDIO_STREAM_STATE_FAILED": "3: Failed to start local audio."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_localvideoeventtype",
    "name": "LOCAL_VIDEO_EVENT_TYPE",
    "description": "Local video event types.\n\nSince Available since v4.6.1.",
    "parameters": [
      {
        "LOCAL_VIDEO_EVENT_TYPE_SCREEN_CAPTURE_WINDOW_HIDDEN": "(1): The screen capture window is hidden (Android only)."
      },
      {
        "LOCAL_VIDEO_EVENT_TYPE_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN": "(2): The screen capture window recovers from hidden state (Android only)."
      },
      {
        "LOCAL_VIDEO_EVENT_TYPE_SCREEN_CAPTURE_STOPPED_BY_USER": "(3): Screen capture is stopped by the user (Android only)."
      },
      {
        "LOCAL_VIDEO_EVENT_TYPE_SCREEN_CAPTURE_SYSTEM_INTERNAL_ERROR": "(4): A system internal error occurred during screen capture (Android only)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_localvideostreamreason",
    "name": "LOCAL_VIDEO_STREAM_REASON",
    "description": "Reason for local video state change.",
    "parameters": [
      {
        "LOCAL_VIDEO_STREAM_REASON_OK": "0: Local video is in normal state."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_FAILURE": "1: Unknown error."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_NO_PERMISSION": "2: No permission to start the local video capture device. Prompt the user to enable device permissions and rejoin the channel. Deprecated: This enumeration is deprecated. Use OnPermissionError callback with CAMERA instead."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_BUSY": "3: The local video capture device is in use. Prompt the user to check if the camera is occupied by another app or try rejoining the channel."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_CAPTURE_FAILURE": "4: Local video capture failed. Prompt the user to check if the video capture device is working properly, whether the camera is occupied by another app, or try rejoining the channel."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_CODEC_NOT_SUPPORT": "5: Local video encoding failed."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_CAPTURE_INBACKGROUND": "6: (iOS only) The app is in the background. Prompt the user that video capture cannot proceed when the app is in the background."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_CAPTURE_MULTIPLE_FOREGROUND_APPS": "7: (iOS only) The app window is in Slide Over, Split View, or Picture-in-Picture mode, and another app is using the camera. Prompt the user that video capture cannot proceed in this case."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_NOT_FOUND": "8: Local video capture device not found. Check whether the camera is properly connected and functioning, or try rejoining the channel."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_DISCONNECTED": "9: (macOS and Windows only) The video capture device in use has been disconnected (e.g., unplugged)."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_INVALID_ID": "10: (macOS and Windows only) The SDK cannot find the video device in the list. Check whether the video device ID is valid."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_MINIMIZED": "11: (macOS and Windows only) The window shared via StartScreenCaptureByWindowId is minimized. The SDK cannot share minimized windows. Prompt the user to restore the window."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_CLOSED": "12: (macOS and Windows only) The window shared via window ID is closed, or a fullscreen window shared via window ID has exited fullscreen. After exiting fullscreen, remote users cannot see the shared window. To avoid showing a black screen, it is recommended to end the sharing immediately.\nCommon scenarios for this error code:\n The local user closes the shared window.\n The local user plays a slideshow and shares it; when the slideshow ends, the SDK reports this error.\n The local user watches a web video or document in fullscreen, then shares it; when exiting fullscreen, the SDK reports this error."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_OCCLUDED": "13: (Windows only) The window to be shared is blocked by another window. The blocked area will be blacked out during sharing."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_INTERRUPT": "14: (Android only) Video capture interrupted. Possible reasons:\n The camera is occupied by another app. Prompt the user to check if the camera is in use.\n The app has been switched to the background. Use a foreground service notification to ensure video capture continues in the background. See [Why does audio/video capture fail when the app is locked or in the background on some Android versions?](https://doc.shengwang.cn/faq/quality-issues/android-background)."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_FATAL_ERROR": "15: (Android only) Video capture device error. Prompt the user to turn off and restart the camera to restore functionality. If the issue persists, check for hardware faults."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_FAILURE": "21: (Windows and Android only) The current captured window has no data."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_NO_PERMISSION": "22: (Windows and macOS only) No permission to capture the screen."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_AUTO_FALLBACK": "24: (Windows only) An unexpected error occurred during screen sharing (possibly due to window exclusion failure), causing the screen sharing strategy to downgrade, but the sharing itself is not affected. During screen sharing, if window exclusion fails due to device driver issues, the SDK reports this event and automatically falls back to sharing the entire screen. If your scenario requires excluding specific windows for privacy, listen for this event and add additional privacy protection mechanisms when triggered."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_HIDDEN": "25: (Windows only) The window being captured is hidden and not visible on the current screen."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_HIDDEN": "26: (Windows only) The window being captured has recovered from a hidden state."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_WINDOW_RECOVER_FROM_MINIMIZED": "27: (macOS and Windows only) The window being captured has recovered from a minimized state."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_PAUSED": "28: (Windows only) Screen capture is paused. Common scenario: the current screen may have switched to a secure desktop, such as a UAC dialog or Winlogon desktop."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_RESUMED": "29: (Windows only) Screen capture has resumed from a paused state."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_DISPLAY_DISCONNECTED": "30: (Windows and macOS only) The display being captured has been disconnected. Prompt the user that screen sharing is paused and restart sharing."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_SCREEN_CAPTURE_EXCLUDE_WINDOW_FAILED": "34: (Windows only) Some windows in the exclusion list failed to be excluded during screen sharing."
      },
      {
        "LOCAL_VIDEO_STREAM_REASON_DEVICE_SYSTEM_PRESSURE": "101: The video capture device is unavailable due to excessive system pressure."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_localvideostreamstate",
    "name": "LOCAL_VIDEO_STREAM_STATE",
    "description": "Local video state.",
    "parameters": [
      {
        "LOCAL_VIDEO_STREAM_STATE_STOPPED": "0: Default initial state of local video."
      },
      {
        "LOCAL_VIDEO_STREAM_STATE_CAPTURING": "1: Local video capture device started successfully. This state is also reported when sharing a maximized window via StartScreenCaptureByWindowId."
      },
      {
        "LOCAL_VIDEO_STREAM_STATE_ENCODING": "2: First frame of local video encoded successfully."
      },
      {
        "LOCAL_VIDEO_STREAM_STATE_FAILED": "3: Failed to start local video."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_loglevel",
    "name": "LOG_LEVEL",
    "description": "Log output level.",
    "parameters": [
      {
        "LOG_LEVEL_NONE": "0: Do not output any logs."
      },
      {
        "LOG_LEVEL_INFO": "0x0001: (Default) Output logs at FATAL, ERROR, WARN, and INFO levels. It is recommended to set the log level to this value."
      },
      {
        "LOG_LEVEL_WARN": "0x0002: Output only FATAL, ERROR, and WARN level logs."
      },
      {
        "LOG_LEVEL_ERROR": "0x0004: Output only FATAL and ERROR level logs."
      },
      {
        "LOG_LEVEL_FATAL": "0x0008: Output only FATAL level logs."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_lowlightenhancelevel",
    "name": "LOW_LIGHT_ENHANCE_LEVEL",
    "description": "Low-light enhancement level.",
    "parameters": [
      {
        "LOW_LIGHT_ENHANCE_LEVEL_HIGH_QUALITY": "0: (Default) Low-light enhancement prioritizing image quality. It processes brightness, details, and noise in the video image. It has moderate performance consumption and processing speed, offering optimal overall quality."
      },
      {
        "LOW_LIGHT_ENHANCE_LEVEL_FAST": "1: Low-light enhancement prioritizing performance. It processes brightness and details in the video image with lower performance consumption and faster processing speed."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_lowlightenhancemode",
    "name": "LOW_LIGHT_ENHANCE_MODE",
    "description": "Low-light enhancement mode.",
    "parameters": [
      {
        "LOW_LIGHT_ENHANCE_AUTO": "0: (Default) Auto mode. The SDK automatically enables or disables the low-light enhancement feature based on ambient brightness to provide appropriate lighting and prevent overexposure."
      },
      {
        "LOW_LIGHT_ENHANCE_MANUAL": "1: Manual mode. Users need to manually enable or disable the low-light enhancement feature."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_maxuseraccountlengthtype",
    "name": "MAX_USER_ACCOUNT_LENGTH_TYPE",
    "description": "Maximum length of the user account.",
    "parameters": [
      {
        "MAX_USER_ACCOUNT_LENGTH": "The maximum length of the user account is 255 characters."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediadevicestatetype",
    "name": "MEDIA_DEVICE_STATE_TYPE",
    "description": "Device state.",
    "parameters": [
      {
        "MEDIA_DEVICE_STATE_IDLE": "0: Device is ready."
      },
      {
        "MEDIA_DEVICE_STATE_ACTIVE": "1: Device is in use."
      },
      {
        "MEDIA_DEVICE_STATE_DISABLED": "2: Device is disabled."
      },
      {
        "MEDIA_DEVICE_STATE_PLUGGED_IN": "3: Device is plugged in."
      },
      {
        "MEDIA_DEVICE_STATE_NOT_PRESENT": "4: Device not present."
      },
      {
        "MEDIA_DEVICE_STATE_UNPLUGGED": "8: Device is unplugged."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediadevicetype",
    "name": "MEDIA_DEVICE_TYPE",
    "description": "Device type.",
    "parameters": [
      {
        "UNKNOWN_AUDIO_DEVICE": "-1: Unknown device type."
      },
      {
        "AUDIO_PLAYOUT_DEVICE": "0: Audio playback device."
      },
      {
        "AUDIO_RECORDING_DEVICE": "1: Audio recording device."
      },
      {
        "VIDEO_RENDER_DEVICE": "2: Video rendering device (graphics card)."
      },
      {
        "VIDEO_CAPTURE_DEVICE": "3: Video capture device."
      },
      {
        "AUDIO_APPLICATION_PLAYOUT_DEVICE": "4: Audio application playback device."
      },
      {
        "AUDIO_VIRTUAL_PLAYOUT_DEVICE": "(macOS only) 5: Virtual audio playback device (virtual sound card)."
      },
      {
        "AUDIO_VIRTUAL_RECORDING_DEVICE": "(macOS only) 6: Virtual audio recording device (virtual sound card)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediaplayerevent",
    "name": "MEDIA_PLAYER_EVENT",
    "description": "Media player events.",
    "parameters": [
      {
        "PLAYER_EVENT_SEEK_BEGIN": "0: Start seeking."
      },
      {
        "PLAYER_EVENT_SEEK_COMPLETE": "1: Seek completed."
      },
      {
        "PLAYER_EVENT_SEEK_ERROR": "2: Seek error."
      },
      {
        "PLAYER_EVENT_AUDIO_TRACK_CHANGED": "5: Current audio track changed."
      },
      {
        "PLAYER_EVENT_BUFFER_LOW": "6: Current buffered data is insufficient for playback."
      },
      {
        "PLAYER_EVENT_BUFFER_RECOVER": "7: Current buffered data is just enough for playback."
      },
      {
        "PLAYER_EVENT_FREEZE_START": "8: Audio or video stutter occurred."
      },
      {
        "PLAYER_EVENT_FREEZE_STOP": "9: Audio and video stutter stopped."
      },
      {
        "PLAYER_EVENT_SWITCH_BEGIN": "10: Start switching media source."
      },
      {
        "PLAYER_EVENT_SWITCH_COMPLETE": "11: Media source switch completed."
      },
      {
        "PLAYER_EVENT_SWITCH_ERROR": "12: Media source switch error."
      },
      {
        "PLAYER_EVENT_FIRST_DISPLAYED": "13: First video frame displayed."
      },
      {
        "PLAYER_EVENT_REACH_CACHE_FILE_MAX_COUNT": "14: Reached maximum number of cacheable files."
      },
      {
        "PLAYER_EVENT_REACH_CACHE_FILE_MAX_SIZE": "15: Reached maximum size of cacheable files."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediaplayermetadatatype",
    "name": "MEDIA_PLAYER_METADATA_TYPE",
    "description": "Media metadata type.",
    "parameters": [
      {
        "PLAYER_METADATA_TYPE_UNKNOWN": "0: Unknown type."
      },
      {
        "PLAYER_METADATA_TYPE_SEI": "1: SEI (Supplemental Enhancement Information) type."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediaplayerreason",
    "name": "MEDIA_PLAYER_REASON",
    "description": "Reason for media player state change.",
    "parameters": [
      {
        "PLAYER_REASON_NONE": "0: No error."
      },
      {
        "PLAYER_REASON_INVALID_ARGUMENTS": "-1: Invalid parameters."
      },
      {
        "PLAYER_REASON_INTERNAL": "-2: Internal error."
      },
      {
        "PLAYER_REASON_NO_RESOURCE": "-3: No resource."
      },
      {
        "PLAYER_REASON_INVALID_MEDIA_SOURCE": "-4: Invalid resource."
      },
      {
        "PLAYER_REASON_UNKNOWN_STREAM_TYPE": "-5: Unknown media stream type."
      },
      {
        "PLAYER_REASON_OBJ_NOT_INITIALIZED": "-6: Object not initialized."
      },
      {
        "PLAYER_REASON_CODEC_NOT_SUPPORTED": "-7: Codec not supported by decoder."
      },
      {
        "PLAYER_REASON_VIDEO_RENDER_FAILED": "-8: Invalid renderer."
      },
      {
        "PLAYER_REASON_INVALID_STATE": "-9: Invalid internal player state."
      },
      {
        "PLAYER_REASON_URL_NOT_FOUND": "-10: URL not found."
      },
      {
        "PLAYER_REASON_INVALID_CONNECTION_STATE": "-11: Invalid connection between player and Agora server."
      },
      {
        "PLAYER_REASON_SRC_BUFFER_UNDERFLOW": "-12: Insufficient data in playback buffer."
      },
      {
        "PLAYER_REASON_INTERRUPTED": "-13: Playback was interrupted abnormally and ended."
      },
      {
        "PLAYER_REASON_NOT_SUPPORTED": "-14: API call not supported by SDK."
      },
      {
        "PLAYER_REASON_TOKEN_EXPIRED": "-15: Authentication information for media resource network path has expired."
      },
      {
        "PLAYER_REASON_UNKNOWN": "-17: Unknown error."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediaplayerstate",
    "name": "MEDIA_PLAYER_STATE",
    "description": "Media player state.",
    "parameters": [
      {
        "PLAYER_STATE_IDLE": "0: Default state. The player returns this state before you open a media file and after playback ends."
      },
      {
        "PLAYER_STATE_OPENING": "1: Opening media file."
      },
      {
        "PLAYER_STATE_OPEN_COMPLETED": "2: Media file opened successfully."
      },
      {
        "PLAYER_STATE_PLAYING": "3: Playing."
      },
      {
        "PLAYER_STATE_PAUSED": "4: Playback paused."
      },
      {
        "PLAYER_STATE_PLAYBACK_COMPLETED": "5: Playback completed."
      },
      {
        "PLAYER_STATE_PLAYBACK_ALL_LOOPS_COMPLETED": "6: All playback loops completed."
      },
      {
        "PLAYER_STATE_STOPPED": "7: Playback stopped."
      },
      {
        "PLAYER_STATE_FAILED": "100: Playback failed."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediasourcetype",
    "name": "MEDIA_SOURCE_TYPE",
    "description": "Media source type.",
    "parameters": [
      {
        "AUDIO_PLAYOUT_SOURCE": "0: Audio playback device."
      },
      {
        "AUDIO_RECORDING_SOURCE": "1: Audio recording device."
      },
      {
        "PRIMARY_CAMERA_SOURCE": "2: Primary camera."
      },
      {
        "SECONDARY_CAMERA_SOURCE": "3: Secondary camera."
      },
      {
        "CUSTOM_VIDEO_SOURCE": "6: Custom video capture source."
      },
      {
        "SPEECH_DRIVEN_VIDEO_SOURCE": "13: Video source processed by speech-driven plugin."
      },
      {
        "UNKNOWN_MEDIA_SOURCE": "100: Unknown media source."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediastreamtype",
    "name": "MEDIA_STREAM_TYPE",
    "description": "Media stream type.",
    "parameters": [
      {
        "STREAM_TYPE_UNKNOWN": "0: Unknown type."
      },
      {
        "STREAM_TYPE_VIDEO": "1: Video stream."
      },
      {
        "STREAM_TYPE_AUDIO": "2: Audio stream."
      },
      {
        "STREAM_TYPE_SUBTITLE": "3: Subtitle stream."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_mediatraceevent",
    "name": "MEDIA_TRACE_EVENT",
    "description": "Rendering status of media frames.",
    "parameters": [
      {
        "MEDIA_TRACE_EVENT_VIDEO_RENDERED": "0: Video frame has been rendered."
      },
      {
        "MEDIA_TRACE_EVENT_VIDEO_DECODED": "1: Video frame has been decoded."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_metadatatype",
    "name": "METADATA_TYPE",
    "description": "Metadata type for the observer. Currently only supports video metadata.",
    "parameters": [
      {
        "UNKNOWN_METADATA": "-1: Unknown metadata type."
      },
      {
        "VIDEO_METADATA": "0: Metadata type is video."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_multipathmode",
    "name": "MultipathMode",
    "description": "Modes for multipath data transmission.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "Duplicate": "(0): Redundant transmission mode. The same data is redundantly transmitted through all available paths."
      },
      {
        "Dynamic": "(1): Dynamic transmission mode. The SDK dynamically selects the optimal path for data transmission based on the current network conditions to improve performance."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_multipathtype",
    "name": "MultipathType",
    "description": "Network path types used for multipath transmission.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "LAN": "(0): Local Area Network (LAN) path."
      },
      {
        "WIFI": "(1): Wi-Fi path."
      },
      {
        "Mobile": "(2): Mobile network path."
      },
      {
        "Unknown": "(99): Unknown or unspecified network path."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_networktype",
    "name": "NETWORK_TYPE",
    "description": "Network connection type.",
    "parameters": [
      {
        "NETWORK_TYPE_UNKNOWN": "-1: Unknown network connection type."
      },
      {
        "NETWORK_TYPE_DISCONNECTED": "0: Network connection is disconnected."
      },
      {
        "NETWORK_TYPE_LAN": "1: Network type is LAN."
      },
      {
        "NETWORK_TYPE_WIFI": "2: Network type is Wi-Fi (including hotspot)."
      },
      {
        "NETWORK_TYPE_MOBILE_2G": "3: Network type is 2G mobile network."
      },
      {
        "NETWORK_TYPE_MOBILE_3G": "4: Network type is 3G mobile network."
      },
      {
        "NETWORK_TYPE_MOBILE_4G": "5: Network type is 4G mobile network."
      },
      {
        "NETWORK_TYPE_MOBILE_5G": "6: Network type is 5G mobile network."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_observermode",
    "name": "OBSERVER_MODE",
    "description": "Raw data callback mode.",
    "parameters": [
      {
        "RAW_DATA": "Callback in raw data mode."
      },
      {
        "INTPTR": "Callback with raw data pointer address."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_orientationmode",
    "name": "ORIENTATION_MODE",
    "description": "Video encoding orientation mode.",
    "parameters": [
      {
        "ORIENTATION_MODE_ADAPTIVE": "0: (Default) In this mode, the SDK outputs video with the same orientation as the captured video. The receiver rotates the video based on the rotation information. This mode is suitable when the receiver can adjust the video orientation.\n If the captured video is in landscape mode, the output video is also in landscape mode.\n If the captured video is in portrait mode, the output video is also in portrait mode."
      },
      {
        "ORIENTATION_MODE_FIXED_LANDSCAPE": "1: In this mode, the SDK outputs video in fixed landscape mode. If the captured video is in portrait mode, the video encoder crops it. This mode is suitable when the receiver cannot adjust the video orientation, such as in CDN streaming scenarios."
      },
      {
        "ORIENTATION_MODE_FIXED_PORTRAIT": "2: In this mode, the SDK outputs video in fixed portrait mode. If the captured video is in landscape mode, the video encoder crops it. This mode is suitable when the receiver cannot adjust the video orientation, such as in CDN streaming scenarios."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_permissiontype",
    "name": "PERMISSION_TYPE",
    "description": "Device permission types.",
    "parameters": [
      {
        "RECORD_AUDIO": "0: Permission for audio capture device."
      },
      {
        "CAMERA": "1: Camera permission."
      },
      {
        "SCREEN_CAPTURE": "(Android only) 2: Screen sharing permission."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_playerpreloadevent",
    "name": "PLAYER_PRELOAD_EVENT",
    "description": "Events during preloading of media resources.",
    "parameters": [
      {
        "PLAYER_PRELOAD_EVENT_BEGIN": "0: Start preloading media resource."
      },
      {
        "PLAYER_PRELOAD_EVENT_COMPLETE": "1: Media resource preload completed."
      },
      {
        "PLAYER_PRELOAD_EVENT_ERROR": "2: Error occurred during media resource preload."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_proxytype",
    "name": "PROXY_TYPE",
    "description": "Proxy types.",
    "parameters": [
      {
        "NONE_PROXY_TYPE": "0: Reserved parameter, not supported yet."
      },
      {
        "UDP_PROXY_TYPE": "1: Cloud proxy using UDP protocol, i.e., Force UDP cloud proxy mode. In this mode, the SDK always transmits data via UDP."
      },
      {
        "TCP_PROXY_TYPE": "2: Cloud proxy using TCP (encrypted) protocol, i.e., Force TCP cloud proxy mode. In this mode, the SDK always transmits data via TLS 443."
      },
      {
        "LOCAL_PROXY_TYPE": "3: Reserved parameter, not supported yet."
      },
      {
        "TCP_PROXY_AUTO_FALLBACK_TYPE": "4: Auto mode. In this mode, the SDK first attempts to connect to SD-RTNâ„¢. If it fails, it automatically switches to TLS 443."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_qualityadaptindication",
    "name": "QUALITY_ADAPT_INDICATION",
    "description": "Local video quality adaptation since last statistics (based on target frame rate and bitrate).",
    "parameters": [
      {
        "ADAPT_NONE": "0: Local video quality remains unchanged."
      },
      {
        "ADAPT_UP_BANDWIDTH": "1: Local video quality improves due to increased network bandwidth."
      },
      {
        "ADAPT_DOWN_BANDWIDTH": "2: Local video quality degrades due to decreased network bandwidth."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_qualitytype",
    "name": "QUALITY_TYPE",
    "description": "Network quality.",
    "parameters": [
      {
        "QUALITY_UNKNOWN": "0: Network quality unknown."
      },
      {
        "QUALITY_EXCELLENT": "1: Excellent network quality."
      },
      {
        "QUALITY_GOOD": "2: Subjectively similar to excellent, but bitrate may be slightly lower."
      },
      {
        "QUALITY_POOR": "3: Slight issues in user experience but communication is not affected."
      },
      {
        "QUALITY_BAD": "4: Communication is possible but not smooth."
      },
      {
        "QUALITY_VBAD": "5: Very poor network quality, communication is barely possible."
      },
      {
        "QUALITY_DOWN": "6: Communication is not possible."
      },
      {
        "QUALITY_DETECTING": "8: Network quality detection in progress."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rawaudioframeopmodetype",
    "name": "RAW_AUDIO_FRAME_OP_MODE_TYPE",
    "description": "Usage mode of audio data.",
    "parameters": [
      {
        "RAW_AUDIO_FRAME_OP_MODE_READ_ONLY": "0: (Default) Read-only mode. For example, if you use the SDK to capture data and perform CDN streaming yourself, you can use this mode."
      },
      {
        "RAW_AUDIO_FRAME_OP_MODE_READ_WRITE": "2: Read-write mode. For example, if you have your own audio effects module and want to pre-process the data (e.g., voice changing), you can use this mode."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_recorderreasoncode",
    "name": "RecorderReasonCode",
    "description": "Reasons for recording state errors.",
    "parameters": [
      {
        "RECORDER_REASON_NONE": "0: Everything is normal."
      },
      {
        "RECORDER_REASON_WRITE_FAILED": "1: Failed to write to recording file."
      },
      {
        "RECORDER_REASON_NO_STREAM": "2: No audio/video stream to record or the stream was interrupted for more than 5 seconds."
      },
      {
        "RECORDER_REASON_OVER_MAX_DURATION": "3: Recording duration exceeds the maximum limit."
      },
      {
        "RECORDER_REASON_CONFIG_CHANGED": "4: Recording configuration changed."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_recorderstate",
    "name": "RecorderState",
    "description": "Current recording state.",
    "parameters": [
      {
        "RECORDER_STATE_ERROR": "-1: Audio/video stream recording error. See RecorderReasonCode."
      },
      {
        "RECORDER_STATE_START": "2: Audio/video stream recording starts."
      },
      {
        "RECORDER_STATE_STOP": "3: Audio/video stream recording stops."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_remoteaudiostate",
    "name": "REMOTE_AUDIO_STATE",
    "description": "Remote audio stream state.",
    "parameters": [
      {
        "REMOTE_AUDIO_STATE_STOPPED": "0: Default initial state of the remote audio. This state is reported under REMOTE_AUDIO_REASON_LOCAL_MUTED, REMOTE_AUDIO_REASON_REMOTE_MUTED, or REMOTE_AUDIO_REASON_REMOTE_OFFLINE."
      },
      {
        "REMOTE_AUDIO_STATE_STARTING": "1: The local user has received the first packet of the remote audio."
      },
      {
        "REMOTE_AUDIO_STATE_DECODING": "2: Remote audio stream is decoding and playing normally. This state is reported under REMOTE_AUDIO_REASON_NETWORK_RECOVERY, REMOTE_AUDIO_REASON_LOCAL_UNMUTED, or REMOTE_AUDIO_REASON_REMOTE_UNMUTED."
      },
      {
        "REMOTE_AUDIO_STATE_FROZEN": "3: Remote audio stream is frozen. This state is reported under REMOTE_AUDIO_REASON_NETWORK_CONGESTION."
      },
      {
        "REMOTE_AUDIO_STATE_FAILED": "4: Remote audio stream playback failed. This state is reported under REMOTE_AUDIO_REASON_INTERNAL."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_remoteaudiostatereason",
    "name": "REMOTE_AUDIO_STATE_REASON",
    "description": "Reason for remote audio stream state change.",
    "parameters": [
      {
        "REMOTE_AUDIO_REASON_INTERNAL": "0: This reason is reported when the audio state changes."
      },
      {
        "REMOTE_AUDIO_REASON_NETWORK_CONGESTION": "1: Network congestion."
      },
      {
        "REMOTE_AUDIO_REASON_NETWORK_RECOVERY": "2: Network recovered."
      },
      {
        "REMOTE_AUDIO_REASON_LOCAL_MUTED": "3: The local user stops receiving the remote audio stream or disables the audio module."
      },
      {
        "REMOTE_AUDIO_REASON_LOCAL_UNMUTED": "4: The local user resumes receiving the remote audio stream or enables the audio module."
      },
      {
        "REMOTE_AUDIO_REASON_REMOTE_MUTED": "5: The remote user stops sending the audio stream or disables the audio module."
      },
      {
        "REMOTE_AUDIO_REASON_REMOTE_UNMUTED": "6: The remote user resumes sending the audio stream or enables the audio module."
      },
      {
        "REMOTE_AUDIO_REASON_REMOTE_OFFLINE": "7: The remote user leaves the channel."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_remotevideostate",
    "name": "REMOTE_VIDEO_STATE",
    "description": "Remote video stream state.",
    "parameters": [
      {
        "REMOTE_VIDEO_STATE_STOPPED": "0: Default initial state of the remote video. This state is reported under REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED, REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED, or REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE."
      },
      {
        "REMOTE_VIDEO_STATE_STARTING": "1: The local user has received the first packet of the remote video."
      },
      {
        "REMOTE_VIDEO_STATE_DECODING": "2: Remote video stream is decoding and playing normally. This state is reported under REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY, REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED, REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED, or REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY."
      },
      {
        "REMOTE_VIDEO_STATE_FROZEN": "3: Remote video stream is frozen. This state is reported under REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION or REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK."
      },
      {
        "REMOTE_VIDEO_STATE_FAILED": "4: Remote video stream playback failed. This state is reported under REMOTE_VIDEO_STATE_REASON_INTERNAL."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_remotevideostatereason",
    "name": "REMOTE_VIDEO_STATE_REASON",
    "description": "Reason for remote video stream state change.",
    "parameters": [
      {
        "REMOTE_VIDEO_STATE_REASON_INTERNAL": "0: This reason is reported when the video state changes."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_NETWORK_CONGESTION": "1: Network congestion."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_NETWORK_RECOVERY": "2: Network recovered."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_LOCAL_MUTED": "3: The local user stops receiving the remote video stream or disables the video module."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_LOCAL_UNMUTED": "4: The local user resumes receiving the remote video stream or enables the video module."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_REMOTE_MUTED": "5: The remote user stops sending the video stream or disables the video module."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_REMOTE_UNMUTED": "6: The remote user resumes sending the video stream or enables the video module."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_REMOTE_OFFLINE": "7: The remote user leaves the channel."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK": "8: Under poor network conditions, the remote audio/video stream falls back to audio only."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_AUDIO_FALLBACK_RECOVERY": "9: When the network improves, the remote audio stream recovers to audio/video stream."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_SDK_IN_BACKGROUND": "12: (iOS only) The remote user's app has switched to the background."
      },
      {
        "REMOTE_VIDEO_STATE_REASON_CODEC_NOT_SUPPORT": "13: The local video decoder does not support decoding the received remote video stream."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rendermodetype",
    "name": "RENDER_MODE_TYPE",
    "description": "Video display mode.",
    "parameters": [
      {
        "RENDER_MODE_HIDDEN": "1: Video is scaled proportionally. Prioritizes filling the view. Excess video outside the view due to size mismatch is cropped."
      },
      {
        "RENDER_MODE_FIT": "2: Video is scaled proportionally. Prioritizes showing the entire video content. Black bars fill the unused view area due to size mismatch."
      },
      {
        "RENDER_MODE_ADAPTIVE": "3: Adaptive mode. Deprecated: This enum is deprecated and not recommended for use."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_renewtokenerrorcode",
    "name": "RENEW_TOKEN_ERROR_CODE",
    "description": "Error codes after calling renewToken.\n\nSince Available since 4.6.0.",
    "parameters": [
      {
        "RENEW_TOKEN_SUCCESS": "(0): Token updated successfully."
      },
      {
        "RENEW_TOKEN_FAILURE": "(1): Token update failed due to an unknown server error. It is recommended to check the parameters used to generate the Token, regenerate the Token, and retry renewToken."
      },
      {
        "RENEW_TOKEN_TOKEN_EXPIRED": "(2): Token update failed because the provided Token has expired. It is recommended to generate a new Token with a longer expiration time and retry renewToken."
      },
      {
        "RENEW_TOKEN_INVALID_TOKEN": "(3): Token update failed because the provided Token is invalid. Common causes include: the project has enabled App Certificate in the Agora Console but Token is not used when joining the channel; the uid specified in joinChannel is inconsistent with the one used to generate the Token; the channel name specified in joinChannel is inconsistent with the one used to generate the Token. It is recommended to check the Token generation process, regenerate the Token, and retry renewToken."
      },
      {
        "RENEW_TOKEN_INVALID_CHANNEL_NAME": "(4): Token update failed because the channel name in the Token is inconsistent with the current channel. It is recommended to check the channel name, regenerate the Token, and retry renewToken."
      },
      {
        "RENEW_TOKEN_INCONSISTENT_APPID": "(5): Token update failed because the App ID in the Token is inconsistent with the current App ID. It is recommended to check the App ID, regenerate the Token, and retry renewToken."
      },
      {
        "RENEW_TOKEN_CANCELED_BY_NEW_REQUEST": "(6): The previous Token update request was canceled due to a new request being initiated."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rhythmplayerreason",
    "name": "RHYTHM_PLAYER_REASON",
    "description": "Virtual metronome error information.",
    "parameters": [
      {
        "RHYTHM_PLAYER_REASON_OK": "0: The metronome audio file is playing normally without errors."
      },
      {
        "RHYTHM_PLAYER_REASON_FAILED": "1: General error with no specific cause."
      },
      {
        "RHYTHM_PLAYER_REASON_CAN_NOT_OPEN": "801: Error opening the metronome audio file."
      },
      {
        "RHYTHM_PLAYER_REASON_CAN_NOT_PLAY": "802: Error playing the metronome audio file."
      },
      {
        "RHYTHM_PLAYER_REASON_FILE_OVER_DURATION_LIMIT": "803: The duration of the metronome audio file exceeds the limit. The maximum duration is 1.2 seconds."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rhythmplayerstatetype",
    "name": "RHYTHM_PLAYER_STATE_TYPE",
    "description": "Virtual metronome state.",
    "parameters": [
      {
        "RHYTHM_PLAYER_STATE_IDLE": "810: The virtual metronome is not started or has been stopped."
      },
      {
        "RHYTHM_PLAYER_STATE_OPENING": "811: Opening the metronome audio file."
      },
      {
        "RHYTHM_PLAYER_STATE_DECODING": "812: Decoding the metronome audio file."
      },
      {
        "RHYTHM_PLAYER_STATE_PLAYING": "813: Playing the metronome audio file."
      },
      {
        "RHYTHM_PLAYER_STATE_FAILED": "814: Failed to start the virtual metronome. You can troubleshoot the issue using the reported error code errorCode, or try starting the virtual metronome again."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rtmpstreamingevent",
    "name": "RTMP_STREAMING_EVENT",
    "description": "Events that occur during relayed streaming.",
    "parameters": [
      {
        "RTMP_STREAMING_EVENT_FAILED_LOAD_IMAGE": "1: Error adding background image or watermark during relayed streaming."
      },
      {
        "RTMP_STREAMING_EVENT_URL_ALREADY_IN_USE": "2: The stream URL is already in use. If you want to start a new stream, please use a new stream URL."
      },
      {
        "RTMP_STREAMING_EVENT_ADVANCED_FEATURE_NOT_SUPPORT": "3: Feature not supported."
      },
      {
        "RTMP_STREAMING_EVENT_REQUEST_TOO_OFTEN": "4: Reserved parameter."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rtmpstreamlifecycletype",
    "name": "RTMP_STREAM_LIFE_CYCLE_TYPE",
    "description": "Lifecycle of server-side transcoding stream.\n\nDeprecated Deprecated",
    "parameters": [
      {
        "RTMP_STREAM_LIFE_CYCLE_BIND2CHANNEL": "Bound to the channel lifecycle. That is, when all hosts leave the channel, the server-side transcoding stream stops after 30 seconds."
      },
      {
        "RTMP_STREAM_LIFE_CYCLE_BIND2OWNER": "Bound to the lifecycle of the host who started the server-side transcoding stream. That is, when the host leaves, the server-side transcoding stream stops immediately."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rtmpstreampublishreason",
    "name": "RTMP_STREAM_PUBLISH_REASON",
    "description": "Reason for stream state change.",
    "parameters": [
      {
        "RTMP_STREAM_PUBLISH_REASON_OK": "0: Stream published successfully."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_INVALID_ARGUMENT": "1: Invalid parameters. Please check whether the input parameters are correct."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_ENCRYPTED_STREAM_NOT_ALLOWED": "2: The stream is encrypted and cannot be published."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_CONNECTION_TIMEOUT": "3: Stream publishing timed out and failed."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_INTERNAL_SERVER_ERROR": "4: An error occurred on the streaming server."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_RTMP_SERVER_ERROR": "5: An error occurred on the CDN server."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_TOO_OFTEN": "6: Streaming requests are too frequent."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_REACH_LIMIT": "7: The number of stream URLs for a single host has reached the limit of 10. Please delete some unused stream URLs before adding new ones."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_NOT_AUTHORIZED": "8: The host is operating on a stream that does not belong to them. For example, updating another host's stream parameters or stopping another host's stream. Please check your app logic."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_STREAM_NOT_FOUND": "9: The server could not find the stream."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_FORMAT_NOT_SUPPORTED": "10: The stream URL format is incorrect. Please check whether the stream URL format is correct."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_NOT_BROADCASTER": "11: The user role is not a broadcaster and cannot use the streaming function. Please check your application code logic."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_TRANSCODING_NO_MIX_STREAM": "13: Called the UpdateRtmpTranscoding method to update transcoding properties in a non-transcoding stream scenario. Please check your application code logic."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_NET_DOWN": "14: The host's network encountered an error."
      },
      {
        "RTMP_STREAM_PUBLISH_REASON_INVALID_PRIVILEGE": "16: Your project does not have permission to use the streaming service."
      },
      {
        "RTMP_STREAM_UNPUBLISH_REASON_OK": "100: Streaming ended normally. After you stop streaming, the SDK returns this value."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_rtmpstreampublishstate",
    "name": "RTMP_STREAM_PUBLISH_STATE",
    "description": "Streaming state.",
    "parameters": [
      {
        "RTMP_STREAM_PUBLISH_STATE_IDLE": "0: Streaming has not started or has ended."
      },
      {
        "RTMP_STREAM_PUBLISH_STATE_CONNECTING": "1: Connecting to the streaming server and CDN server."
      },
      {
        "RTMP_STREAM_PUBLISH_STATE_RUNNING": "2: Streaming is in progress. This state is returned after successful streaming."
      },
      {
        "RTMP_STREAM_PUBLISH_STATE_RECOVERING": "3: Recovering the stream. When a CDN exception occurs or the stream is briefly interrupted, the SDK automatically attempts to recover the stream and returns this state.\n If the stream is successfully recovered, it enters the RTMP_STREAM_PUBLISH_STATE_RUNNING(2) state.\n If the server encounters an error or recovery fails within 60 seconds, it enters the RTMP_STREAM_PUBLISH_STATE_FAILURE(4) state. If you think 60 seconds is too long, you can also try reconnecting manually."
      },
      {
        "RTMP_STREAM_PUBLISH_STATE_FAILURE": "4: Streaming failed. After failure, you can troubleshoot the cause using the returned error code."
      },
      {
        "RTMP_STREAM_PUBLISH_STATE_DISCONNECTING": "5: The SDK is disconnecting from the streaming server and CDN server. When you call the StopRtmpStream method to end streaming normally, the SDK reports the streaming states in sequence: RTMP_STREAM_PUBLISH_STATE_DISCONNECTING, RTMP_STREAM_PUBLISH_STATE_IDLE."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_screencaptureframeratecapability",
    "name": "SCREEN_CAPTURE_FRAMERATE_CAPABILITY",
    "description": "Maximum frame rate supported by the screen sharing device.",
    "parameters": [
      {
        "SCREEN_CAPTURE_FRAMERATE_CAPABILITY_15_FPS": "0: Supports up to 15 fps."
      },
      {
        "SCREEN_CAPTURE_FRAMERATE_CAPABILITY_30_FPS": "1: Supports up to 30 fps."
      },
      {
        "SCREEN_CAPTURE_FRAMERATE_CAPABILITY_60_FPS": "2: Supports up to 60 fps."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_screencapturesourcetype",
    "name": "ScreenCaptureSourceType",
    "description": "The type of capture target. Set in ScreenCaptureSourceInfo.",
    "parameters": [
      {
        "ScreenCaptureSourceType_Unknown": "-1: Unknown."
      },
      {
        "ScreenCaptureSourceType_Window": "0: The capture target is a specific window."
      },
      {
        "ScreenCaptureSourceType_Screen": "1: The capture target is the screen of a specific monitor."
      },
      {
        "ScreenCaptureSourceType_Custom": "2: Reserved parameter."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_screencolortype",
    "name": "SCREEN_COLOR_TYPE",
    "description": "Screen color types.",
    "parameters": [
      {
        "SCREEN_COLOR_AUTO": "(0): Automatically select screen color."
      },
      {
        "SCREEN_COLOR_GREEN": "(1): Green screen color."
      },
      {
        "SCREEN_COLOR_BLUE": "(2): Blue screen color."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_screenscenariotype",
    "name": "SCREEN_SCENARIO_TYPE",
    "description": "Screen sharing scenarios.",
    "parameters": [
      {
        "SCREEN_SCENARIO_DOCUMENT": "1: (Default) Document. In this scenario, the shared image quality is prioritized, and the latency for the receiving end to see the shared video is reduced. If you are sharing documents, slides, or spreadsheets, you can set this scenario."
      },
      {
        "SCREEN_SCENARIO_GAMING": "2: Gaming. In this scenario, the smoothness of the shared content is prioritized. If you are sharing games, you can set this scenario."
      },
      {
        "SCREEN_SCENARIO_VIDEO": "3: Video. In this scenario, the smoothness of the shared content is prioritized. If you are sharing movies or live videos, you can set this scenario."
      },
      {
        "SCREEN_SCENARIO_RDC": "4: Remote control. In this scenario, the shared image quality is prioritized, and the latency for the receiving end to see the shared video is reduced. If you are sharing the desktop of a remotely controlled device, you can set this scenario."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_segmodeltype",
    "name": "SEG_MODEL_TYPE",
    "description": "Algorithm for background processing.",
    "parameters": [
      {
        "SEG_MODEL_AI": "1: (Default) Background processing algorithm suitable for all scenarios."
      },
      {
        "SEG_MODEL_GREEN": "2: Background processing algorithm (green screen only)."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_simulcaststreammode",
    "name": "SIMULCAST_STREAM_MODE",
    "description": "Mode for sending video streams.",
    "parameters": [
      {
        "AUTO_SIMULCAST_STREAM": "-1: By default, small streams are not sent until a subscription request for a small stream is received from the receiver, at which point small streams are sent automatically."
      },
      {
        "DISABLE_SIMULCAST_STREAM": "0: Never send small streams."
      },
      {
        "ENABLE_SIMULCAST_STREAM": "1: Always send small streams."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_streamfallbackoptions",
    "name": "STREAM_FALLBACK_OPTIONS",
    "description": "Options for handling audio/video stream fallback under poor network conditions.",
    "parameters": [
      {
        "STREAM_FALLBACK_OPTION_DISABLED": "0: Do not apply fallback to audio/video streams, but the quality of the streams is not guaranteed."
      },
      {
        "STREAM_FALLBACK_OPTION_VIDEO_STREAM_LOW": "1: Receive only the low-quality video stream (low resolution, low bitrate)."
      },
      {
        "STREAM_FALLBACK_OPTION_AUDIO_ONLY": "2: Under poor network conditions, first attempt to receive only the low-quality video stream; if the network is too poor to display video, fallback to receiving only the subscribed audio stream."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_streampublishstate",
    "name": "STREAM_PUBLISH_STATE",
    "description": "Publish state.",
    "parameters": [
      {
        "PUB_STATE_IDLE": "0: Initial publish state after joining the channel."
      },
      {
        "PUB_STATE_NO_PUBLISHED": "1: Publish failed. Possible reasons:\n The local user called MuteLocalAudioStream (true) or MuteLocalVideoStream (true) to stop sending local media streams.\n The local user called DisableAudio or DisableVideo to disable the local audio or video module.\n The local user called EnableLocalAudio (false) or EnableLocalVideo (false) to disable local audio or video capture.\n The local user's role is audience."
      },
      {
        "PUB_STATE_PUBLISHING": "2: Publishing."
      },
      {
        "PUB_STATE_PUBLISHED": "3: Publish succeeded."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_streamsubscribestate",
    "name": "STREAM_SUBSCRIBE_STATE",
    "description": "Subscribe state.",
    "parameters": [
      {
        "SUB_STATE_IDLE": "0: Initial subscribe state after joining the channel."
      },
      {
        "SUB_STATE_NO_SUBSCRIBED": "1: Subscription failed. Possible reasons:\n Remote user:\n Called MuteLocalAudioStream (true) or MuteLocalVideoStream (true) to stop sending local media streams.\n Called DisableAudio or DisableVideo to disable the local audio or video module.\n Called EnableLocalAudio (false) or EnableLocalVideo (false) to disable local audio or video capture.\n User role is audience.\n Local user called the following methods to stop receiving remote media streams:\n Called MuteRemoteAudioStream (true), MuteAllRemoteAudioStreams (true) to stop receiving remote audio streams.\n Called MuteRemoteVideoStream (true), MuteAllRemoteVideoStreams (true) to stop receiving remote video streams."
      },
      {
        "SUB_STATE_SUBSCRIBING": "2: Subscribing."
      },
      {
        "SUB_STATE_SUBSCRIBED": "3: Remote stream received, subscription succeeded."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_userofflinereasontype",
    "name": "USER_OFFLINE_REASON_TYPE",
    "description": "Reason for user going offline.",
    "parameters": [
      {
        "USER_OFFLINE_QUIT": "0: User left voluntarily."
      },
      {
        "USER_OFFLINE_DROPPED": "1: Timed out due to not receiving packets from the peer for a long time. Since the SDK uses an unreliable channel, it is also possible that the peer left the channel voluntarily, but the local side did not receive the leave message and mistakenly judged it as a timeout."
      },
      {
        "USER_OFFLINE_BECOME_AUDIENCE": "2: The user's role switched from host to audience."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videoapplicationscenariotype",
    "name": "VIDEO_APPLICATION_SCENARIO_TYPE",
    "description": "Video application scenario types.",
    "parameters": [
      {
        "APPLICATION_SCENARIO_GENERAL": "0: (Default) General scenario."
      },
      {
        "APPLICATION_SCENARIO_MEETING": "1: Meeting scenario."
      },
      {
        "APPLICATION_SCENARIO_1V1": "2: 1v1 video call"
      },
      {
        "APPLICATION_SCENARIO_LIVESHOW": "3: Live show"
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videobuffertype",
    "name": "VIDEO_BUFFER_TYPE",
    "description": "Video buffer type.",
    "parameters": [
      {
        "VIDEO_BUFFER_RAW_DATA": "1: Type is raw data."
      },
      {
        "VIDEO_BUFFER_ARRAY": "2: Type is raw data."
      },
      {
        "VIDEO_BUFFER_TEXTURE": "3: Type is Texture."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videocodeccapabilitylevel",
    "name": "VIDEO_CODEC_CAPABILITY_LEVEL",
    "description": "Video codec capability level.",
    "parameters": [
      {
        "CODEC_CAPABILITY_LEVEL_UNSPECIFIED": "-1: Unsupported video type. Currently, only video in H.264 and H.265 formats is supported for querying. If the video is in another format, this value is returned."
      },
      {
        "CODEC_CAPABILITY_LEVEL_BASIC_SUPPORT": "5: Basic codec support, i.e., encoding and decoding for video up to 1080p and 30 fps."
      },
      {
        "CODEC_CAPABILITY_LEVEL_1080P30FPS": "10: Supports encoding and decoding video up to 1080p and 30 fps."
      },
      {
        "CODEC_CAPABILITY_LEVEL_1080P60FPS": "20: Supports encoding and decoding video up to 1080p and 60 fps."
      },
      {
        "CODEC_CAPABILITY_LEVEL_4K60FPS": "30: Supports encoding and decoding video up to 4K and 30 fps."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videocodecprofiletype",
    "name": "VIDEO_CODEC_PROFILE_TYPE",
    "description": "Codec profile type for video output in relayed streaming.",
    "parameters": [
      {
        "VIDEO_CODEC_PROFILE_BASELINE": "66: Baseline profile, typically used for lower-end or error-resilient applications such as video calls and mobile videos."
      },
      {
        "VIDEO_CODEC_PROFILE_MAIN": "77: Main profile, typically used in mainstream consumer electronics such as MP4, portable video players, PSP, iPad, etc."
      },
      {
        "VIDEO_CODEC_PROFILE_HIGH": "100: (Default) High profile, typically used in broadcasting, video disc storage, and HDTV."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videocodectype",
    "name": "VIDEO_CODEC_TYPE",
    "description": "Video codec format.",
    "parameters": [
      {
        "VIDEO_CODEC_NONE": "0: (Default) No specific codec format. The SDK automatically selects a suitable codec format based on the current video stream resolution and device performance."
      },
      {
        "VIDEO_CODEC_VP8": "1: Standard VP8."
      },
      {
        "VIDEO_CODEC_H264": "2: Standard H.264."
      },
      {
        "VIDEO_CODEC_H265": "3: Standard H.265."
      },
      {
        "VIDEO_CODEC_GENERIC": "6: Generic. This type is mainly used for transmitting raw video data (e.g., user-encrypted video frames). These frames are returned via callback and require you to decode and render them."
      },
      {
        "VIDEO_CODEC_GENERIC_JPEG": "20: Generic JPEG. Requires relatively low computational power and is suitable for IoT devices with limited resources."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videocodectypeforstream",
    "name": "VIDEO_CODEC_TYPE_FOR_STREAM",
    "description": "Codec type for transcoded video stream output.",
    "parameters": [
      {
        "VIDEO_CODEC_H264_FOR_STREAM": "1: (Default) H.264."
      },
      {
        "VIDEO_CODEC_H265_FOR_STREAM": "2: H.265."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videocontenthint",
    "name": "VIDEO_CONTENT_HINT",
    "description": "Content type for screen sharing.",
    "parameters": [
      {
        "CONTENT_HINT_NONE": "(Default) No specified content type."
      },
      {
        "CONTENT_HINT_MOTION": "Content type is motion. Recommended when sharing videos, movies, or video games."
      },
      {
        "CONTENT_HINT_DETAILS": "Content type is details. Recommended when sharing images or text."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videodenoiserlevel",
    "name": "VIDEO_DENOISER_LEVEL",
    "description": "Video denoising level.",
    "parameters": [
      {
        "VIDEO_DENOISER_LEVEL_HIGH_QUALITY": "0: (Default) Video denoising prioritizing image quality. This level balances performance consumption and denoising effect. It has moderate performance consumption and denoising speed, providing optimal overall quality."
      },
      {
        "VIDEO_DENOISER_LEVEL_FAST": "1: Video denoising prioritizing performance. This level focuses on saving performance in the balance between performance consumption and denoising effect. It consumes less performance and has faster denoising speed. To avoid noticeable ghosting in the processed video, it is recommended to use this setting when the camera is stationary."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videodenoisermode",
    "name": "VIDEO_DENOISER_MODE",
    "description": "Video denoising mode.",
    "parameters": [
      {
        "VIDEO_DENOISER_AUTO": "0: (Default) Auto mode. The SDK automatically enables or disables the video denoising feature based on ambient brightness."
      },
      {
        "VIDEO_DENOISER_MANUAL": "1: Manual mode. Users need to manually enable or disable the video denoising feature."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videoeffectaction",
    "name": "VIDEO_EFFECT_ACTION",
    "description": "Operation types performed on video effect nodes.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "SAVE": "(1): Save the current parameters of the video effect."
      },
      {
        "RESET": "(2): Reset the video effect to default parameters."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videoeffectnodeid",
    "name": "VIDEO_EFFECT_NODE_ID",
    "description": "Video effect node types.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "BEAUTY": "(1): Beauty effect node."
      },
      {
        "STYLE_MAKEUP": "(2): Style makeup effect node."
      },
      {
        "FILTER": "(4): Filter effect node."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videoframetype",
    "name": "VIDEO_FRAME_TYPE",
    "description": "Video frame type.",
    "parameters": [
      {
        "VIDEO_FRAME_TYPE_BLANK_FRAME": "0: Blank frame."
      },
      {
        "VIDEO_FRAME_TYPE_KEY_FRAME": "3: Key frame."
      },
      {
        "VIDEO_FRAME_TYPE_DELTA_FRAME": "4: Delta frame."
      },
      {
        "VIDEO_FRAME_TYPE_B_FRAME": "5: B frame."
      },
      {
        "VIDEO_FRAME_TYPE_DROPPABLE_FRAME": "6: Droppable frame."
      },
      {
        "VIDEO_FRAME_TYPE_UNKNOW": "Unknown frame."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videomirrormodetype",
    "name": "VIDEO_MIRROR_MODE_TYPE",
    "description": "Mirror mode type.",
    "parameters": [
      {
        "VIDEO_MIRROR_MODE_AUTO": "0: Mirror mode is determined by the SDK.\n Local view mirror mode: If you use the front camera, local view mirror mode is enabled by default; if you use the rear camera, it is disabled by default.\n Remote user view mirror mode: Disabled by default."
      },
      {
        "VIDEO_MIRROR_MODE_ENABLED": "1: Enable mirror mode."
      },
      {
        "VIDEO_MIRROR_MODE_DISABLED": "2: Disable mirror mode."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videomoduleposition",
    "name": "VIDEO_MODULE_POSITION",
    "description": "Video observation position.",
    "parameters": [
      {
        "POSITION_POST_CAPTURER": "1: Position after local video capture and preprocessing, corresponding to the OnCaptureVideoFrame callback. The observed video includes preprocessing effects, which can be verified by enabling beauty effects, virtual background, or watermark."
      },
      {
        "POSITION_PRE_RENDERER": "2: Position before rendering the received remote video, corresponding to the OnRenderVideoFrame callback."
      },
      {
        "POSITION_PRE_ENCODER": "4: Position before local video encoding, corresponding to the OnPreEncodeVideoFrame callback. The observed video includes preprocessing and pre-encoding effects:\n Preprocessing effects can be verified by enabling beauty effects, virtual background, or watermark.\n Pre-encoding effects can be verified by setting a low frame rate (e.g., 5 fps)."
      },
      {
        "POSITION_POST_CAPTURER_ORIGIN": "8: Position after local video capture and before preprocessing. The observed video does not include preprocessing effects, which can be verified by enabling beauty effects, virtual background, or watermark."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videoobserverframetype",
    "name": "VIDEO_OBSERVER_FRAME_TYPE",
    "description": "Raw video data types.",
    "parameters": [
      {
        "FRAME_TYPE_DEFAULT": "Raw video pixel format."
      },
      {
        "FRAME_TYPE_YUV420": "Video data in YUV420 format."
      },
      {
        "FRAME_TYPE_YUV422": "Video data in YUV422 format."
      },
      {
        "FRAME_TYPE_RGBA": "Video data in RGBA format."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videoorientation",
    "name": "VIDEO_ORIENTATION",
    "description": "Clockwise video rotation information.",
    "parameters": [
      {
        "VIDEO_ORIENTATION_0": "0: (Default) Rotated 0 degrees clockwise."
      },
      {
        "VIDEO_ORIENTATION_90": "90: Rotated 90 degrees clockwise."
      },
      {
        "VIDEO_ORIENTATION_180": "180: Rotated 180 degrees clockwise."
      },
      {
        "VIDEO_ORIENTATION_270": "270: Rotated 270 degrees clockwise."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videopixelformat",
    "name": "VIDEO_PIXEL_FORMAT",
    "description": "Video pixel formats.",
    "parameters": [
      {
        "VIDEO_PIXEL_DEFAULT": "0: Raw video pixel format."
      },
      {
        "VIDEO_PIXEL_I420": "1: I420 format."
      },
      {
        "VIDEO_PIXEL_RGBA": "4: RGBA format."
      },
      {
        "VIDEO_PIXEL_I422": "16: I422 format."
      },
      {
        "VIDEO_TEXTURE_ID3D11TEXTURE2D": "17: ID3D11TEXTURE2D format. Currently supported types include DXGI_FORMAT_B8G8R8A8_UNORM, DXGI_FORMAT_B8G8R8A8_TYPELESS, and DXGI_FORMAT_NV12."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videosourcetype",
    "name": "VIDEO_SOURCE_TYPE",
    "description": "Types of video sources.",
    "parameters": [
      {
        "VIDEO_SOURCE_CAMERA_PRIMARY": "0: (Default) Video source is the primary camera."
      },
      {
        "VIDEO_SOURCE_CAMERA": "0: (Default) Video source is the primary camera."
      },
      {
        "VIDEO_SOURCE_CAMERA_SECONDARY": "1: Video source is the secondary camera."
      },
      {
        "VIDEO_SOURCE_SCREEN_PRIMARY": "2: Video source is the primary screen."
      },
      {
        "VIDEO_SOURCE_SCREEN": "2: Video source is the primary screen."
      },
      {
        "VIDEO_SOURCE_SCREEN_SECONDARY": "3: Video source is the secondary screen."
      },
      {
        "VIDEO_SOURCE_CUSTOM": "4: Custom video source."
      },
      {
        "VIDEO_SOURCE_MEDIA_PLAYER": "5: Video source is a media player."
      },
      {
        "VIDEO_SOURCE_RTC_IMAGE_PNG": "6: Video source is a PNG image."
      },
      {
        "VIDEO_SOURCE_RTC_IMAGE_JPEG": "7: Video source is a JPEG image."
      },
      {
        "VIDEO_SOURCE_RTC_IMAGE_GIF": "8: Video source is a GIF image."
      },
      {
        "VIDEO_SOURCE_REMOTE": "9: Video source is a remote video retrieved over the network."
      },
      {
        "VIDEO_SOURCE_TRANSCODED": "10: Transcoded video source."
      },
      {
        "VIDEO_SOURCE_CAMERA_THIRD": "11: (Android, Windows, and macOS only) Video source is the third camera."
      },
      {
        "VIDEO_SOURCE_CAMERA_FOURTH": "12: (Android, Windows, and macOS only) Video source is the fourth camera."
      },
      {
        "VIDEO_SOURCE_SCREEN_THIRD": "13: (Windows and macOS only) Video source is the third screen."
      },
      {
        "VIDEO_SOURCE_SCREEN_FOURTH": "14: (Windows and macOS only) Video source is the fourth screen."
      },
      {
        "VIDEO_SOURCE_SPEECH_DRIVEN": "15: Video source is video processed by a speech-driven plugin."
      },
      {
        "VIDEO_SOURCE_UNKNOWN": "100: Unknown video source."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videostreamtype",
    "name": "VIDEO_STREAM_TYPE",
    "description": "Video stream types.",
    "parameters": [
      {
        "VIDEO_STREAM_HIGH": "0: High stream, i.e., high resolution and high bitrate video stream."
      },
      {
        "VIDEO_STREAM_LOW": "1: Low stream, i.e., low resolution and low bitrate video stream."
      },
      {
        "VIDEO_STREAM_LAYER_1": "4: Video quality layer 1. The resolution of this layer is only lower than VIDEO_STREAM_HIGH."
      },
      {
        "VIDEO_STREAM_LAYER_2": "5: Video quality layer 2. The resolution of this layer is only lower than VIDEO_STREAM_LAYER_1."
      },
      {
        "VIDEO_STREAM_LAYER_3": "6: Video quality layer 3. The resolution of this layer is only lower than VIDEO_STREAM_LAYER_2."
      },
      {
        "VIDEO_STREAM_LAYER_4": "7: Video quality layer 4. The resolution of this layer is only lower than VIDEO_STREAM_LAYER_3."
      },
      {
        "VIDEO_STREAM_LAYER_5": "8: Video quality layer 5. The resolution of this layer is only lower than VIDEO_STREAM_LAYER_4."
      },
      {
        "VIDEO_STREAM_LAYER_6": "9: Video quality layer 6. The resolution of this layer is only lower than VIDEO_STREAM_LAYER_5."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videotranscodererror",
    "name": "VIDEO_TRANSCODER_ERROR",
    "description": "Local video composition error codes.",
    "parameters": [
      {
        "VT_ERR_VIDEO_SOURCE_NOT_READY": "1: The specified video source has not started video capture. You need to create a video track for it and start video capture."
      },
      {
        "VT_ERR_INVALID_VIDEO_SOURCE_TYPE": "2: Invalid video source type. You need to specify a supported video source type again."
      },
      {
        "VT_ERR_INVALID_IMAGE_PATH": "3: Invalid image path. You need to specify the correct image path again."
      },
      {
        "VT_ERR_UNSUPPORT_IMAGE_FORMAT": "4: Unsupported image format. Make sure the image format is one of PNG, JPEG, or GIF."
      },
      {
        "VT_ERR_INVALID_LAYOUT": "5: Invalid video encoding resolution after composition."
      },
      {
        "VT_ERR_INTERNAL": "20: Internal unknown error."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_videoviewsetupmode",
    "name": "VIDEO_VIEW_SETUP_MODE",
    "description": "View setup mode.",
    "parameters": [
      {
        "VIDEO_VIEW_SETUP_REPLACE": "0: (Default) Clears all added views and replaces them with a new view."
      },
      {
        "VIDEO_VIEW_SETUP_ADD": "1: Adds a view."
      },
      {
        "VIDEO_VIEW_SETUP_REMOVE": "2: Removes a view. When you no longer need a view, it is recommended to set setupMode to VIDEO_VIEW_SETUP_REMOVE in time to remove the view, otherwise it may cause rendering resource leaks."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_voiceaitunertype",
    "name": "VOICE_AI_TUNER_TYPE",
    "description": "AI tuner voice effect types.",
    "parameters": [
      {
        "VOICE_AI_TUNER_MATURE_MALE": "0: Mature male voice. A deep and magnetic male voice."
      },
      {
        "VOICE_AI_TUNER_FRESH_MALE": "1: Fresh male voice. A fresh and slightly sweet male voice."
      },
      {
        "VOICE_AI_TUNER_ELEGANT_FEMALE": "2: Elegant female voice. A deep and charming female voice."
      },
      {
        "VOICE_AI_TUNER_SWEET_FEMALE": "3: Sweet girl voice. A high-pitched and cute female voice."
      },
      {
        "VOICE_AI_TUNER_WARM_MALE_SINGING": "4: Warm male singing voice. A warm and melodious male voice."
      },
      {
        "VOICE_AI_TUNER_GENTLE_FEMALE_SINGING": "5: Gentle female singing voice. A soft and delicate female voice."
      },
      {
        "VOICE_AI_TUNER_HUSKY_MALE_SINGING": "6: Husky mature male singing voice. A unique hoarse male voice."
      },
      {
        "VOICE_AI_TUNER_WARM_ELEGANT_FEMALE_SINGING": "7: Warm elegant female singing voice. A warm and mature female voice."
      },
      {
        "VOICE_AI_TUNER_POWERFUL_MALE_SINGING": "8: Powerful male singing voice. A strong and forceful male voice."
      },
      {
        "VOICE_AI_TUNER_DREAMY_FEMALE_SINGING": "9: Dreamy female singing voice. A dreamy and soft female voice."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_voicebeautifierpreset",
    "name": "VOICE_BEAUTIFIER_PRESET",
    "description": "Preset voice beautifier effects.",
    "parameters": [
      {
        "VOICE_BEAUTIFIER_OFF": "Original voice, i.e., disables voice beautifier effects."
      },
      {
        "CHAT_BEAUTIFIER_MAGNETIC": "Magnetic (male). This setting is only effective for male voices. Do not apply it to female voices, otherwise audio distortion may occur."
      },
      {
        "CHAT_BEAUTIFIER_FRESH": "Fresh (female). This setting is only effective for female voices. Do not apply it to male voices, otherwise audio distortion may occur."
      },
      {
        "CHAT_BEAUTIFIER_VITALITY": "Energetic (female). This setting is only effective for female voices. Do not apply it to male voices, otherwise audio distortion may occur."
      },
      {
        "SINGING_BEAUTIFIER": "Singing beautifier.\n If you call SetVoiceBeautifierPreset (SINGING_BEAUTIFIER), you can beautify male voices and add a small room reverb effect. Do not apply it to female voices, otherwise audio distortion may occur.\n If you call SetVoiceBeautifierParameters (SINGING_BEAUTIFIER, param1, param2), you can beautify male or female voices and add reverb effects."
      },
      {
        "TIMBRE_TRANSFORMATION_VIGOROUS": "Vigorous."
      },
      {
        "TIMBRE_TRANSFORMATION_DEEP": "Deep."
      },
      {
        "TIMBRE_TRANSFORMATION_MELLOW": "Mellow."
      },
      {
        "TIMBRE_TRANSFORMATION_FALSETTO": "Falsetto."
      },
      {
        "TIMBRE_TRANSFORMATION_FULL": "Full."
      },
      {
        "TIMBRE_TRANSFORMATION_CLEAR": "Clear."
      },
      {
        "TIMBRE_TRANSFORMATION_RESOUNDING": "Resounding."
      },
      {
        "TIMBRE_TRANSFORMATION_RINGING": "Ringing."
      },
      {
        "ULTRA_HIGH_QUALITY_VOICE": "Ultra-high-quality voice, which makes the audio clearer and more detailed.\n For better results, it is recommended to set the profile parameter of SetAudioProfile [2/2] to AUDIO_PROFILE_MUSIC_HIGH_QUALITY (4) or AUDIO_PROFILE_MUSIC_HIGH_QUALITY_STEREO (5), and the scenario parameter to AUDIO_SCENARIO_GAME_STREAMING (3) before calling SetVoiceBeautifierPreset.\n If the user's audio capture device can highly restore audio details, it is recommended not to enable ultra-high-quality voice, otherwise the SDK may over-restore audio details and fail to achieve the expected effect."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_voiceconversionpreset",
    "name": "VOICE_CONVERSION_PRESET",
    "description": "Preset voice conversion effects.",
    "parameters": [
      {
        "VOICE_CONVERSION_OFF": "Original voice, i.e., disables voice conversion effects."
      },
      {
        "VOICE_CHANGER_NEUTRAL": "Neutral. To avoid audio distortion, make sure to apply this effect only to female voices."
      },
      {
        "VOICE_CHANGER_SWEET": "Sweet. To avoid audio distortion, make sure to apply this effect only to female voices."
      },
      {
        "VOICE_CHANGER_SOLID": "Solid. To avoid audio distortion, make sure to apply this effect only to male voices."
      },
      {
        "VOICE_CHANGER_BASS": "Bass. To avoid audio distortion, make sure to apply this effect only to male voices."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_warningcode",
    "name": "WarningCode",
    "description": "Warning codes. See https://docs.agora.io/en/Interactive%20Broadcast/error_rtc.",
    "parameters": [],
    "returns": ""
  },
  {
    "id": "enum_watermarkfitmode",
    "name": "WATERMARK_FIT_MODE",
    "description": "Watermark fit mode.",
    "parameters": [
      {
        "FIT_MODE_COVER_POSITION": "0: Uses the positionInLandscapeMode and positionInPortraitMode values set in WatermarkOptions. The settings in WatermarkRatio are ignored."
      },
      {
        "FIT_MODE_USE_IMAGE_RATIO": "1: Uses the values set in WatermarkRatio. The positionInLandscapeMode and positionInPortraitMode settings in WatermarkOptions are ignored."
      }
    ],
    "returns": "",
    "is_hide": false
  },
  {
    "id": "enum_watermarksourcetype",
    "name": "WATERMARK_SOURCE_TYPE",
    "description": "Watermark source type.\n\nSince Available since v4.6.2.",
    "parameters": [
      {
        "IMAGE": "(0): The watermark source is an image."
      },
      {
        "BUFFER": "(1): The watermark source is a buffer."
      },
      {
        "LITERAL": "(2): The watermark source is a text literal. Supported on Linux only."
      },
      {
        "TIMESTAMPS": "(3): The watermark source is a timestamp. Supported on Linux only."
      }
    ],
    "returns": "",
    "is_hide": false
  }
]
